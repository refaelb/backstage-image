'use strict';

var catalogModel = require('@backstage/catalog-model');
var integration = require('@backstage/integration');
var crypto = require('crypto');
var lodash = require('lodash');
var errors = require('@backstage/errors');
require('core-js/features/promise');
var codeowners = require('codeowners-utils');
var parseGitUrl = require('git-url-parse');
var pluginCatalogNode = require('@backstage/plugin-catalog-node');
var fs = require('fs-extra');
var g = require('glob');
var path = require('path');
var util = require('util');
var yaml = require('yaml');
var limiterFactory = require('p-limit');
var uuid = require('uuid');
var backendCommon = require('@backstage/backend-common');
var luxon = require('luxon');
var promClient = require('prom-client');
var api = require('@opentelemetry/api');
var stableStringify = require('fast-json-stable-stringify');
var uniq = require('lodash/uniq');
var splitToChunks = require('lodash/chunk');
var zod = require('zod');
var types = require('@backstage/types');
var catalogClient = require('@backstage/catalog-client');
var yn = require('yn');
var backendOpenapiUtils = require('@backstage/backend-openapi-utils');
var pluginAuthNode = require('@backstage/plugin-auth-node');
var alpha = require('@backstage/plugin-catalog-common/alpha');
var pluginPermissionCommon = require('@backstage/plugin-permission-common');
var minimatch = require('minimatch');
var config = require('@backstage/config');
var pluginPermissionNode = require('@backstage/plugin-permission-node');

function _interopDefaultLegacy (e) { return e && typeof e === 'object' && 'default' in e ? e : { 'default': e }; }

function _interopNamespace(e) {
  if (e && e.__esModule) return e;
  var n = Object.create(null);
  if (e) {
    Object.keys(e).forEach(function (k) {
      if (k !== 'default') {
        var d = Object.getOwnPropertyDescriptor(e, k);
        Object.defineProperty(n, k, d.get ? d : {
          enumerable: true,
          get: function () { return e[k]; }
        });
      }
    });
  }
  n["default"] = e;
  return Object.freeze(n);
}

var lodash__default = /*#__PURE__*/_interopDefaultLegacy(lodash);
var codeowners__namespace = /*#__PURE__*/_interopNamespace(codeowners);
var parseGitUrl__default = /*#__PURE__*/_interopDefaultLegacy(parseGitUrl);
var fs__default = /*#__PURE__*/_interopDefaultLegacy(fs);
var g__default = /*#__PURE__*/_interopDefaultLegacy(g);
var path__default = /*#__PURE__*/_interopDefaultLegacy(path);
var yaml__default = /*#__PURE__*/_interopDefaultLegacy(yaml);
var limiterFactory__default = /*#__PURE__*/_interopDefaultLegacy(limiterFactory);
var stableStringify__default = /*#__PURE__*/_interopDefaultLegacy(stableStringify);
var uniq__default = /*#__PURE__*/_interopDefaultLegacy(uniq);
var splitToChunks__default = /*#__PURE__*/_interopDefaultLegacy(splitToChunks);
var yn__default = /*#__PURE__*/_interopDefaultLegacy(yn);
var minimatch__default = /*#__PURE__*/_interopDefaultLegacy(minimatch);

const USER_PATTERN = /^@.*/;
const GROUP_PATTERN = /^@.*\/.*/;
const EMAIL_PATTERN = /^.*@.*\..*$/;
function resolveCodeOwner(contents, catalogInfoFileUrl) {
  const codeOwnerEntries = codeowners__namespace.parse(contents);
  const { filepath } = parseGitUrl__default["default"](catalogInfoFileUrl);
  const match = codeowners__namespace.matchFile(filepath, codeOwnerEntries);
  return match ? normalizeCodeOwner(match.owners[0]) : void 0;
}
function normalizeCodeOwner(owner) {
  if (owner.match(GROUP_PATTERN)) {
    return owner.split("/")[1];
  } else if (owner.match(USER_PATTERN)) {
    return `User:${owner.substring(1)}`;
  } else if (owner.match(EMAIL_PATTERN)) {
    return owner.split("@")[0];
  }
  return owner;
}

const CODEOWNERS = "CODEOWNERS";
const scmCodeOwnersPaths = {
  // https://mibexsoftware.atlassian.net/wiki/spaces/CODEOWNERS/pages/222822413/Usage
  bitbucket: [CODEOWNERS, `.bitbucket/${CODEOWNERS}`],
  // https://docs.gitlab.com/ee/user/project/code_owners.html#how-to-set-up-code-owners
  gitlab: [CODEOWNERS, `.gitlab/${CODEOWNERS}`, `docs/${CODEOWNERS}`],
  // https://docs.github.com/en/github/creating-cloning-and-archiving-repositories/about-code-owners#codeowners-file-location
  github: [CODEOWNERS, `.github/${CODEOWNERS}`, `docs/${CODEOWNERS}`]
};

async function readCodeOwners(reader, sourceUrl, codeownersPaths) {
  const readOwnerLocation = async (path) => {
    const url = `${sourceUrl}${path}`;
    const data = await reader.readUrl(url);
    const buffer = await data.buffer();
    return buffer.toString();
  };
  const candidates = codeownersPaths.map(readOwnerLocation);
  return Promise.any(candidates).catch((aggregateError) => {
    const hardError = aggregateError.errors.find(
      (error) => !(error instanceof errors.NotFoundError)
    );
    if (hardError) {
      throw hardError;
    }
    return void 0;
  });
}
async function findCodeOwnerByTarget(reader, targetUrl, scmIntegration) {
  var _a;
  const codeownersPaths = scmCodeOwnersPaths[(_a = scmIntegration == null ? void 0 : scmIntegration.type) != null ? _a : ""];
  const sourceUrl = scmIntegration == null ? void 0 : scmIntegration.resolveUrl({
    url: "/",
    base: targetUrl
  });
  if (!sourceUrl || !codeownersPaths) {
    return void 0;
  }
  const contents = await readCodeOwners(reader, sourceUrl, codeownersPaths);
  if (!contents) {
    return void 0;
  }
  const owner = resolveCodeOwner(contents, targetUrl);
  return owner;
}

var __defProp$c = Object.defineProperty;
var __defNormalProp$c = (obj, key, value) => key in obj ? __defProp$c(obj, key, { enumerable: true, configurable: true, writable: true, value }) : obj[key] = value;
var __publicField$c = (obj, key, value) => {
  __defNormalProp$c(obj, typeof key !== "symbol" ? key + "" : key, value);
  return value;
};
const ALLOWED_KINDS = ["API", "Component", "Domain", "Resource", "System"];
const ALLOWED_LOCATION_TYPES = ["url"];
class CodeOwnersProcessor {
  constructor(options) {
    __publicField$c(this, "integrations");
    __publicField$c(this, "logger");
    __publicField$c(this, "reader");
    this.integrations = options.integrations;
    this.logger = options.logger;
    this.reader = options.reader;
  }
  static fromConfig(config, options) {
    const integrations = integration.ScmIntegrations.fromConfig(config);
    return new CodeOwnersProcessor({
      ...options,
      integrations
    });
  }
  getProcessorName() {
    return "CodeOwnersProcessor";
  }
  async preProcessEntity(entity, location) {
    if (!entity || !ALLOWED_KINDS.includes(entity.kind) || !ALLOWED_LOCATION_TYPES.includes(location.type) || entity.spec && entity.spec.owner) {
      return entity;
    }
    const scmIntegration = this.integrations.byUrl(location.target);
    if (!scmIntegration) {
      return entity;
    }
    const owner = await findCodeOwnerByTarget(
      this.reader,
      location.target,
      scmIntegration
    );
    if (!owner) {
      this.logger.debug(
        `CodeOwnerProcessor could not resolve owner for ${location.target}`
      );
      return entity;
    }
    return {
      ...entity,
      spec: { ...entity.spec, owner }
    };
  }
}

class AnnotateLocationEntityProcessor {
  constructor(options) {
    this.options = options;
  }
  getProcessorName() {
    return "AnnotateLocationEntityProcessor";
  }
  async preProcessEntity(entity, location, _, originLocation) {
    const { integrations } = this.options;
    let viewUrl;
    let editUrl;
    let sourceLocation;
    if (location.type === "url") {
      const scmIntegration = integrations.byUrl(location.target);
      viewUrl = location.target;
      editUrl = scmIntegration == null ? void 0 : scmIntegration.resolveEditUrl(location.target);
      const sourceUrl = scmIntegration == null ? void 0 : scmIntegration.resolveUrl({
        url: "./",
        base: location.target
      });
      if (sourceUrl) {
        sourceLocation = catalogModel.stringifyLocationRef({
          type: "url",
          target: sourceUrl
        });
      }
    }
    return lodash.merge(
      {
        metadata: {
          annotations: lodash.pickBy(
            {
              [catalogModel.ANNOTATION_LOCATION]: catalogModel.stringifyLocationRef(location),
              [catalogModel.ANNOTATION_ORIGIN_LOCATION]: catalogModel.stringifyLocationRef(originLocation),
              [catalogModel.ANNOTATION_VIEW_URL]: viewUrl,
              [catalogModel.ANNOTATION_EDIT_URL]: editUrl,
              [catalogModel.ANNOTATION_SOURCE_LOCATION]: sourceLocation
            },
            lodash.identity
          )
        }
      },
      entity
    );
  }
}

var __defProp$b = Object.defineProperty;
var __defNormalProp$b = (obj, key, value) => key in obj ? __defProp$b(obj, key, { enumerable: true, configurable: true, writable: true, value }) : obj[key] = value;
var __publicField$b = (obj, key, value) => {
  __defNormalProp$b(obj, typeof key !== "symbol" ? key + "" : key, value);
  return value;
};
class BuiltinKindsEntityProcessor {
  constructor() {
    __publicField$b(this, "validators", [
      catalogModel.apiEntityV1alpha1Validator,
      catalogModel.componentEntityV1alpha1Validator,
      catalogModel.resourceEntityV1alpha1Validator,
      catalogModel.groupEntityV1alpha1Validator,
      catalogModel.locationEntityV1alpha1Validator,
      catalogModel.userEntityV1alpha1Validator,
      catalogModel.systemEntityV1alpha1Validator,
      catalogModel.domainEntityV1alpha1Validator
    ]);
  }
  getProcessorName() {
    return "BuiltinKindsEntityProcessor";
  }
  async validateEntityKind(entity) {
    for (const validator of this.validators) {
      const results = await validator.check(entity);
      if (results) {
        return true;
      }
    }
    return false;
  }
  async postProcessEntity(entity, _location, emit) {
    const selfRef = catalogModel.getCompoundEntityRef(entity);
    function doEmit(targets, context, outgoingRelation, incomingRelation) {
      if (!targets) {
        return;
      }
      for (const target of [targets].flat()) {
        const targetRef = catalogModel.parseEntityRef(target, context);
        emit(
          pluginCatalogNode.processingResult.relation({
            source: selfRef,
            type: outgoingRelation,
            target: {
              kind: targetRef.kind,
              namespace: targetRef.namespace,
              name: targetRef.name
            }
          })
        );
        emit(
          pluginCatalogNode.processingResult.relation({
            source: {
              kind: targetRef.kind,
              namespace: targetRef.namespace,
              name: targetRef.name
            },
            type: incomingRelation,
            target: selfRef
          })
        );
      }
    }
    if (entity.kind === "Component") {
      const component = entity;
      doEmit(
        component.spec.owner,
        { defaultKind: "Group", defaultNamespace: selfRef.namespace },
        catalogModel.RELATION_OWNED_BY,
        catalogModel.RELATION_OWNER_OF
      );
      doEmit(
        component.spec.subcomponentOf,
        { defaultKind: "Component", defaultNamespace: selfRef.namespace },
        catalogModel.RELATION_PART_OF,
        catalogModel.RELATION_HAS_PART
      );
      doEmit(
        component.spec.providesApis,
        { defaultKind: "API", defaultNamespace: selfRef.namespace },
        catalogModel.RELATION_PROVIDES_API,
        catalogModel.RELATION_API_PROVIDED_BY
      );
      doEmit(
        component.spec.consumesApis,
        { defaultKind: "API", defaultNamespace: selfRef.namespace },
        catalogModel.RELATION_CONSUMES_API,
        catalogModel.RELATION_API_CONSUMED_BY
      );
      doEmit(
        component.spec.dependsOn,
        { defaultNamespace: selfRef.namespace },
        catalogModel.RELATION_DEPENDS_ON,
        catalogModel.RELATION_DEPENDENCY_OF
      );
      doEmit(
        component.spec.system,
        { defaultKind: "System", defaultNamespace: selfRef.namespace },
        catalogModel.RELATION_PART_OF,
        catalogModel.RELATION_HAS_PART
      );
    }
    if (entity.kind === "API") {
      const api = entity;
      doEmit(
        api.spec.owner,
        { defaultKind: "Group", defaultNamespace: selfRef.namespace },
        catalogModel.RELATION_OWNED_BY,
        catalogModel.RELATION_OWNER_OF
      );
      doEmit(
        api.spec.system,
        { defaultKind: "System", defaultNamespace: selfRef.namespace },
        catalogModel.RELATION_PART_OF,
        catalogModel.RELATION_HAS_PART
      );
    }
    if (entity.kind === "Resource") {
      const resource = entity;
      doEmit(
        resource.spec.owner,
        { defaultKind: "Group", defaultNamespace: selfRef.namespace },
        catalogModel.RELATION_OWNED_BY,
        catalogModel.RELATION_OWNER_OF
      );
      doEmit(
        resource.spec.dependsOn,
        { defaultNamespace: selfRef.namespace },
        catalogModel.RELATION_DEPENDS_ON,
        catalogModel.RELATION_DEPENDENCY_OF
      );
      doEmit(
        resource.spec.dependencyOf,
        { defaultNamespace: selfRef.namespace },
        catalogModel.RELATION_DEPENDENCY_OF,
        catalogModel.RELATION_DEPENDS_ON
      );
      doEmit(
        resource.spec.system,
        { defaultKind: "System", defaultNamespace: selfRef.namespace },
        catalogModel.RELATION_PART_OF,
        catalogModel.RELATION_HAS_PART
      );
    }
    if (entity.kind === "User") {
      const user = entity;
      doEmit(
        user.spec.memberOf,
        { defaultKind: "Group", defaultNamespace: selfRef.namespace },
        catalogModel.RELATION_MEMBER_OF,
        catalogModel.RELATION_HAS_MEMBER
      );
    }
    if (entity.kind === "Group") {
      const group = entity;
      doEmit(
        group.spec.parent,
        { defaultKind: "Group", defaultNamespace: selfRef.namespace },
        catalogModel.RELATION_CHILD_OF,
        catalogModel.RELATION_PARENT_OF
      );
      doEmit(
        group.spec.children,
        { defaultKind: "Group", defaultNamespace: selfRef.namespace },
        catalogModel.RELATION_PARENT_OF,
        catalogModel.RELATION_CHILD_OF
      );
      doEmit(
        group.spec.members,
        { defaultKind: "User", defaultNamespace: selfRef.namespace },
        catalogModel.RELATION_HAS_MEMBER,
        catalogModel.RELATION_MEMBER_OF
      );
    }
    if (entity.kind === "System") {
      const system = entity;
      doEmit(
        system.spec.owner,
        { defaultKind: "Group", defaultNamespace: selfRef.namespace },
        catalogModel.RELATION_OWNED_BY,
        catalogModel.RELATION_OWNER_OF
      );
      doEmit(
        system.spec.domain,
        { defaultKind: "Domain", defaultNamespace: selfRef.namespace },
        catalogModel.RELATION_PART_OF,
        catalogModel.RELATION_HAS_PART
      );
    }
    if (entity.kind === "Domain") {
      const domain = entity;
      doEmit(
        domain.spec.owner,
        { defaultKind: "Group", defaultNamespace: selfRef.namespace },
        catalogModel.RELATION_OWNED_BY,
        catalogModel.RELATION_OWNER_OF
      );
    }
    return entity;
  }
}

const glob = util.promisify(g__default["default"]);
const LOCATION_TYPE = "file";
class FileReaderProcessor {
  getProcessorName() {
    return "FileReaderProcessor";
  }
  async readLocation(location, optional, emit, parser) {
    if (location.type !== LOCATION_TYPE) {
      return false;
    }
    try {
      const fileMatches = await glob(location.target);
      if (fileMatches.length > 0) {
        for (const fileMatch of fileMatches) {
          const data = await fs__default["default"].readFile(fileMatch);
          const normalizedFilePath = path__default["default"].normalize(fileMatch);
          for await (const parseResult of parser({
            data,
            location: {
              type: LOCATION_TYPE,
              target: normalizedFilePath
            }
          })) {
            emit(parseResult);
            emit(
              pluginCatalogNode.processingResult.refresh(
                `${LOCATION_TYPE}:${normalizedFilePath}`
              )
            );
          }
        }
      } else if (!optional) {
        const message = `${location.type} ${location.target} does not exist`;
        emit(pluginCatalogNode.processingResult.notFoundError(location, message));
      }
    } catch (e) {
      const message = `${location.type} ${location.target} could not be read, ${e}`;
      emit(pluginCatalogNode.processingResult.generalError(location, message));
    }
    return true;
  }
}

class PlaceholderProcessor {
  constructor(options) {
    this.options = options;
  }
  getProcessorName() {
    return "PlaceholderProcessor";
  }
  async preProcessEntity(entity, location, emit) {
    const process = async (data) => {
      if (!data || !(data instanceof Object)) {
        return [data, false];
      }
      if (Array.isArray(data)) {
        const items = await Promise.all(data.map((item) => process(item)));
        return items.every(([, changed]) => !changed) ? [data, false] : [items.map(([item]) => item), true];
      }
      const keys = Object.keys(data);
      if (!keys.some((k) => k.startsWith("$"))) {
        const entries = await Promise.all(
          Object.entries(data).map(
            ([k, v]) => process(v).then((vp) => [k, vp])
          )
        );
        return entries.every(([, [, changed]]) => !changed) ? [data, false] : [Object.fromEntries(entries.map(([k, [v]]) => [k, v])), true];
      } else if (keys.length !== 1) {
        return [data, false];
      }
      const resolverKey = keys[0].substring(1);
      const resolverValue = data[keys[0]];
      const resolver = this.options.resolvers[resolverKey];
      if (!resolver) {
        return [data, false];
      }
      const read = async (url) => {
        const response = await this.options.reader.readUrl(url);
        const buffer = await response.buffer();
        return buffer;
      };
      const resolveUrl = (url, base) => this.options.integrations.resolveUrl({
        url,
        base
      });
      return [
        await resolver({
          key: resolverKey,
          value: resolverValue,
          baseUrl: location.target,
          read,
          resolveUrl,
          emit
        }),
        true
      ];
    };
    const [result] = await process(entity);
    return result;
  }
}
async function yamlPlaceholderResolver(params) {
  var _a;
  const { content, url } = await readTextLocation(params);
  params.emit(pluginCatalogNode.processingResult.refresh(`url:${url}`));
  let documents;
  try {
    documents = yaml__default["default"].parseAllDocuments(content).filter((d) => d);
  } catch (e) {
    throw new Error(
      `Placeholder $${params.key} failed to parse YAML data at ${params.value}, ${e}`
    );
  }
  if (documents.length !== 1) {
    throw new Error(
      `Placeholder $${params.key} expected to find exactly one document of data at ${params.value}, found ${documents.length}`
    );
  }
  const document = documents[0];
  if ((_a = document.errors) == null ? void 0 : _a.length) {
    throw new Error(
      `Placeholder $${params.key} found an error in the data at ${params.value}, ${document.errors[0]}`
    );
  }
  return document.toJSON();
}
async function jsonPlaceholderResolver(params) {
  const { content, url } = await readTextLocation(params);
  params.emit(pluginCatalogNode.processingResult.refresh(`url:${url}`));
  try {
    return JSON.parse(content);
  } catch (e) {
    throw new Error(
      `Placeholder $${params.key} failed to parse JSON data at ${params.value}, ${e}`
    );
  }
}
async function textPlaceholderResolver(params) {
  const { content, url } = await readTextLocation(params);
  params.emit(pluginCatalogNode.processingResult.refresh(`url:${url}`));
  return content;
}
async function readTextLocation(params) {
  const newUrl = relativeUrl(params);
  try {
    const data = await params.read(newUrl);
    return { content: data.toString("utf-8"), url: newUrl };
  } catch (e) {
    throw new Error(
      `Placeholder $${params.key} could not read location ${params.value}, ${e}`
    );
  }
}
function relativeUrl({
  key,
  value,
  baseUrl,
  resolveUrl
}) {
  if (typeof value !== "string") {
    throw new Error(
      `Placeholder $${key} expected a string value parameter, in the form of an absolute URL or a relative path`
    );
  }
  try {
    return resolveUrl(value, baseUrl);
  } catch (e) {
    throw new Error(
      `Placeholder $${key} could not form a URL out of ${baseUrl} and ${value}, ${e}`
    );
  }
}

const CACHE_KEY = "v1";
class UrlReaderProcessor {
  constructor(options) {
    this.options = options;
  }
  getProcessorName() {
    return "url-reader";
  }
  async readLocation(location, optional, emit, parser, cache) {
    if (location.type !== "url") {
      return false;
    }
    const cacheItem = await cache.get(CACHE_KEY);
    try {
      const { response, etag: newEtag } = await this.doRead(
        location.target,
        cacheItem == null ? void 0 : cacheItem.etag
      );
      const parseResults = [];
      for (const item of response) {
        for await (const parseResult of parser({
          data: item.data,
          location: { type: location.type, target: item.url }
        })) {
          parseResults.push(parseResult);
          emit(parseResult);
        }
      }
      const isOnlyEntities = parseResults.every((r) => r.type === "entity");
      if (newEtag && isOnlyEntities) {
        await cache.set(CACHE_KEY, {
          etag: newEtag,
          value: parseResults
        });
      }
      emit(pluginCatalogNode.processingResult.refresh(`${location.type}:${location.target}`));
    } catch (error) {
      errors.assertError(error);
      const message = `Unable to read ${location.type}, ${error}`.substring(
        0,
        5e3
      );
      if (error.name === "NotModifiedError" && cacheItem) {
        for (const parseResult of cacheItem.value) {
          emit(parseResult);
        }
        emit(pluginCatalogNode.processingResult.refresh(`${location.type}:${location.target}`));
      } else if (error.name === "NotFoundError") {
        if (!optional) {
          emit(pluginCatalogNode.processingResult.notFoundError(location, message));
        }
      } else {
        emit(pluginCatalogNode.processingResult.generalError(location, message));
      }
    }
    return true;
  }
  async doRead(location, etag) {
    const { filepath } = parseGitUrl__default["default"](location);
    if (filepath == null ? void 0 : filepath.match(/[*?]/)) {
      const limiter = limiterFactory__default["default"](5);
      const response = await this.options.reader.search(location, { etag });
      const output = response.files.map(async (file) => ({
        url: file.url,
        data: await limiter(file.content)
      }));
      return { response: await Promise.all(output), etag: response.etag };
    }
    const data = await this.options.reader.readUrl(location, { etag });
    return {
      response: [{ url: location, data: await data.buffer() }],
      etag: data.etag
    };
  }
}

function* parseEntityYaml(data, location) {
  var _a;
  let documents;
  try {
    documents = yaml__default["default"].parseAllDocuments(data.toString("utf8")).filter((d) => d);
  } catch (e) {
    const loc = catalogModel.stringifyLocationRef(location);
    const message = `Failed to parse YAML at ${loc}, ${e}`;
    yield pluginCatalogNode.processingResult.generalError(location, message);
    return;
  }
  for (const document of documents) {
    if ((_a = document.errors) == null ? void 0 : _a.length) {
      const loc = catalogModel.stringifyLocationRef(location);
      const message = `YAML error at ${loc}, ${document.errors[0]}`;
      yield pluginCatalogNode.processingResult.generalError(location, message);
    } else {
      const json = document.toJSON();
      if (lodash__default["default"].isPlainObject(json)) {
        yield pluginCatalogNode.processingResult.entity(location, json);
      } else if (json === null) ; else {
        const message = `Expected object at root, got ${typeof json}`;
        yield pluginCatalogNode.processingResult.generalError(location, message);
      }
    }
  }
}
const defaultEntityDataParser = async function* defaultEntityDataParser2({ data, location }) {
  for (const e of parseEntityYaml(data, location)) {
    yield e;
  }
};

function createRandomProcessingInterval(options) {
  const { minSeconds, maxSeconds } = options;
  return () => {
    return Math.random() * (maxSeconds - minSeconds) + minSeconds;
  };
}

function isLocationEntity(entity) {
  return entity.kind === "Location";
}
function getEntityLocationRef(entity) {
  var _a;
  const ref = (_a = entity.metadata.annotations) == null ? void 0 : _a[catalogModel.ANNOTATION_LOCATION];
  if (!ref) {
    const entityRef = catalogModel.stringifyEntityRef(entity);
    throw new errors.InputError(
      `Entity '${entityRef}' does not have the annotation ${catalogModel.ANNOTATION_LOCATION}`
    );
  }
  return ref;
}
function getEntityOriginLocationRef(entity) {
  var _a;
  const ref = (_a = entity.metadata.annotations) == null ? void 0 : _a[catalogModel.ANNOTATION_ORIGIN_LOCATION];
  if (!ref) {
    const entityRef = catalogModel.stringifyEntityRef(entity);
    throw new errors.InputError(
      `Entity '${entityRef}' does not have the annotation ${catalogModel.ANNOTATION_ORIGIN_LOCATION}`
    );
  }
  return ref;
}
function toAbsoluteUrl(integrations, base, type, target) {
  if (base.type !== type) {
    return target;
  }
  try {
    if (type === "file") {
      if (target.startsWith(".")) {
        return path__default["default"].join(path__default["default"].dirname(base.target), target);
      }
      return target;
    } else if (type === "url") {
      return integrations.resolveUrl({ url: target, base: base.target });
    }
    return target;
  } catch (e) {
    return target;
  }
}
function isObject(value) {
  return typeof value === "object" && value !== null && !Array.isArray(value);
}
const validateEntity = catalogModel.entitySchemaValidator();
const validateEntityEnvelope = catalogModel.entityEnvelopeSchemaValidator();

function locationSpecToMetadataName(location) {
  const hash = crypto.createHash("sha1").update(`${location.type}:${location.target}`).digest("hex");
  return `generated-${hash}`;
}
function locationSpecToLocationEntity(opts) {
  var _a, _b;
  const location = opts.location;
  const parentEntity = opts.parentEntity;
  let ownLocation;
  let originLocation;
  if (parentEntity) {
    const maybeOwnLocation = (_a = parentEntity.metadata.annotations) == null ? void 0 : _a[catalogModel.ANNOTATION_LOCATION];
    if (!maybeOwnLocation) {
      throw new Error(
        `Parent entity '${catalogModel.stringifyEntityRef(
          parentEntity
        )}' of location '${catalogModel.stringifyLocationRef(
          location
        )}' does not have a location annotation`
      );
    }
    ownLocation = maybeOwnLocation;
    const maybeOriginLocation = (_b = parentEntity.metadata.annotations) == null ? void 0 : _b[catalogModel.ANNOTATION_ORIGIN_LOCATION];
    if (!maybeOriginLocation) {
      throw new Error(
        `Parent entity '${catalogModel.stringifyEntityRef(
          parentEntity
        )}' of location '${catalogModel.stringifyLocationRef(
          location
        )}' does not have an origin location annotation`
      );
    }
    originLocation = maybeOriginLocation;
  } else {
    ownLocation = catalogModel.stringifyLocationRef(location);
    originLocation = ownLocation;
  }
  const result = {
    apiVersion: "backstage.io/v1alpha1",
    kind: "Location",
    metadata: {
      name: locationSpecToMetadataName(location),
      annotations: {
        [catalogModel.ANNOTATION_LOCATION]: ownLocation,
        [catalogModel.ANNOTATION_ORIGIN_LOCATION]: originLocation
      }
    },
    spec: {
      type: location.type,
      target: location.target,
      presence: location.presence
    }
  };
  return result;
}

class ConfigLocationEntityProvider {
  constructor(config) {
    this.config = config;
  }
  getProviderName() {
    return "ConfigLocationProvider";
  }
  async connect(connection) {
    const entities = this.getEntitiesFromConfig();
    await connection.applyMutation({
      type: "full",
      entities
    });
    if (this.config.subscribe) {
      let currentKey = JSON.stringify(entities);
      this.config.subscribe(() => {
        const newEntities = this.getEntitiesFromConfig();
        const newKey = JSON.stringify(newEntities);
        if (currentKey !== newKey) {
          currentKey = newKey;
          connection.applyMutation({
            type: "full",
            entities: newEntities
          });
        }
      });
    }
  }
  getEntitiesFromConfig() {
    var _a;
    const locationConfigs = (_a = this.config.getOptionalConfigArray("catalog.locations")) != null ? _a : [];
    return locationConfigs.map((location) => {
      const type = location.getString("type");
      const target = location.getString("target");
      const entity = locationSpecToLocationEntity({
        location: {
          type,
          target: type === "file" ? path__default["default"].resolve(target) : target
        }
      });
      const locationKey = getEntityLocationRef(entity);
      return { entity, locationKey };
    });
  }
}

var __defProp$a = Object.defineProperty;
var __defNormalProp$a = (obj, key, value) => key in obj ? __defProp$a(obj, key, { enumerable: true, configurable: true, writable: true, value }) : obj[key] = value;
var __publicField$a = (obj, key, value) => {
  __defNormalProp$a(obj, typeof key !== "symbol" ? key + "" : key, value);
  return value;
};
class DefaultLocationStore {
  constructor(db) {
    this.db = db;
    __publicField$a(this, "_connection");
  }
  getProviderName() {
    return "DefaultLocationStore";
  }
  async createLocation(input) {
    const location = await this.db.transaction(async (tx) => {
      const previousLocations = await this.locations(tx);
      const previousLocation = previousLocations.some(
        (l) => input.type === l.type && input.target === l.target
      );
      if (previousLocation) {
        throw new errors.ConflictError(
          `Location ${input.type}:${input.target} already exists`
        );
      }
      const inner = {
        id: uuid.v4(),
        type: input.type,
        target: input.target
      };
      await tx("locations").insert(inner);
      return inner;
    });
    const entity = locationSpecToLocationEntity({ location });
    await this.connection.applyMutation({
      type: "delta",
      added: [{ entity, locationKey: getEntityLocationRef(entity) }],
      removed: []
    });
    return location;
  }
  async listLocations() {
    return await this.locations();
  }
  async getLocation(id) {
    const items = await this.db("locations").where({ id }).select();
    if (!items.length) {
      throw new errors.NotFoundError(`Found no location with ID ${id}`);
    }
    return items[0];
  }
  async deleteLocation(id) {
    if (!this.connection) {
      throw new Error("location store is not initialized");
    }
    const deleted = await this.db.transaction(async (tx) => {
      const [location] = await tx("locations").where({ id }).select();
      if (!location) {
        throw new errors.NotFoundError(`Found no location with ID ${id}`);
      }
      await tx("locations").where({ id }).del();
      return location;
    });
    const entity = locationSpecToLocationEntity({ location: deleted });
    await this.connection.applyMutation({
      type: "delta",
      added: [],
      removed: [{ entity, locationKey: getEntityLocationRef(entity) }]
    });
  }
  async getLocationByEntity(entityRef) {
    const entityRefString = catalogModel.stringifyEntityRef(entityRef);
    const [entity] = await this.db("refresh_state").where({ entity_ref: entityRefString }).select("entity_id").limit(1);
    if (!entity) {
      throw new errors.NotFoundError(`found no entity for ref ${entityRefString}`);
    }
    const [locationKeyValue] = await this.db("search").where({
      entity_id: entity.entity_id,
      key: `metadata.annotations.${catalogModel.ANNOTATION_ORIGIN_LOCATION}`
    }).select("value").limit(1);
    if (!locationKeyValue) {
      throw new errors.NotFoundError(
        `found no origin annotation for ref ${entityRefString}`
      );
    }
    const { type, target } = catalogModel.parseLocationRef(entityRefString);
    const [location] = await this.db("locations").where({ type, target }).select().limit(1);
    if (!location) {
      throw new errors.NotFoundError(
        `Found no location with type ${type} and target ${target}`
      );
    }
    return location;
  }
  get connection() {
    if (!this._connection) {
      throw new Error("location store is not initialized");
    }
    return this._connection;
  }
  async connect(connection) {
    this._connection = connection;
    const locations = await this.locations();
    const entities = locations.map((location) => {
      const entity = locationSpecToLocationEntity({ location });
      return { entity, locationKey: getEntityLocationRef(entity) };
    });
    await this.connection.applyMutation({
      type: "full",
      entities
    });
  }
  async locations(dbOrTx = this.db) {
    const locations = await dbOrTx("locations").select();
    return locations.filter(({ type }) => type !== "bootstrap").map((item) => ({
      id: item.id,
      target: item.target,
      type: item.type
    }));
  }
}

var __defProp$9 = Object.defineProperty;
var __defNormalProp$9 = (obj, key, value) => key in obj ? __defProp$9(obj, key, { enumerable: true, configurable: true, writable: true, value }) : obj[key] = value;
var __publicField$9 = (obj, key, value) => {
  __defNormalProp$9(obj, typeof key !== "symbol" ? key + "" : key, value);
  return value;
};
class RepoLocationAnalyzer {
  constructor(logger, scmIntegrations, analyzers) {
    __publicField$9(this, "logger");
    __publicField$9(this, "scmIntegrations");
    __publicField$9(this, "analyzers");
    this.logger = logger;
    this.scmIntegrations = scmIntegrations;
    this.analyzers = analyzers;
  }
  async analyzeLocation(request) {
    const integration = this.scmIntegrations.byUrl(request.location.target);
    const { owner, name } = parseGitUrl__default["default"](request.location.target);
    let annotationPrefix;
    switch (integration == null ? void 0 : integration.type) {
      case "azure":
        annotationPrefix = "dev.azure.com";
        break;
      case "bitbucket":
        annotationPrefix = "bitbucket.org";
        break;
      case "github":
        annotationPrefix = "github.com";
        break;
      case "gitlab":
        annotationPrefix = "gitlab.com";
        break;
    }
    const analyzer = this.analyzers.find(
      (a) => a.supports(request.location.target)
    );
    if (analyzer) {
      const analyzerResult = await analyzer.analyze({
        url: request.location.target
      });
      if (analyzerResult.existing.length > 0) {
        this.logger.debug(
          `entity for ${request.location.target} already exists.`
        );
        return {
          existingEntityFiles: analyzerResult.existing,
          generateEntities: []
        };
      }
    }
    const entity = {
      apiVersion: "backstage.io/v1alpha1",
      kind: "Component",
      metadata: {
        name
      },
      spec: { type: "other", lifecycle: "unknown" }
    };
    if (annotationPrefix) {
      entity.metadata.annotations = {
        [`${annotationPrefix}/project-slug`]: `${owner}/${name}`
      };
    }
    this.logger.debug(`entity created for ${request.location.target}`);
    return {
      existingEntityFiles: [],
      generateEntities: [{ entity, fields: [] }]
    };
  }
}

function timestampToDateTime(input) {
  try {
    if (typeof input === "object") {
      return luxon.DateTime.fromJSDate(input).toUTC();
    }
    const result = input.includes(" ") ? luxon.DateTime.fromSQL(input, { zone: "utc" }) : luxon.DateTime.fromISO(input, { zone: "utc" });
    if (!result.isValid) {
      throw new TypeError("Not valid");
    }
    return result;
  } catch (e) {
    throw new errors.InputError(`Failed to parse database timestamp ${input}`, e);
  }
}
function rethrowError(e) {
  if (backendCommon.isDatabaseConflictError(e)) {
    throw new errors.ConflictError(`Rejected due to a conflicting entity`, e);
  }
  throw e;
}

function createCounterMetric(config) {
  let metric = promClient.register.getSingleMetric(config.name);
  if (!metric) {
    metric = new promClient.Counter(config);
    promClient.register.registerMetric(metric);
  }
  return metric;
}
function createGaugeMetric(config) {
  let metric = promClient.register.getSingleMetric(config.name);
  if (!metric) {
    metric = new promClient.Gauge(config);
    promClient.register.registerMetric(metric);
  }
  return metric;
}
function createSummaryMetric(config) {
  let metric = promClient.register.getSingleMetric(config.name);
  if (!metric) {
    metric = new promClient.Summary(config);
    promClient.register.registerMetric(metric);
  }
  return metric;
}

function initDatabaseMetrics(knex) {
  const seenProm = /* @__PURE__ */ new Set();
  const seen = /* @__PURE__ */ new Set();
  const meter = api.metrics.getMeter("default");
  return {
    entities_count_prom: createGaugeMetric({
      name: "catalog_entities_count",
      help: "Total amount of entities in the catalog. DEPRECATED: Please use opentelemetry metrics instead.",
      labelNames: ["kind"],
      async collect() {
        const result = await knex("refresh_state").select(
          "entity_ref"
        );
        const results = result.map((row) => row.entity_ref.split(":")[0]).reduce((acc, e) => acc.set(e, (acc.get(e) || 0) + 1), /* @__PURE__ */ new Map());
        results.forEach((value, key) => {
          seenProm.add(key);
          this.set({ kind: key }, value);
        });
        seenProm.forEach((key) => {
          if (!results.has(key)) {
            this.set({ kind: key }, 0);
            seenProm.delete(key);
          }
        });
      }
    }),
    registered_locations_prom: createGaugeMetric({
      name: "catalog_registered_locations_count",
      help: "Total amount of registered locations in the catalog. DEPRECATED: Please use opentelemetry metrics instead.",
      async collect() {
        const total = await knex("locations").count({
          count: "*"
        });
        this.set(Number(total[0].count));
      }
    }),
    relations_prom: createGaugeMetric({
      name: "catalog_relations_count",
      help: "Total amount of relations between entities. DEPRECATED: Please use opentelemetry metrics instead.",
      async collect() {
        const total = await knex("relations").count({
          count: "*"
        });
        this.set(Number(total[0].count));
      }
    }),
    entities_count: meter.createObservableGauge("catalog_entities_count", {
      description: "Total amount of entities in the catalog"
    }).addCallback(async (gauge) => {
      const result = await knex("refresh_state").select(
        "entity_ref"
      );
      const results = result.map((row) => catalogModel.parseEntityRef(row.entity_ref).kind).reduce((acc, e) => acc.set(e, (acc.get(e) || 0) + 1), /* @__PURE__ */ new Map());
      results.forEach((value, key) => {
        seen.add(key);
        gauge.observe(value, { kind: key });
      });
      seen.forEach((key) => {
        if (!results.has(key)) {
          gauge.observe(0, { kind: key });
          seen.delete(key);
        }
      });
    }),
    registered_locations: meter.createObservableGauge("catalog_registered_locations_count", {
      description: "Total amount of registered locations in the catalog"
    }).addCallback(async (gauge) => {
      const total = await knex("locations").count({
        count: "*"
      });
      gauge.observe(Number(total[0].count));
    }),
    relations: meter.createObservableGauge("catalog_relations_count", {
      description: "Total amount of relations between entities"
    }).addCallback(async (gauge) => {
      const total = await knex("relations").count({
        count: "*"
      });
      gauge.observe(Number(total[0].count));
    })
  };
}

async function checkLocationKeyConflict(options) {
  const { tx, entityRef, locationKey } = options;
  const row = await tx("refresh_state").select("location_key").where("entity_ref", entityRef).first();
  const conflictingKey = row == null ? void 0 : row.location_key;
  if (!conflictingKey) {
    return void 0;
  }
  if (conflictingKey !== locationKey) {
    return conflictingKey;
  }
  return void 0;
}

async function insertUnprocessedEntity(options) {
  const { tx, entity, hash, logger, locationKey } = options;
  const entityRef = catalogModel.stringifyEntityRef(entity);
  const serializedEntity = JSON.stringify(entity);
  try {
    let query = tx("refresh_state").insert({
      entity_id: uuid.v4(),
      entity_ref: entityRef,
      unprocessed_entity: serializedEntity,
      unprocessed_hash: hash,
      errors: "",
      location_key: locationKey,
      next_update_at: tx.fn.now(),
      last_discovery_at: tx.fn.now()
    });
    if (tx.client.config.client.includes("pg")) {
      query = query.onConflict("entity_ref").ignore();
    }
    const result = await query;
    return result.rowCount === 1 || result.length === 1;
  } catch (error) {
    if (!backendCommon.isDatabaseConflictError(error)) {
      throw error;
    } else {
      logger.debug(`Unable to insert a new refresh state row, ${error}`);
      return false;
    }
  }
}

async function updateUnprocessedEntity(options) {
  const { tx, entity, hash, locationKey } = options;
  const entityRef = catalogModel.stringifyEntityRef(entity);
  const serializedEntity = JSON.stringify(entity);
  const refreshResult = await tx("refresh_state").update({
    unprocessed_entity: serializedEntity,
    unprocessed_hash: hash,
    location_key: locationKey,
    last_discovery_at: tx.fn.now(),
    // We only get to this point if a processed entity actually had any changes, or
    // if an entity provider requested this mutation, meaning that we can safely
    // bump the deferred entities to the front of the queue for immediate processing.
    next_update_at: tx.fn.now()
  }).where("entity_ref", entityRef).andWhere((inner) => {
    if (!locationKey) {
      return inner.whereNull("location_key");
    }
    return inner.where("location_key", locationKey).orWhereNull("location_key");
  });
  return refreshResult === 1;
}

function generateStableHash$1(entity) {
  return crypto.createHash("sha1").update(stableStringify__default["default"]({ ...entity })).digest("hex");
}

const CATALOG_CONFLICTS_TOPIC = "experimental.catalog.conflict";

const BATCH_SIZE$2 = 50;
class DefaultProcessingDatabase {
  constructor(options) {
    this.options = options;
    initDatabaseMetrics(options.database);
  }
  async updateProcessedEntity(txOpaque, options) {
    const tx = txOpaque;
    const {
      id,
      processedEntity,
      resultHash,
      errors: errors$1,
      relations,
      deferredEntities,
      refreshKeys,
      locationKey
    } = options;
    const configClient = tx.client.config.client;
    const refreshResult = await tx("refresh_state").update({
      processed_entity: JSON.stringify(processedEntity),
      result_hash: resultHash,
      errors: errors$1,
      location_key: locationKey
    }).where("entity_id", id).andWhere((inner) => {
      if (!locationKey) {
        return inner.whereNull("location_key");
      }
      return inner.where("location_key", locationKey).orWhereNull("location_key");
    });
    if (refreshResult === 0) {
      throw new errors.ConflictError(
        `Conflicting write of processing result for ${id} with location key '${locationKey}'`
      );
    }
    const sourceEntityRef = catalogModel.stringifyEntityRef(processedEntity);
    await this.addUnprocessedEntities(tx, {
      entities: deferredEntities,
      sourceEntityRef
    });
    let previousRelationRows;
    if (configClient.includes("sqlite3") || configClient.includes("mysql")) {
      previousRelationRows = await tx("relations").select("*").where({ originating_entity_id: id });
      await tx("relations").where({ originating_entity_id: id }).delete();
    } else {
      previousRelationRows = await tx("relations").where({ originating_entity_id: id }).delete().returning("*");
    }
    const relationRows = relations.map(
      ({ source, target, type }) => ({
        originating_entity_id: id,
        source_entity_ref: catalogModel.stringifyEntityRef(source),
        target_entity_ref: catalogModel.stringifyEntityRef(target),
        type
      })
    );
    await tx.batchInsert(
      "relations",
      this.deduplicateRelations(relationRows),
      BATCH_SIZE$2
    );
    await tx("refresh_keys").where({ entity_id: id }).delete();
    await tx.batchInsert(
      "refresh_keys",
      refreshKeys.map((k) => ({
        entity_id: id,
        key: k.key
      })),
      BATCH_SIZE$2
    );
    return {
      previous: {
        relations: previousRelationRows
      }
    };
  }
  async updateProcessedEntityErrors(txOpaque, options) {
    const tx = txOpaque;
    const { id, errors, resultHash } = options;
    await tx("refresh_state").update({
      errors,
      result_hash: resultHash
    }).where("entity_id", id);
  }
  async updateEntityCache(txOpaque, options) {
    const tx = txOpaque;
    const { id, state } = options;
    await tx("refresh_state").update({ cache: JSON.stringify(state != null ? state : {}) }).where("entity_id", id);
  }
  async getProcessableEntities(txOpaque, request) {
    const tx = txOpaque;
    let itemsQuery = tx("refresh_state").select();
    if (["mysql", "mysql2", "pg"].includes(tx.client.config.client)) {
      itemsQuery = itemsQuery.forUpdate().skipLocked();
    }
    const items = await itemsQuery.where("next_update_at", "<=", tx.fn.now()).limit(request.processBatchSize).orderBy("next_update_at", "asc");
    const interval = this.options.refreshInterval();
    const nextUpdateAt = (refreshInterval) => {
      if (tx.client.config.client.includes("sqlite3")) {
        return tx.raw(`datetime('now', ?)`, [`${refreshInterval} seconds`]);
      }
      if (tx.client.config.client.includes("mysql")) {
        return tx.raw(`now() + interval ${refreshInterval} second`);
      }
      return tx.raw(`now() + interval '${refreshInterval} seconds'`);
    };
    await tx("refresh_state").whereIn(
      "entity_ref",
      items.map((i) => i.entity_ref)
    ).update({
      next_update_at: nextUpdateAt(interval)
    });
    return {
      items: items.map(
        (i) => ({
          id: i.entity_id,
          entityRef: i.entity_ref,
          unprocessedEntity: JSON.parse(i.unprocessed_entity),
          processedEntity: i.processed_entity ? JSON.parse(i.processed_entity) : void 0,
          resultHash: i.result_hash || "",
          nextUpdateAt: timestampToDateTime(i.next_update_at),
          lastDiscoveryAt: timestampToDateTime(i.last_discovery_at),
          state: i.cache ? JSON.parse(i.cache) : void 0,
          errors: i.errors,
          locationKey: i.location_key
        })
      )
    };
  }
  async listParents(txOpaque, options) {
    const tx = txOpaque;
    const rows = await tx(
      "refresh_state_references"
    ).where({ target_entity_ref: options.entityRef }).select();
    const entityRefs = rows.map((r) => r.source_entity_ref).filter(Boolean);
    return { entityRefs };
  }
  async transaction(fn) {
    try {
      let result = void 0;
      await this.options.database.transaction(
        async (tx) => {
          result = await fn(tx);
        },
        {
          // If we explicitly trigger a rollback, don't fail.
          doNotRejectOnRollback: true
        }
      );
      return result;
    } catch (e) {
      this.options.logger.debug(`Error during transaction, ${e}`);
      throw rethrowError(e);
    }
  }
  deduplicateRelations(rows) {
    return lodash__default["default"].uniqBy(
      rows,
      (r) => `${r.source_entity_ref}:${r.target_entity_ref}:${r.type}`
    );
  }
  /**
   * Add a set of deferred entities for processing.
   * The entities will be added at the front of the processing queue.
   */
  async addUnprocessedEntities(txOpaque, options) {
    var _a;
    const tx = txOpaque;
    const stateReferences = new Array();
    for (const { entity, locationKey } of options.entities) {
      const entityRef = catalogModel.stringifyEntityRef(entity);
      const hash = generateStableHash$1(entity);
      const updated = await updateUnprocessedEntity({
        tx,
        entity,
        hash,
        locationKey
      });
      if (updated) {
        stateReferences.push(entityRef);
        continue;
      }
      const inserted = await insertUnprocessedEntity({
        tx,
        entity,
        hash,
        locationKey,
        logger: this.options.logger
      });
      if (inserted) {
        stateReferences.push(entityRef);
        continue;
      }
      const conflictingKey = await checkLocationKeyConflict({
        tx,
        entityRef,
        locationKey
      });
      if (conflictingKey) {
        this.options.logger.warn(
          `Detected conflicting entityRef ${entityRef} already referenced by ${conflictingKey} and now also ${locationKey}`
        );
        if (this.options.eventBroker && locationKey) {
          const eventParams = {
            topic: CATALOG_CONFLICTS_TOPIC,
            eventPayload: {
              unprocessedEntity: entity,
              entityRef,
              newLocationKey: locationKey,
              existingLocationKey: conflictingKey,
              lastConflictAt: luxon.DateTime.now().toISO()
            }
          };
          await ((_a = this.options.eventBroker) == null ? void 0 : _a.publish(eventParams));
        }
      }
    }
    await tx("refresh_state_references").andWhere({ source_entity_ref: options.sourceEntityRef }).delete();
    await tx.batchInsert(
      "refresh_state_references",
      stateReferences.map((entityRef) => ({
        source_entity_ref: options.sourceEntityRef,
        target_entity_ref: entityRef
      })),
      BATCH_SIZE$2
    );
  }
}

async function applyDatabaseMigrations(knex) {
  const migrationsDir = backendCommon.resolvePackagePath(
    "@backstage/plugin-catalog-backend",
    "migrations"
  );
  await knex.migrate.latest({
    directory: migrationsDir
  });
}

function stitchingStrategyFromConfig(config) {
  const strategyMode = config.getOptionalString(
    "catalog.stitchingStrategy.mode"
  );
  if (strategyMode === void 0 || strategyMode === "immediate") {
    return {
      mode: "immediate"
    };
  } else if (strategyMode === "deferred") {
    return {
      mode: "deferred",
      pollingInterval: { seconds: 1 },
      stitchTimeout: { seconds: 60 }
    };
  }
  throw new Error(
    `Invalid stitching strategy mode '${strategyMode}', expected one of 'immediate' or 'deferred'`
  );
}

const TRACER_ID = "backstage-plugin-catalog-backend";
function setAttributeIfDefined(span, attribute, value) {
  if (value !== null && value !== void 0) {
    span.setAttribute(attribute, value);
  }
}
function addEntityAttributes(span, entity) {
  var _a, _b;
  setAttributeIfDefined(span, "backstage.entity.apiVersion", entity.apiVersion);
  setAttributeIfDefined(span, "backstage.entity.kind", entity.kind);
  setAttributeIfDefined(
    span,
    "backstage.entity.metadata.namespace",
    (_a = entity.metadata) == null ? void 0 : _a.namespace
  );
  setAttributeIfDefined(
    span,
    "backstage.entity.metadata.name",
    (_b = entity.metadata) == null ? void 0 : _b.name
  );
}
const onException = (e, span) => {
  span.recordException(e);
  span.setStatus({
    code: api.SpanStatusCode.ERROR
  });
};
function isPromiseLike(obj) {
  return !!obj && (typeof obj === "object" || typeof obj === "function") && "then" in obj && typeof obj.then === "function";
}
function handleFn(span, fn) {
  try {
    const ret = fn(span);
    if (isPromiseLike(ret)) {
      ret.then(
        () => {
          span.end();
        },
        (e) => {
          onException(e, span);
          span.end();
        }
      );
    } else {
      span.end();
    }
    return ret;
  } catch (e) {
    onException(e, span);
    span.end();
    throw e;
  }
}
function withActiveSpan(tracer, name, fn, spanOptions = {}) {
  return tracer.startActiveSpan(name, spanOptions, (span) => {
    return handleFn(span, fn);
  });
}

const DEFAULT_POLLING_INTERVAL_MS = 1e3;
const tracer$2 = api.trace.getTracer(TRACER_ID);
function startTaskPipeline(options) {
  const {
    loadTasks,
    processTask,
    lowWatermark,
    highWatermark,
    pollingIntervalMs = DEFAULT_POLLING_INTERVAL_MS
  } = options;
  if (lowWatermark >= highWatermark) {
    throw new Error("lowWatermark must be lower than highWatermark");
  }
  const state = { inFlightCount: 0 };
  const abortController = new AbortController();
  const abortSignal = abortController.signal;
  const barrier = createBarrier({
    waitTimeoutMillis: pollingIntervalMs,
    signal: abortSignal
  });
  async function pipelineLoop() {
    while (!abortSignal.aborted) {
      if (state.inFlightCount <= lowWatermark) {
        await withActiveSpan(tracer$2, "TaskPipelineLoop", async (span) => {
          const loadCount = highWatermark - state.inFlightCount;
          const loadedItems = await Promise.resolve().then(() => loadTasks(loadCount)).catch(() => {
            return [];
          });
          span.setAttribute("itemCount", loadedItems.length);
          if (loadedItems.length && !abortSignal.aborted) {
            state.inFlightCount += loadedItems.length;
            for (const item of loadedItems) {
              Promise.resolve().then(() => processTask(item)).catch(() => {
              }).finally(() => {
                state.inFlightCount -= 1;
                barrier.release();
              });
            }
          }
        });
      }
      await barrier.wait();
    }
  }
  pipelineLoop().catch((error) => {
    throw new Error(`Unexpected error in processing pipeline loop`, error);
  });
  return () => {
    abortController.abort();
    barrier.destroy();
  };
}
function createBarrier(options) {
  const { waitTimeoutMillis, signal } = options;
  const resolvers = /* @__PURE__ */ new Set();
  function wait() {
    if (signal.aborted || !(waitTimeoutMillis > 0)) {
      return Promise.resolve();
    }
    return new Promise((resolve) => {
      const timeoutHandle = setTimeout(done, waitTimeoutMillis);
      function done() {
        resolvers.delete(done);
        clearTimeout(timeoutHandle);
        resolve();
      }
      resolvers.add(done);
    });
  }
  function release() {
    const resolversToCall = new Set(resolvers);
    resolvers.clear();
    for (const resolver of resolversToCall) {
      resolver();
    }
  }
  signal.addEventListener("abort", release);
  return {
    wait,
    release,
    destroy: () => signal.removeEventListener("abort", release)
  };
}

async function markForStitching(options) {
  const entityRefs = split(options.entityRefs);
  const entityIds = split(options.entityIds);
  const knex = options.knex;
  const mode = options.strategy.mode;
  if (mode === "immediate") {
    for (const chunk of entityRefs) {
      await knex.table("final_entities").update({
        hash: "force-stitching"
      }).whereIn(
        "entity_id",
        knex("refresh_state").select("entity_id").whereIn("entity_ref", chunk)
      );
      await knex.table("refresh_state").update({
        result_hash: "force-stitching",
        next_update_at: knex.fn.now()
      }).whereIn("entity_ref", chunk);
    }
    for (const chunk of entityIds) {
      await knex.table("final_entities").update({
        hash: "force-stitching"
      }).whereIn("entity_id", chunk);
      await knex.table("refresh_state").update({
        result_hash: "force-stitching",
        next_update_at: knex.fn.now()
      }).whereIn("entity_id", chunk);
    }
  } else if (mode === "deferred") {
    const ticket = uuid.v4();
    for (const chunk of entityRefs) {
      await knex("refresh_state").update({
        next_stitch_at: knex.fn.now(),
        next_stitch_ticket: ticket
      }).whereIn("entity_ref", chunk);
    }
    for (const chunk of entityIds) {
      await knex("refresh_state").update({
        next_stitch_at: knex.fn.now(),
        next_stitch_ticket: ticket
      }).whereIn("entity_id", chunk);
    }
  } else {
    throw new Error(`Unknown stitching strategy mode ${mode}`);
  }
}
function split(input) {
  if (!input) {
    return [];
  }
  return splitToChunks__default["default"](Array.isArray(input) ? input : [...input], 200);
}

async function deleteOrphanedEntities(options) {
  const { knex, strategy } = options;
  let total = 0;
  for (let i = 0; i < 100; ++i) {
    const candidates = await knex.with(
      "orphans",
      ["entity_id", "entity_ref"],
      (orphans) => orphans.from("refresh_state").select("refresh_state.entity_id", "refresh_state.entity_ref").leftOuterJoin(
        "refresh_state_references",
        "refresh_state_references.target_entity_ref",
        "refresh_state.entity_ref"
      ).whereNull("refresh_state_references.target_entity_ref")
    ).select({
      entityId: "orphans.entity_id",
      relationSourceId: "refresh_state.entity_id"
    }).from("orphans").leftOuterJoin(
      "relations",
      "relations.target_entity_ref",
      "orphans.entity_ref"
    ).leftOuterJoin(
      "refresh_state",
      "refresh_state.entity_ref",
      "relations.source_entity_ref"
    );
    if (!candidates.length) {
      break;
    }
    const orphanIds = uniq__default["default"](candidates.map((r) => r.entityId));
    const orphanRelationIds = uniq__default["default"](
      candidates.map((r) => r.relationSourceId).filter(Boolean)
    );
    total += orphanIds.length;
    await knex.table("refresh_state").delete().whereIn("entity_id", orphanIds);
    await markForStitching({
      knex,
      strategy,
      entityIds: orphanRelationIds
    });
  }
  return total;
}

var __defProp$8 = Object.defineProperty;
var __defNormalProp$8 = (obj, key, value) => key in obj ? __defProp$8(obj, key, { enumerable: true, configurable: true, writable: true, value }) : obj[key] = value;
var __publicField$8 = (obj, key, value) => {
  __defNormalProp$8(obj, typeof key !== "symbol" ? key + "" : key, value);
  return value;
};
const CACHE_TTL = 5;
const tracer$1 = api.trace.getTracer(TRACER_ID);
class DefaultCatalogProcessingEngine {
  constructor(options) {
    __publicField$8(this, "config");
    __publicField$8(this, "scheduler");
    __publicField$8(this, "logger");
    __publicField$8(this, "knex");
    __publicField$8(this, "processingDatabase");
    __publicField$8(this, "orchestrator");
    __publicField$8(this, "stitcher");
    __publicField$8(this, "createHash");
    __publicField$8(this, "pollingIntervalMs");
    __publicField$8(this, "orphanCleanupIntervalMs");
    __publicField$8(this, "onProcessingError");
    __publicField$8(this, "tracker");
    __publicField$8(this, "stopFunc");
    var _a, _b, _c;
    this.config = options.config;
    this.scheduler = options.scheduler;
    this.logger = options.logger;
    this.knex = options.knex;
    this.processingDatabase = options.processingDatabase;
    this.orchestrator = options.orchestrator;
    this.stitcher = options.stitcher;
    this.createHash = options.createHash;
    this.pollingIntervalMs = (_a = options.pollingIntervalMs) != null ? _a : 1e3;
    this.orphanCleanupIntervalMs = (_b = options.orphanCleanupIntervalMs) != null ? _b : 3e4;
    this.onProcessingError = options.onProcessingError;
    this.tracker = (_c = options.tracker) != null ? _c : progressTracker$1();
    this.stopFunc = void 0;
  }
  async start() {
    if (this.stopFunc) {
      throw new Error("Processing engine is already started");
    }
    const stopPipeline = this.startPipeline();
    const stopCleanup = this.startOrphanCleanup();
    this.stopFunc = () => {
      stopPipeline();
      stopCleanup();
    };
  }
  async stop() {
    if (this.stopFunc) {
      this.stopFunc();
      this.stopFunc = void 0;
    }
  }
  startPipeline() {
    return startTaskPipeline({
      lowWatermark: 5,
      highWatermark: 10,
      pollingIntervalMs: this.pollingIntervalMs,
      loadTasks: async (count) => {
        try {
          const { items } = await this.processingDatabase.transaction(
            async (tx) => {
              return this.processingDatabase.getProcessableEntities(tx, {
                processBatchSize: count
              });
            }
          );
          return items;
        } catch (error) {
          this.logger.warn("Failed to load processing items", error);
          return [];
        }
      },
      processTask: async (item) => {
        await withActiveSpan(tracer$1, "ProcessingRun", async (span) => {
          var _a, _b;
          const track = this.tracker.processStart(item, this.logger);
          addEntityAttributes(span, item.unprocessedEntity);
          try {
            const {
              id,
              state,
              unprocessedEntity,
              entityRef,
              locationKey,
              resultHash: previousResultHash
            } = item;
            const result = await this.orchestrator.process({
              entity: unprocessedEntity,
              state
            });
            track.markProcessorsCompleted(result);
            if (result.ok) {
              const { ttl: _, ...stateWithoutTtl } = state != null ? state : {};
              if (stableStringify__default["default"](stateWithoutTtl) !== stableStringify__default["default"](result.state)) {
                await this.processingDatabase.transaction(async (tx) => {
                  await this.processingDatabase.updateEntityCache(tx, {
                    id,
                    state: {
                      ttl: CACHE_TTL,
                      ...result.state
                    }
                  });
                });
              }
            } else {
              const maybeTtl = state == null ? void 0 : state.ttl;
              const ttl = Number.isInteger(maybeTtl) ? maybeTtl : 0;
              await this.processingDatabase.transaction(async (tx) => {
                await this.processingDatabase.updateEntityCache(tx, {
                  id,
                  state: ttl > 0 ? { ...state, ttl: ttl - 1 } : {}
                });
              });
            }
            const location = (_b = (_a = unprocessedEntity == null ? void 0 : unprocessedEntity.metadata) == null ? void 0 : _a.annotations) == null ? void 0 : _b[catalogModel.ANNOTATION_LOCATION];
            for (const error of result.errors) {
              this.logger.warn(error.message, {
                entity: entityRef,
                location
              });
            }
            const errorsString = JSON.stringify(
              result.errors.map((e) => errors.serializeError(e))
            );
            let hashBuilder = this.createHash().update(errorsString);
            if (result.ok) {
              const { entityRefs: parents } = await this.processingDatabase.transaction(
                (tx) => this.processingDatabase.listParents(tx, {
                  entityRef
                })
              );
              hashBuilder = hashBuilder.update(stableStringify__default["default"]({ ...result.completedEntity })).update(stableStringify__default["default"]([...result.deferredEntities])).update(stableStringify__default["default"]([...result.relations])).update(stableStringify__default["default"]([...result.refreshKeys])).update(stableStringify__default["default"]([...parents]));
            }
            const resultHash = hashBuilder.digest("hex");
            if (resultHash === previousResultHash) {
              track.markSuccessfulWithNoChanges();
              return;
            }
            if (!result.ok) {
              Promise.resolve(void 0).then(
                () => {
                  var _a2;
                  return (_a2 = this.onProcessingError) == null ? void 0 : _a2.call(this, {
                    unprocessedEntity,
                    errors: result.errors
                  });
                }
              ).catch((error) => {
                this.logger.debug(
                  `Processing error listener threw an exception, ${errors.stringifyError(
                    error
                  )}`
                );
              });
              await this.processingDatabase.transaction(async (tx) => {
                await this.processingDatabase.updateProcessedEntityErrors(tx, {
                  id,
                  errors: errorsString,
                  resultHash
                });
              });
              await this.stitcher.stitch({
                entityRefs: [catalogModel.stringifyEntityRef(unprocessedEntity)]
              });
              track.markSuccessfulWithErrors();
              return;
            }
            result.completedEntity.metadata.uid = id;
            let oldRelationSources;
            await this.processingDatabase.transaction(async (tx) => {
              const { previous } = await this.processingDatabase.updateProcessedEntity(tx, {
                id,
                processedEntity: result.completedEntity,
                resultHash,
                errors: errorsString,
                relations: result.relations,
                deferredEntities: result.deferredEntities,
                locationKey,
                refreshKeys: result.refreshKeys
              });
              oldRelationSources = new Map(
                previous.relations.map((r) => [
                  `${r.source_entity_ref}:${r.type}`,
                  r.source_entity_ref
                ])
              );
            });
            const newRelationSources = new Map(
              result.relations.map((relation) => {
                const sourceEntityRef = catalogModel.stringifyEntityRef(relation.source);
                return [`${sourceEntityRef}:${relation.type}`, sourceEntityRef];
              })
            );
            const setOfThingsToStitch = /* @__PURE__ */ new Set([
              catalogModel.stringifyEntityRef(result.completedEntity)
            ]);
            newRelationSources.forEach((sourceEntityRef, uniqueKey) => {
              if (!oldRelationSources.has(uniqueKey)) {
                setOfThingsToStitch.add(sourceEntityRef);
              }
            });
            oldRelationSources.forEach((sourceEntityRef, uniqueKey) => {
              if (!newRelationSources.has(uniqueKey)) {
                setOfThingsToStitch.add(sourceEntityRef);
              }
            });
            await this.stitcher.stitch({
              entityRefs: setOfThingsToStitch
            });
            track.markSuccessfulWithChanges();
          } catch (error) {
            errors.assertError(error);
            track.markFailed(error);
          }
        });
      }
    });
  }
  startOrphanCleanup() {
    var _a;
    const orphanStrategy = (_a = this.config.getOptionalString("catalog.orphanStrategy")) != null ? _a : "keep";
    if (orphanStrategy !== "delete") {
      return () => {
      };
    }
    const stitchingStrategy = stitchingStrategyFromConfig(this.config);
    const runOnce = async () => {
      try {
        const n = await deleteOrphanedEntities({
          knex: this.knex,
          strategy: stitchingStrategy
        });
        if (n > 0) {
          this.logger.info(`Deleted ${n} orphaned entities`);
        }
      } catch (error) {
        this.logger.warn(`Failed to delete orphaned entities`, error);
      }
    };
    if (this.scheduler) {
      const abortController = new AbortController();
      this.scheduler.scheduleTask({
        id: "catalog_orphan_cleanup",
        frequency: { milliseconds: this.orphanCleanupIntervalMs },
        timeout: { milliseconds: this.orphanCleanupIntervalMs * 0.8 },
        fn: runOnce,
        signal: abortController.signal
      });
      return () => {
        abortController.abort();
      };
    }
    const intervalKey = setInterval(runOnce, this.orphanCleanupIntervalMs);
    return () => {
      clearInterval(intervalKey);
    };
  }
}
function progressTracker$1() {
  const promProcessedEntities = createCounterMetric({
    name: "catalog_processed_entities_count",
    help: "Amount of entities processed, DEPRECATED, use OpenTelemetry metrics instead",
    labelNames: ["result"]
  });
  const promProcessingDuration = createSummaryMetric({
    name: "catalog_processing_duration_seconds",
    help: "Time spent executing the full processing flow, DEPRECATED, use OpenTelemetry metrics instead",
    labelNames: ["result"]
  });
  const promProcessorsDuration = createSummaryMetric({
    name: "catalog_processors_duration_seconds",
    help: "Time spent executing catalog processors, DEPRECATED, use OpenTelemetry metrics instead",
    labelNames: ["result"]
  });
  const promProcessingQueueDelay = createSummaryMetric({
    name: "catalog_processing_queue_delay_seconds",
    help: "The amount of delay between being scheduled for processing, and the start of actually being processed, DEPRECATED, use OpenTelemetry metrics instead"
  });
  const meter = api.metrics.getMeter("default");
  const processedEntities = meter.createCounter(
    "catalog.processed.entities.count",
    { description: "Amount of entities processed" }
  );
  const processingDuration = meter.createHistogram(
    "catalog.processing.duration",
    {
      description: "Time spent executing the full processing flow",
      unit: "seconds"
    }
  );
  const processorsDuration = meter.createHistogram(
    "catalog.processors.duration",
    {
      description: "Time spent executing catalog processors",
      unit: "seconds"
    }
  );
  const processingQueueDelay = meter.createHistogram(
    "catalog.processing.queue.delay",
    {
      description: "The amount of delay between being scheduled for processing, and the start of actually being processed",
      unit: "seconds"
    }
  );
  function processStart(item, logger) {
    const startTime = process.hrtime();
    const endOverallTimer = promProcessingDuration.startTimer();
    const endProcessorsTimer = promProcessorsDuration.startTimer();
    logger.debug(`Processing ${item.entityRef}`);
    if (item.nextUpdateAt) {
      const seconds = -item.nextUpdateAt.diffNow().as("seconds");
      promProcessingQueueDelay.observe(seconds);
      processingQueueDelay.record(seconds);
    }
    function endTime() {
      const delta = process.hrtime(startTime);
      return delta[0] + delta[1] / 1e9;
    }
    function markProcessorsCompleted(result) {
      endProcessorsTimer({ result: result.ok ? "ok" : "failed" });
      processorsDuration.record(endTime(), {
        result: result.ok ? "ok" : "failed"
      });
    }
    function markSuccessfulWithNoChanges() {
      endOverallTimer({ result: "unchanged" });
      promProcessedEntities.inc({ result: "unchanged" }, 1);
      processingDuration.record(endTime(), { result: "unchanged" });
      processedEntities.add(1, { result: "unchanged" });
    }
    function markSuccessfulWithErrors() {
      endOverallTimer({ result: "errors" });
      promProcessedEntities.inc({ result: "errors" }, 1);
      processingDuration.record(endTime(), { result: "errors" });
      processedEntities.add(1, { result: "errors" });
    }
    function markSuccessfulWithChanges() {
      endOverallTimer({ result: "changed" });
      promProcessedEntities.inc({ result: "changed" }, 1);
      processingDuration.record(endTime(), { result: "changed" });
      processedEntities.add(1, { result: "changed" });
    }
    function markFailed(error) {
      promProcessedEntities.inc({ result: "failed" }, 1);
      processedEntities.add(1, { result: "failed" });
      logger.warn(`Processing of ${item.entityRef} failed`, error);
    }
    return {
      markProcessorsCompleted,
      markSuccessfulWithNoChanges,
      markSuccessfulWithErrors,
      markSuccessfulWithChanges,
      markFailed
    };
  }
  return { processStart };
}

class DefaultLocationService {
  constructor(store, orchestrator, options = {
    allowedLocationTypes: ["url"]
  }) {
    this.store = store;
    this.orchestrator = orchestrator;
    this.options = options;
  }
  async createLocation(input, dryRun) {
    if (!this.options.allowedLocationTypes.includes(input.type)) {
      throw new errors.InputError(
        `Registered locations must be of an allowed type ${JSON.stringify(
          this.options.allowedLocationTypes
        )}`
      );
    }
    if (dryRun) {
      return this.dryRunCreateLocation(input);
    }
    const location = await this.store.createLocation(input);
    return { location, entities: [] };
  }
  listLocations() {
    return this.store.listLocations();
  }
  getLocation(id) {
    return this.store.getLocation(id);
  }
  deleteLocation(id) {
    return this.store.deleteLocation(id);
  }
  getLocationByEntity(entityRef) {
    return this.store.getLocationByEntity(catalogModel.parseEntityRef(entityRef));
  }
  async processEntities(unprocessedEntities) {
    const entities = [];
    while (unprocessedEntities.length) {
      const currentEntity = unprocessedEntities.pop();
      if (!currentEntity) {
        continue;
      }
      const processed = await this.orchestrator.process({
        entity: currentEntity.entity,
        state: {}
        // we process without the existing cache
      });
      if (processed.ok) {
        if (entities.some(
          (e) => catalogModel.stringifyEntityRef(e) === catalogModel.stringifyEntityRef(processed.completedEntity)
        )) {
          throw new errors.InputError(
            `Duplicate nested entity: ${catalogModel.stringifyEntityRef(
              processed.completedEntity
            )}`
          );
        }
        unprocessedEntities.push(...processed.deferredEntities);
        entities.push(processed.completedEntity);
      } else {
        throw new errors.InputError(processed.errors.map(String).join(", "));
      }
    }
    return entities;
  }
  async dryRunCreateLocation(spec) {
    const existsPromise = this.store.listLocations().then(
      (locations) => locations.some((l) => l.type === spec.type && l.target === spec.target)
    );
    const entity = {
      apiVersion: "backstage.io/v1alpha1",
      kind: "Location",
      metadata: {
        name: locationSpecToMetadataName({
          type: spec.type,
          target: spec.target
        }),
        namespace: "default",
        annotations: {
          [catalogModel.ANNOTATION_LOCATION]: `${spec.type}:${spec.target}`,
          [catalogModel.ANNOTATION_ORIGIN_LOCATION]: `${spec.type}:${spec.target}`
        }
      },
      spec: {
        type: spec.type,
        target: spec.target
      }
    };
    const unprocessedEntities = [
      { entity, locationKey: `${spec.type}:${spec.target}` }
    ];
    const entities = await this.processEntities(unprocessedEntities);
    return {
      exists: await existsPromise,
      location: { ...spec, id: `${spec.type}:${spec.target}` },
      entities
    };
  }
}

async function requireRequestBody(req) {
  const contentType = req.header("content-type");
  if (!contentType) {
    throw new errors.InputError("Content-Type missing");
  } else if (!contentType.match(/^application\/json($|;)/)) {
    throw new errors.InputError("Illegal Content-Type");
  }
  const body = req.body;
  if (!body) {
    throw new errors.InputError("Missing request body");
  } else if (!lodash__default["default"].isPlainObject(body)) {
    throw new errors.InputError("Expected body to be a JSON object");
  } else if (Object.keys(body).length === 0) {
    throw new errors.InputError("Empty request body");
  }
  return body;
}
const locationInput = zod.z.object({
  type: zod.z.string(),
  target: zod.z.string(),
  presence: zod.z.literal("required").or(zod.z.literal("optional")).optional()
}).strict();
async function validateRequestBody(req, schema) {
  const body = await requireRequestBody(req);
  try {
    return await schema.parse(body);
  } catch (e) {
    throw new errors.InputError(`Malformed request: ${e}`);
  }
}
function disallowReadonlyMode(readonly) {
  if (readonly) {
    throw new errors.NotAllowedError("This operation not allowed in readonly mode");
  }
}
function isQueryEntitiesInitialRequest(input) {
  if (!input) {
    return false;
  }
  return !isQueryEntitiesCursorRequest(input);
}
function isQueryEntitiesCursorRequest(input) {
  if (!input) {
    return false;
  }
  return !!input.cursor;
}
const entityFilterParser$1 = zod.z.lazy(
  () => zod.z.object({
    key: zod.z.string(),
    values: zod.z.array(zod.z.string()).optional()
  }).or(zod.z.object({ not: entityFilterParser$1 })).or(zod.z.object({ anyOf: zod.z.array(entityFilterParser$1) })).or(zod.z.object({ allOf: zod.z.array(entityFilterParser$1) }))
);
const cursorParser = zod.z.object({
  orderFields: zod.z.array(
    zod.z.object({ field: zod.z.string(), order: zod.z.enum(["asc", "desc"]) })
  ),
  fullTextFilter: zod.z.object({
    term: zod.z.string(),
    fields: zod.z.array(zod.z.string()).optional()
  }).optional(),
  orderFieldValues: zod.z.array(zod.z.string().or(zod.z.null())),
  filter: entityFilterParser$1.optional(),
  isPrevious: zod.z.boolean(),
  query: zod.z.string().optional(),
  firstSortFieldValues: zod.z.array(zod.z.string().or(zod.z.null())).optional(),
  totalItems: zod.z.number().optional()
});
function encodeCursor(cursor) {
  const json = JSON.stringify(cursor);
  return Buffer.from(json, "utf8").toString("base64");
}
function decodeCursor(encodedCursor) {
  try {
    const data = Buffer.from(encodedCursor, "base64").toString("utf8");
    const result = cursorParser.safeParse(JSON.parse(data));
    if (!result.success) {
      throw new errors.InputError(`Malformed cursor: ${result.error}`);
    }
    return result.data;
  } catch (e) {
    throw new errors.InputError(`Malformed cursor: ${e}`);
  }
}

var __defProp$7 = Object.defineProperty;
var __defNormalProp$7 = (obj, key, value) => key in obj ? __defProp$7(obj, key, { enumerable: true, configurable: true, writable: true, value }) : obj[key] = value;
var __publicField$7 = (obj, key, value) => {
  __defNormalProp$7(obj, typeof key !== "symbol" ? key + "" : key, value);
  return value;
};
const defaultSortField = {
  field: "metadata.uid",
  order: "asc"
};
const DEFAULT_LIMIT = 20;
function parsePagination(input) {
  if (!input) {
    return {};
  }
  let { limit, offset } = input;
  if (input.after === void 0) {
    return { limit, offset };
  }
  let cursor;
  try {
    const json = Buffer.from(input.after, "base64").toString("utf8");
    cursor = JSON.parse(json);
  } catch {
    throw new errors.InputError("Malformed after cursor, could not be parsed");
  }
  if (cursor.limit !== void 0) {
    if (!Number.isInteger(cursor.limit)) {
      throw new errors.InputError("Malformed after cursor, limit was not an number");
    }
    limit = cursor.limit;
  }
  if (cursor.offset !== void 0) {
    if (!Number.isInteger(cursor.offset)) {
      throw new errors.InputError("Malformed after cursor, offset was not a number");
    }
    offset = cursor.offset;
  }
  return { limit, offset };
}
function stringifyPagination(input) {
  const { limit, offset } = input;
  const json = JSON.stringify({ limit, offset });
  const base64 = Buffer.from(json, "utf8").toString("base64");
  return base64;
}
function addCondition(queryBuilder, db, filter, negate = false, entityIdField = "entity_id") {
  var _a;
  const key = filter.key.toLowerCase();
  const values = (_a = filter.values) == null ? void 0 : _a.map((v) => v.toLowerCase());
  const matchQuery = db("search").select("search.entity_id").where({ key }).andWhere(function keyFilter() {
    if ((values == null ? void 0 : values.length) === 1) {
      this.where({ value: values.at(0) });
    } else if (values) {
      this.andWhere("value", "in", values);
    }
  });
  queryBuilder.andWhere(entityIdField, negate ? "not in" : "in", matchQuery);
}
function isEntitiesSearchFilter(filter) {
  return filter.hasOwnProperty("key");
}
function isOrEntityFilter(filter) {
  return filter.hasOwnProperty("anyOf");
}
function isNegationEntityFilter(filter) {
  return filter.hasOwnProperty("not");
}
function parseFilter(filter, query, db, negate = false, entityIdField = "entity_id") {
  if (isNegationEntityFilter(filter)) {
    return parseFilter(filter.not, query, db, !negate, entityIdField);
  }
  if (isEntitiesSearchFilter(filter)) {
    return query.andWhere(function filterFunction() {
      addCondition(this, db, filter, negate, entityIdField);
    });
  }
  return query[negate ? "andWhereNot" : "andWhere"](function filterFunction() {
    var _a, _b;
    if (isOrEntityFilter(filter)) {
      for (const subFilter of (_a = filter.anyOf) != null ? _a : []) {
        this.orWhere(
          (subQuery) => parseFilter(subFilter, subQuery, db, false, entityIdField)
        );
      }
    } else {
      for (const subFilter of (_b = filter.allOf) != null ? _b : []) {
        this.andWhere(
          (subQuery) => parseFilter(subFilter, subQuery, db, false, entityIdField)
        );
      }
    }
  });
}
class DefaultEntitiesCatalog {
  constructor(options) {
    __publicField$7(this, "database");
    __publicField$7(this, "logger");
    __publicField$7(this, "stitcher");
    this.database = options.database;
    this.logger = options.logger;
    this.stitcher = options.stitcher;
  }
  async entities(request) {
    var _a, _b;
    const db = this.database;
    let entitiesQuery = db("final_entities").select("final_entities.*");
    (_a = request == null ? void 0 : request.order) == null ? void 0 : _a.forEach(({ field }, index) => {
      const alias = `order_${index}`;
      entitiesQuery = entitiesQuery.leftOuterJoin(
        { [alias]: "search" },
        function search(inner) {
          inner.on(`${alias}.entity_id`, "final_entities.entity_id").andOn(`${alias}.key`, db.raw("?", [field]));
        }
      );
    });
    entitiesQuery = entitiesQuery.whereNotNull("final_entities.final_entity");
    if (request == null ? void 0 : request.filter) {
      entitiesQuery = parseFilter(
        request.filter,
        entitiesQuery,
        db,
        false,
        "final_entities.entity_id"
      );
    }
    (_b = request == null ? void 0 : request.order) == null ? void 0 : _b.forEach(({ order }, index) => {
      if (db.client.config.client === "pg") {
        entitiesQuery = entitiesQuery.orderBy([
          { column: `order_${index}.value`, order, nulls: "last" }
        ]);
      } else {
        entitiesQuery = entitiesQuery.orderBy([
          { column: `order_${index}.value`, order: void 0, nulls: "last" },
          { column: `order_${index}.value`, order }
        ]);
      }
    });
    entitiesQuery = entitiesQuery.orderBy("final_entities.entity_id", "asc");
    const { limit, offset } = parsePagination(request == null ? void 0 : request.pagination);
    if (limit !== void 0) {
      entitiesQuery = entitiesQuery.limit(limit + 1);
    }
    if (offset !== void 0) {
      entitiesQuery = entitiesQuery.offset(offset);
    }
    let rows = await entitiesQuery;
    let pageInfo;
    if (limit === void 0 || rows.length <= limit) {
      pageInfo = { hasNextPage: false };
    } else {
      rows = rows.slice(0, -1);
      pageInfo = {
        hasNextPage: true,
        endCursor: stringifyPagination({
          limit,
          offset: (offset != null ? offset : 0) + limit
        })
      };
    }
    let entities = rows.map((e) => JSON.parse(e.final_entity));
    if (request == null ? void 0 : request.fields) {
      entities = entities.map((e) => request.fields(e));
    }
    for (const entity of entities) {
      if (entity.relations) {
        for (const relation of entity.relations) {
          if (!relation.targetRef && relation.target) {
            relation.targetRef = catalogModel.stringifyEntityRef(relation.target);
          } else if (!relation.target && relation.targetRef) {
            relation.target = catalogModel.parseEntityRef(relation.targetRef);
          }
        }
      }
    }
    return {
      entities,
      pageInfo
    };
  }
  async entitiesBatch(request) {
    const lookup = /* @__PURE__ */ new Map();
    for (const chunk of lodash.chunk(request.entityRefs, 200)) {
      let query = this.database("final_entities").innerJoin(
        "refresh_state",
        "refresh_state.entity_id",
        "final_entities.entity_id"
      ).select({
        entityRef: "refresh_state.entity_ref",
        entity: "final_entities.final_entity"
      }).whereIn("refresh_state.entity_ref", chunk);
      if (request == null ? void 0 : request.filter) {
        query = parseFilter(
          request.filter,
          query,
          this.database,
          false,
          "refresh_state.entity_id"
        );
      }
      for (const row of await query) {
        lookup.set(row.entityRef, row.entity ? JSON.parse(row.entity) : null);
      }
    }
    let items = request.entityRefs.map((ref) => {
      var _a;
      return (_a = lookup.get(ref)) != null ? _a : null;
    });
    if (request.fields) {
      items = items.map((e) => e && request.fields(e));
    }
    return { items };
  }
  async queryEntities(request) {
    var _a, _b, _c, _d, _e;
    const db = this.database;
    const limit = (_a = request.limit) != null ? _a : DEFAULT_LIMIT;
    const cursor = {
      orderFields: [defaultSortField],
      isPrevious: false,
      ...parseCursorFromRequest(request)
    };
    const isFetchingBackwards = cursor.isPrevious;
    if (cursor.orderFields.length > 1) {
      this.logger.warn(`Only one sort field is supported, ignoring the rest`);
    }
    const sortField = {
      ...defaultSortField,
      ...cursor.orderFields[0]
    };
    const [prevItemOrderFieldValue, prevItemUid] = cursor.orderFieldValues || [];
    const dbQuery = db("search").join("final_entities", "search.entity_id", "final_entities.entity_id").where("search.key", sortField.field);
    if (cursor.filter) {
      parseFilter(cursor.filter, dbQuery, db, false, "search.entity_id");
    }
    const normalizedFullTextFilterTerm = (_c = (_b = cursor.fullTextFilter) == null ? void 0 : _b.term) == null ? void 0 : _c.trim();
    const textFilterFields = (_e = (_d = cursor.fullTextFilter) == null ? void 0 : _d.fields) != null ? _e : [sortField.field];
    if (normalizedFullTextFilterTerm) {
      if (textFilterFields.length === 1 && textFilterFields[0] === sortField.field) {
        dbQuery.andWhereRaw(
          "value like ?",
          `%${normalizedFullTextFilterTerm.toLocaleLowerCase("en-US")}%`
        );
      } else {
        const matchQuery = db("search").select("search.entity_id").whereIn("key", textFilterFields).andWhere(function keyFilter() {
          this.andWhereRaw(
            "value like ?",
            `%${normalizedFullTextFilterTerm.toLocaleLowerCase("en-US")}%`
          );
        });
        dbQuery.andWhere("search.entity_id", "in", matchQuery);
      }
    }
    const countQuery = dbQuery.clone();
    const isOrderingDescending = sortField.order === "desc";
    if (prevItemOrderFieldValue) {
      dbQuery.andWhere(function nested() {
        this.where(
          "value",
          isFetchingBackwards !== isOrderingDescending ? "<" : ">",
          prevItemOrderFieldValue
        ).orWhere("value", "=", prevItemOrderFieldValue).andWhere(
          "search.entity_id",
          isFetchingBackwards !== isOrderingDescending ? "<" : ">",
          prevItemUid
        );
      });
    }
    dbQuery.orderBy([
      {
        column: "value",
        order: isFetchingBackwards ? invertOrder(sortField.order) : sortField.order
      },
      {
        column: "search.entity_id",
        order: isFetchingBackwards ? invertOrder(sortField.order) : sortField.order
      }
    ]).limit(isFetchingBackwards ? limit : limit + 1);
    countQuery.count("search.entity_id", { as: "count" });
    const [rows, [{ count }]] = await Promise.all([
      limit > 0 ? dbQuery : [],
      // for performance reasons we invoke the countQuery
      // only on the first request.
      // The result is then embedded into the cursor
      // for subsequent requests.
      typeof cursor.totalItems === "undefined" ? countQuery : [{ count: cursor.totalItems }]
    ]);
    const totalItems = Number(count);
    if (isFetchingBackwards) {
      rows.reverse();
    }
    const hasMoreResults = limit > 0 && (isFetchingBackwards || rows.length > limit);
    if (rows.length > limit) {
      rows.length -= 1;
    }
    const isInitialRequest = cursor.firstSortFieldValues === void 0;
    const firstRow = rows[0];
    const lastRow = rows[rows.length - 1];
    const firstSortFieldValues = cursor.firstSortFieldValues || [
      firstRow == null ? void 0 : firstRow.value,
      firstRow == null ? void 0 : firstRow.entity_id
    ];
    const nextCursor = hasMoreResults ? {
      ...cursor,
      orderFieldValues: sortFieldsFromRow(lastRow),
      firstSortFieldValues,
      isPrevious: false,
      totalItems
    } : void 0;
    const prevCursor = !isInitialRequest && rows.length > 0 && !lodash.isEqual(sortFieldsFromRow(firstRow), cursor.firstSortFieldValues) ? {
      ...cursor,
      orderFieldValues: sortFieldsFromRow(firstRow),
      firstSortFieldValues: cursor.firstSortFieldValues,
      isPrevious: true,
      totalItems
    } : void 0;
    const items = rows.map((e) => JSON.parse(e.final_entity)).map((e) => request.fields ? request.fields(e) : e);
    return {
      items,
      pageInfo: {
        ...!!prevCursor && { prevCursor },
        ...!!nextCursor && { nextCursor }
      },
      totalItems
    };
  }
  async removeEntityByUid(uid) {
    const dbConfig = this.database.client.config;
    if (dbConfig.client.includes("mysql")) {
      const results = await this.database("refresh_state").select("entity_id").whereIn("entity_ref", function parents(builder) {
        return builder.from("refresh_state").innerJoin(
          "refresh_state_references",
          {
            "refresh_state_references.target_entity_ref": "refresh_state.entity_ref"
          }
        ).where("refresh_state.entity_id", "=", uid).select("refresh_state_references.source_entity_ref");
      });
      await this.database("refresh_state").update({
        result_hash: "child-was-deleted",
        next_update_at: this.database.fn.now()
      }).whereIn(
        "entity_id",
        results.map((key) => key.entity_id)
      );
    } else {
      await this.database("refresh_state").update({
        result_hash: "child-was-deleted",
        next_update_at: this.database.fn.now()
      }).whereIn("entity_ref", function parents(builder) {
        return builder.from("refresh_state").innerJoin(
          "refresh_state_references",
          {
            "refresh_state_references.target_entity_ref": "refresh_state.entity_ref"
          }
        ).where("refresh_state.entity_id", "=", uid).select("refresh_state_references.source_entity_ref");
      });
    }
    const relationPeers = await this.database.from("relations").innerJoin("refresh_state", {
      "refresh_state.entity_ref": "relations.target_entity_ref"
    }).where("relations.originating_entity_id", "=", uid).andWhere("refresh_state.entity_id", "!=", uid).select({ ref: "relations.target_entity_ref" }).union(
      (other) => other.from("relations").innerJoin("refresh_state", {
        "refresh_state.entity_ref": "relations.source_entity_ref"
      }).where("relations.originating_entity_id", "=", uid).andWhere("refresh_state.entity_id", "!=", uid).select({ ref: "relations.source_entity_ref" })
    );
    await this.database("refresh_state").where("entity_id", uid).delete();
    await this.stitcher.stitch({
      entityRefs: new Set(relationPeers.map((p) => p.ref))
    });
  }
  async entityAncestry(rootRef) {
    const [rootRow] = await this.database("refresh_state").leftJoin("final_entities", {
      "refresh_state.entity_id": "final_entities.entity_id"
    }).where("refresh_state.entity_ref", "=", rootRef).select({
      entityJson: "final_entities.final_entity"
    });
    if (!rootRow) {
      throw new errors.NotFoundError(`No such entity ${rootRef}`);
    }
    const rootEntity = JSON.parse(rootRow.entityJson);
    const seenEntityRefs = /* @__PURE__ */ new Set();
    const todo = new Array();
    const items = new Array();
    for (let current = rootEntity; current; current = todo.pop()) {
      const currentRef = catalogModel.stringifyEntityRef(current);
      seenEntityRefs.add(currentRef);
      const parentRows = await this.database(
        "refresh_state_references"
      ).innerJoin("refresh_state", {
        "refresh_state_references.source_entity_ref": "refresh_state.entity_ref"
      }).innerJoin("final_entities", {
        "refresh_state.entity_id": "final_entities.entity_id"
      }).where("refresh_state_references.target_entity_ref", "=", currentRef).select({
        parentEntityRef: "refresh_state.entity_ref",
        parentEntityJson: "final_entities.final_entity"
      });
      const parentRefs = [];
      for (const { parentEntityRef, parentEntityJson } of parentRows) {
        parentRefs.push(parentEntityRef);
        if (!seenEntityRefs.has(parentEntityRef)) {
          seenEntityRefs.add(parentEntityRef);
          todo.push(JSON.parse(parentEntityJson));
        }
      }
      items.push({
        entity: current,
        parentEntityRefs: parentRefs
      });
    }
    return {
      rootEntityRef: catalogModel.stringifyEntityRef(rootEntity),
      items
    };
  }
  async facets(request) {
    const facets = {};
    const db = this.database;
    for (const facet of request.facets) {
      const dbQuery = db("search").where("search.key", facet.toLocaleLowerCase("en-US")).whereNotNull("search.original_value").select({ value: "search.original_value", count: db.raw("count(*)") }).groupBy("search.original_value");
      if (request == null ? void 0 : request.filter) {
        parseFilter(request.filter, dbQuery, db, false, "search.entity_id");
      }
      const result = await dbQuery;
      facets[facet] = result.map((data) => ({
        value: String(data.value),
        count: Number(data.count)
      }));
    }
    return { facets };
  }
}
const entityFilterParser = zod.z.lazy(
  () => zod.z.object({
    key: zod.z.string(),
    values: zod.z.array(zod.z.string()).optional()
  }).or(zod.z.object({ not: entityFilterParser })).or(zod.z.object({ anyOf: zod.z.array(entityFilterParser) })).or(zod.z.object({ allOf: zod.z.array(entityFilterParser) }))
);
zod.z.object({
  orderFields: zod.z.array(
    zod.z.object({ field: zod.z.string(), order: zod.z.enum(["asc", "desc"]) })
  ),
  orderFieldValues: zod.z.array(zod.z.string().or(zod.z.null())),
  filter: entityFilterParser.optional(),
  isPrevious: zod.z.boolean(),
  query: zod.z.string().optional(),
  firstSortFieldValues: zod.z.array(zod.z.string().or(zod.z.null())).optional(),
  totalItems: zod.z.number().optional()
});
function parseCursorFromRequest(request) {
  if (isQueryEntitiesInitialRequest(request)) {
    const {
      filter,
      orderFields: sortFields = [defaultSortField],
      fullTextFilter
    } = request;
    return { filter, orderFields: sortFields, fullTextFilter };
  }
  if (isQueryEntitiesCursorRequest(request)) {
    return request.cursor;
  }
  return {};
}
function invertOrder(order) {
  return order === "asc" ? "desc" : "asc";
}
function sortFieldsFromRow(row) {
  return [row.value, row.entity_id];
}

var __defProp$6 = Object.defineProperty;
var __defNormalProp$6 = (obj, key, value) => key in obj ? __defProp$6(obj, key, { enumerable: true, configurable: true, writable: true, value }) : obj[key] = value;
var __publicField$6 = (obj, key, value) => {
  __defNormalProp$6(obj, typeof key !== "symbol" ? key + "" : key, value);
  return value;
};
class ProcessorOutputCollector {
  constructor(logger, parentEntity) {
    this.logger = logger;
    this.parentEntity = parentEntity;
    __publicField$6(this, "errors", new Array());
    __publicField$6(this, "relations", new Array());
    __publicField$6(this, "deferredEntities", new Array());
    __publicField$6(this, "refreshKeys", new Array());
    __publicField$6(this, "done", false);
  }
  generic() {
    return (i) => this.receive(this.logger, i);
  }
  forProcessor(processor) {
    const logger = this.logger.child({
      processor: processor.getProcessorName()
    });
    return (i) => this.receive(logger, i);
  }
  results() {
    this.done = true;
    return {
      errors: this.errors,
      relations: this.relations,
      refreshKeys: this.refreshKeys,
      deferredEntities: this.deferredEntities
    };
  }
  receive(logger, i) {
    if (this.done) {
      logger.warn(
        `Item of type "${i.type}" was emitted after processing had completed. Stack trace: ${new Error().stack}`
      );
      return;
    }
    if (i.type === "entity") {
      let entity;
      const location = catalogModel.stringifyLocationRef(i.location);
      try {
        entity = validateEntityEnvelope(i.entity);
      } catch (e) {
        errors.assertError(e);
        logger.debug(`Envelope validation failed at ${location}, ${e}`);
        this.errors.push(e);
        return;
      }
      const entityRef = catalogModel.stringifyEntityRef(entity);
      if (entityRef === catalogModel.stringifyEntityRef(this.parentEntity)) {
        logger.warn(
          `Ignored emitted entity ${entityRef} whose ref was identical to the one being processed. This commonly indicates mistakenly emitting the input entity instead of returning it.`
        );
        return;
      }
      const annotations = entity.metadata.annotations || {};
      if (typeof annotations === "object" && !Array.isArray(annotations)) {
        const originLocation = getEntityOriginLocationRef(this.parentEntity);
        entity = {
          ...entity,
          metadata: {
            ...entity.metadata,
            annotations: {
              ...annotations,
              [catalogModel.ANNOTATION_ORIGIN_LOCATION]: originLocation,
              [catalogModel.ANNOTATION_LOCATION]: location
            }
          }
        };
      }
      this.deferredEntities.push({ entity, locationKey: location });
    } else if (i.type === "location") {
      const entity = locationSpecToLocationEntity({
        location: i.location,
        parentEntity: this.parentEntity
      });
      const locationKey = getEntityLocationRef(entity);
      this.deferredEntities.push({ entity, locationKey });
    } else if (i.type === "relation") {
      this.relations.push(i.relation);
    } else if (i.type === "error") {
      this.errors.push(i.error);
    } else if (i.type === "refresh") {
      this.refreshKeys.push({ key: i.key });
    }
  }
}

var __defProp$5 = Object.defineProperty;
var __defNormalProp$5 = (obj, key, value) => key in obj ? __defProp$5(obj, key, { enumerable: true, configurable: true, writable: true, value }) : obj[key] = value;
var __publicField$5 = (obj, key, value) => {
  __defNormalProp$5(obj, typeof key !== "symbol" ? key + "" : key, value);
  return value;
};
class SingleProcessorSubCache {
  constructor(existingState) {
    this.existingState = existingState;
    __publicField$5(this, "newState");
  }
  async get(key) {
    var _a;
    return (_a = this.existingState) == null ? void 0 : _a[key];
  }
  async set(key, value) {
    if (!this.newState) {
      this.newState = {};
    }
    this.newState[key] = value;
  }
  collect() {
    var _a;
    return (_a = this.newState) != null ? _a : this.existingState;
  }
}
class SingleProcessorCache {
  constructor(existingState) {
    this.existingState = existingState;
    __publicField$5(this, "newState");
    __publicField$5(this, "subCaches", /* @__PURE__ */ new Map());
  }
  async get(key) {
    var _a;
    return (_a = this.existingState) == null ? void 0 : _a[key];
  }
  async set(key, value) {
    if (!this.newState) {
      this.newState = {};
    }
    this.newState[key] = value;
  }
  withKey(key) {
    var _a;
    const existingSubCache = this.subCaches.get(key);
    if (existingSubCache) {
      return existingSubCache;
    }
    const existing = (_a = this.existingState) == null ? void 0 : _a[key];
    const subCache = new SingleProcessorSubCache(
      isObject(existing) ? existing : void 0
    );
    this.subCaches.set(key, subCache);
    return subCache;
  }
  collect() {
    var _a;
    let obj = (_a = this.newState) != null ? _a : this.existingState;
    for (const [key, subCache] of this.subCaches) {
      const subCacheValue = subCache.collect();
      if (subCacheValue) {
        obj = { ...obj, [key]: subCacheValue };
      }
    }
    return obj;
  }
}
class ProcessorCacheManager {
  constructor(existingState) {
    this.existingState = existingState;
    __publicField$5(this, "caches", /* @__PURE__ */ new Map());
  }
  forProcessor(processor, key) {
    const name = processor.getProcessorName();
    const cache = this.caches.get(name);
    if (cache) {
      return key ? cache.withKey(key) : cache;
    }
    const existing = this.existingState[name];
    const newCache = new SingleProcessorCache(
      isObject(existing) ? existing : void 0
    );
    this.caches.set(name, newCache);
    return key ? newCache.withKey(key) : newCache;
  }
  collect() {
    const result = {};
    for (const [key, value] of this.caches.entries()) {
      result[key] = value.collect();
    }
    return result;
  }
}

const tracer = api.trace.getTracer(TRACER_ID);
function addProcessorAttributes(span, stage, processor) {
  span.setAttribute("backstage.catalog.processor.stage", stage);
  span.setAttribute(
    "backstage.catalog.processor.name",
    processor.getProcessorName()
  );
}
class DefaultCatalogProcessingOrchestrator {
  constructor(options) {
    this.options = options;
  }
  async process(request) {
    return this.processSingleEntity(request.entity, request.state);
  }
  async processSingleEntity(unprocessedEntity, state) {
    const collector = new ProcessorOutputCollector(
      this.options.logger,
      unprocessedEntity
    );
    const cache = new ProcessorCacheManager(
      isObject(state) && isObject(state.cache) ? state.cache : {}
    );
    try {
      let entity = unprocessedEntity;
      try {
        validateEntityEnvelope(entity);
      } catch (e) {
        throw new errors.InputError(
          `Entity envelope failed validation before processing`,
          e
        );
      }
      const context = {
        entityRef: catalogModel.stringifyEntityRef(entity),
        location: catalogModel.parseLocationRef(getEntityLocationRef(entity)),
        originLocation: catalogModel.parseLocationRef(getEntityOriginLocationRef(entity)),
        cache,
        collector
      };
      entity = await this.runPreProcessStep(entity, context);
      entity = await this.runPolicyStep(entity);
      await this.runValidateStep(entity, context);
      if (isLocationEntity(entity)) {
        await this.runSpecialLocationStep(entity, context);
      }
      entity = await this.runPostProcessStep(entity, context);
      const collectorResults = context.collector.results();
      for (const deferredEntity of collectorResults.deferredEntities) {
        if (!this.options.rulesEnforcer.isAllowed(
          deferredEntity.entity,
          context.originLocation
        )) {
          throw new errors.NotAllowedError(
            `Entity ${catalogModel.stringifyEntityRef(
              deferredEntity.entity
            )} at ${catalogModel.stringifyLocationRef(
              context.location
            )}, originated at ${catalogModel.stringifyLocationRef(
              context.originLocation
            )}, is not of an allowed kind for that location`
          );
        }
      }
      return {
        ...collectorResults,
        completedEntity: entity,
        state: { cache: cache.collect() },
        ok: collectorResults.errors.length === 0
      };
    } catch (error) {
      errors.assertError(error);
      return {
        ok: false,
        errors: collector.results().errors.concat(error)
      };
    }
  }
  // Pre-process phase, used to populate entities with data that is required
  // during the main processing step
  async runPreProcessStep(entity, context) {
    return await withActiveSpan(tracer, "ProcessingStage", async (stageSpan) => {
      addEntityAttributes(stageSpan, entity);
      stageSpan.setAttribute("backstage.catalog.processor.stage", "preProcess");
      let res = entity;
      for (const processor of this.options.processors) {
        if (processor.preProcessEntity) {
          let innerRes = res;
          res = await withActiveSpan(tracer, "ProcessingStep", async (span) => {
            addEntityAttributes(span, entity);
            addProcessorAttributes(span, "preProcessEntity", processor);
            try {
              innerRes = await processor.preProcessEntity(
                innerRes,
                context.location,
                context.collector.forProcessor(processor),
                context.originLocation,
                context.cache.forProcessor(processor)
              );
            } catch (e) {
              throw new errors.InputError(
                `Processor ${processor.constructor.name} threw an error while preprocessing`,
                e
              );
            }
            return innerRes;
          });
        }
      }
      return res;
    });
  }
  /**
   * Enforce entity policies making sure that entities conform to a general schema
   */
  async runPolicyStep(entity) {
    return await withActiveSpan(tracer, "ProcessingStage", async (stageSpan) => {
      addEntityAttributes(stageSpan, entity);
      stageSpan.setAttribute(
        "backstage.catalog.processor.stage",
        "enforcePolicy"
      );
      let policyEnforcedEntity;
      try {
        policyEnforcedEntity = await this.options.policy.enforce(entity);
      } catch (e) {
        throw new errors.InputError(
          `Policy check failed for ${catalogModel.stringifyEntityRef(entity)}`,
          e
        );
      }
      if (!policyEnforcedEntity) {
        throw new Error(
          `Policy unexpectedly returned no data for ${catalogModel.stringifyEntityRef(
            entity
          )}`
        );
      }
      return policyEnforcedEntity;
    });
  }
  /**
   * Validate the given entity
   */
  async runValidateStep(entity, context) {
    return await withActiveSpan(tracer, "ProcessingStage", async (stageSpan) => {
      addEntityAttributes(stageSpan, entity);
      stageSpan.setAttribute("backstage.catalog.processor.stage", "validate");
      if (catalogModel.stringifyEntityRef(entity) !== context.entityRef) {
        throw new errors.ConflictError(
          "Fatal: The entity kind, namespace, or name changed during processing"
        );
      }
      try {
        validateEntity(entity);
      } catch (e) {
        throw new errors.ConflictError(
          `Entity envelope for ${context.entityRef} failed validation after preprocessing`,
          e
        );
      }
      let valid = false;
      for (const processor of this.options.processors) {
        if (processor.validateEntityKind) {
          try {
            const thisValid = await withActiveSpan(
              tracer,
              "ProcessingStep",
              async (span) => {
                addEntityAttributes(span, entity);
                addProcessorAttributes(span, "validateEntityKind", processor);
                return await processor.validateEntityKind(entity);
              }
            );
            if (thisValid) {
              valid = true;
              if (this.options.legacySingleProcessorValidation) {
                break;
              }
            }
          } catch (e) {
            throw new errors.InputError(
              `Processor ${processor.constructor.name} threw an error while validating the entity ${context.entityRef}`,
              e
            );
          }
        }
      }
      if (!valid) {
        throw new errors.InputError(
          `No processor recognized the entity ${context.entityRef} as valid, possibly caused by a foreign kind or apiVersion`
        );
      }
    });
  }
  /**
   * Backwards compatible processing of location entities
   */
  async runSpecialLocationStep(entity, context) {
    return await withActiveSpan(tracer, "ProcessingStage", async (stageSpan) => {
      addEntityAttributes(stageSpan, entity);
      stageSpan.setAttribute(
        "backstage.catalog.processor.stage",
        "readLocation"
      );
      const { type = context.location.type, presence = "required" } = entity.spec;
      const targets = new Array();
      if (entity.spec.target) {
        targets.push(entity.spec.target);
      }
      if (entity.spec.targets) {
        targets.push(...entity.spec.targets);
      }
      for (const maybeRelativeTarget of targets) {
        if (type === "file" && maybeRelativeTarget.endsWith(path__default["default"].sep)) {
          context.collector.generic()(
            pluginCatalogNode.processingResult.inputError(
              context.location,
              `LocationEntityProcessor cannot handle ${type} type location with target ${context.location.target} that ends with a path separator`
            )
          );
          continue;
        }
        const target = toAbsoluteUrl(
          this.options.integrations,
          context.location,
          type,
          maybeRelativeTarget
        );
        let didRead = false;
        for (const processor of this.options.processors) {
          if (processor.readLocation) {
            try {
              const read = await withActiveSpan(
                tracer,
                "ProcessingStep",
                async (span) => {
                  addEntityAttributes(span, entity);
                  addProcessorAttributes(span, "readLocation", processor);
                  return await processor.readLocation(
                    {
                      type,
                      target,
                      presence
                    },
                    presence === "optional",
                    context.collector.forProcessor(processor),
                    this.options.parser,
                    context.cache.forProcessor(processor, target)
                  );
                }
              );
              if (read) {
                didRead = true;
                break;
              }
            } catch (e) {
              throw new errors.InputError(
                `Processor ${processor.constructor.name} threw an error while reading ${type}:${target}`,
                e
              );
            }
          }
        }
        if (!didRead) {
          throw new errors.InputError(
            `No processor was able to handle reading of ${type}:${target}`
          );
        }
      }
    });
  }
  /**
   * Main processing step of the entity
   */
  async runPostProcessStep(entity, context) {
    return await withActiveSpan(tracer, "ProcessingStage", async (stageSpan) => {
      addEntityAttributes(stageSpan, entity);
      stageSpan.setAttribute(
        "backstage.catalog.processor.stage",
        "postProcessEntity"
      );
      let res = entity;
      for (const processor of this.options.processors) {
        if (processor.postProcessEntity) {
          let innerRes = res;
          res = await withActiveSpan(tracer, "ProcessingStep", async (span) => {
            addEntityAttributes(span, entity);
            addProcessorAttributes(span, "postProcessEntity", processor);
            try {
              innerRes = await processor.postProcessEntity(
                innerRes,
                context.location,
                context.collector.forProcessor(processor),
                context.cache.forProcessor(processor)
              );
            } catch (e) {
              throw new errors.InputError(
                `Processor ${processor.constructor.name} threw an error while postprocessing`,
                e
              );
            }
            return innerRes;
          });
        }
      }
      return res;
    });
  }
}

async function getDeferredStitchableEntities(options) {
  const { knex, batchSize, stitchTimeout } = options;
  let itemsQuery = knex("refresh_state").select(
    "entity_ref",
    "next_stitch_at",
    "next_stitch_ticket"
  );
  if (["mysql", "mysql2", "pg"].includes(knex.client.config.client)) {
    itemsQuery = itemsQuery.forUpdate().skipLocked();
  }
  const items = await itemsQuery.whereNotNull("next_stitch_at").whereNotNull("next_stitch_ticket").where("next_stitch_at", "<=", knex.fn.now()).orderBy("next_stitch_at", "asc").limit(batchSize);
  if (!items.length) {
    return [];
  }
  await knex("refresh_state").whereIn(
    "entity_ref",
    items.map((i) => i.entity_ref)
  ).whereNotNull("next_stitch_ticket").update({
    next_stitch_at: nowPlus(knex, stitchTimeout)
  });
  return items.map((i) => ({
    entityRef: i.entity_ref,
    stitchTicket: i.next_stitch_ticket,
    stitchRequestedAt: timestampToDateTime(i.next_stitch_at)
  }));
}
function nowPlus(knex, duration) {
  const seconds = types.durationToMilliseconds(duration) / 1e3;
  if (knex.client.config.client.includes("sqlite3")) {
    return knex.raw(`datetime('now', ?)`, [`${seconds} seconds`]);
  } else if (knex.client.config.client.includes("mysql")) {
    return knex.raw(`now() + interval ${seconds} second`);
  }
  return knex.raw(`now() + interval '${seconds} seconds'`);
}

const SPECIAL_KEYS = [
  "attachments",
  "relations",
  "status",
  "metadata.name",
  "metadata.namespace",
  "metadata.uid",
  "metadata.etag"
];
const MAX_KEY_LENGTH = 200;
const MAX_VALUE_LENGTH = 200;
function traverse(root) {
  const output = [];
  function visit(path, current) {
    if (SPECIAL_KEYS.includes(path)) {
      return;
    }
    if (current === void 0 || current === null || ["string", "number", "boolean"].includes(typeof current)) {
      output.push({ key: path, value: current });
      return;
    }
    if (typeof current !== "object") {
      return;
    }
    if (Array.isArray(current)) {
      for (const item of current) {
        visit(path, item);
        if (typeof item === "string") {
          output.push({ key: `${path}.${item}`, value: true });
        }
      }
      return;
    }
    for (const [key, value] of Object.entries(current)) {
      visit(path ? `${path}.${key}` : key, value);
    }
  }
  visit("", root);
  return output;
}
function mapToRows(input, entityId) {
  const result = [];
  for (const { key: rawKey, value: rawValue } of input) {
    const key = rawKey.toLocaleLowerCase("en-US");
    if (rawValue === void 0 || rawValue === null) {
      result.push({
        entity_id: entityId,
        key,
        original_value: null,
        value: null
      });
    } else {
      const value = String(rawValue).toLocaleLowerCase("en-US");
      if (key.length <= MAX_KEY_LENGTH) {
        if (value.length <= MAX_VALUE_LENGTH) {
          result.push({
            entity_id: entityId,
            key,
            original_value: String(rawValue),
            value
          });
        } else {
          result.push({
            entity_id: entityId,
            key,
            original_value: null,
            value: null
          });
        }
      }
    }
  }
  return result;
}
function buildEntitySearch(entityId, entity) {
  var _a;
  const raw = traverse(entity);
  raw.push({ key: "metadata.name", value: entity.metadata.name });
  raw.push({ key: "metadata.namespace", value: entity.metadata.namespace });
  raw.push({ key: "metadata.uid", value: entity.metadata.uid });
  if (!entity.metadata.namespace) {
    raw.push({ key: "metadata.namespace", value: catalogModel.DEFAULT_NAMESPACE });
  }
  for (const relation of (_a = entity.relations) != null ? _a : []) {
    raw.push({
      key: `relations.${relation.type}`,
      value: relation.targetRef
    });
  }
  const keys = new Set(raw.map((r) => r.key));
  const lowerKeys = new Set(raw.map((r) => r.key.toLocaleLowerCase("en-US")));
  if (keys.size !== lowerKeys.size) {
    const difference = [];
    for (const key of keys) {
      const lower = key.toLocaleLowerCase("en-US");
      if (!lowerKeys.delete(lower)) {
        difference.push(lower);
      }
    }
    const badKeys = `'${difference.join("', '")}'`;
    throw new errors.InputError(
      `Entity has duplicate keys that vary only in casing, ${badKeys}`
    );
  }
  return mapToRows(raw, entityId);
}

async function markDeferredStitchCompleted(option) {
  const { knex, entityRef, stitchTicket } = option;
  await knex("refresh_state").update({
    next_stitch_at: null,
    next_stitch_ticket: null
  }).where("entity_ref", "=", entityRef).andWhere("next_stitch_ticket", "=", stitchTicket);
}

const BATCH_SIZE$1 = 50;
function generateStableHash(entity) {
  return crypto.createHash("sha1").update(stableStringify__default["default"]({ ...entity })).digest("hex");
}

const scriptProtocolPattern = (
  // eslint-disable-next-line no-control-regex
  /^[\u0000-\u001F ]*j[\r\n\t]*a[\r\n\t]*v[\r\n\t]*a[\r\n\t]*s[\r\n\t]*c[\r\n\t]*r[\r\n\t]*i[\r\n\t]*p[\r\n\t]*t[\r\n\t]*\:/i
);
async function performStitching(options) {
  var _a, _b, _c, _d;
  const { knex, logger, entityRef } = options;
  const stitchTicket = (_a = options.stitchTicket) != null ? _a : uuid.v4();
  const entityResult = await knex("refresh_state").where({ entity_ref: entityRef }).limit(1).select("entity_id");
  if (!entityResult.length) {
    return "abandoned";
  }
  await knex("final_entities").insert({
    entity_id: entityResult[0].entity_id,
    hash: "",
    stitch_ticket: stitchTicket
  }).onConflict("entity_id").merge(["stitch_ticket"]);
  const [processedResult, relationsResult] = await Promise.all([
    knex.with("incoming_references", function incomingReferences(builder) {
      return builder.from("refresh_state_references").where({ target_entity_ref: entityRef }).count({ count: "*" });
    }).select({
      entityId: "refresh_state.entity_id",
      processedEntity: "refresh_state.processed_entity",
      errors: "refresh_state.errors",
      incomingReferenceCount: "incoming_references.count",
      previousHash: "final_entities.hash"
    }).from("refresh_state").where({ "refresh_state.entity_ref": entityRef }).crossJoin(knex.raw("incoming_references")).leftOuterJoin("final_entities", {
      "final_entities.entity_id": "refresh_state.entity_id"
    }),
    knex.distinct({
      relationType: "type",
      relationTarget: "target_entity_ref"
    }).from("relations").where({ source_entity_ref: entityRef }).orderBy("relationType", "asc").orderBy("relationTarget", "asc")
  ]);
  if (!processedResult.length) {
    logger.debug(
      `Unable to stitch ${entityRef}, item does not exist in refresh state table`
    );
    return "abandoned";
  }
  const {
    entityId,
    processedEntity,
    errors,
    incomingReferenceCount,
    previousHash
  } = processedResult[0];
  if (!processedEntity) {
    logger.debug(
      `Unable to stitch ${entityRef}, the entity has not yet been processed`
    );
    return "abandoned";
  }
  const entity = JSON.parse(processedEntity);
  const isOrphan = Number(incomingReferenceCount) === 0;
  let statusItems = [];
  if (isOrphan) {
    logger.debug(`${entityRef} is an orphan`);
    entity.metadata.annotations = {
      ...entity.metadata.annotations,
      ["backstage.io/orphan"]: "true"
    };
  }
  if (errors) {
    const parsedErrors = JSON.parse(errors);
    if (Array.isArray(parsedErrors) && parsedErrors.length) {
      statusItems = parsedErrors.map((e) => ({
        type: catalogClient.ENTITY_STATUS_CATALOG_PROCESSING_TYPE,
        level: "error",
        message: `${e.name}: ${e.message}`,
        error: e
      }));
    }
  }
  for (const annotation of [catalogModel.ANNOTATION_VIEW_URL, catalogModel.ANNOTATION_EDIT_URL]) {
    const value = (_b = entity.metadata.annotations) == null ? void 0 : _b[annotation];
    if (typeof value === "string" && scriptProtocolPattern.test(value)) {
      entity.metadata.annotations[annotation] = "https://backstage.io/annotation-rejected-for-security-reasons";
    }
  }
  entity.relations = relationsResult.filter(
    (row) => row.relationType
    /* exclude null row, if relevant */
  ).map((row) => ({
    type: row.relationType,
    targetRef: row.relationTarget
  }));
  if (statusItems.length) {
    entity.status = {
      ...entity.status,
      items: [...(_d = (_c = entity.status) == null ? void 0 : _c.items) != null ? _d : [], ...statusItems]
    };
  }
  const hash = generateStableHash(entity);
  if (hash === previousHash) {
    logger.debug(`Skipped stitching of ${entityRef}, no changes`);
    return "unchanged";
  }
  entity.metadata.uid = entityId;
  if (!entity.metadata.etag) {
    entity.metadata.etag = hash;
  }
  const searchEntries = buildEntitySearch(entityId, entity);
  const amountOfRowsChanged = await knex("final_entities").update({
    final_entity: JSON.stringify(entity),
    hash,
    last_updated_at: knex.fn.now()
  }).where("entity_id", entityId).where("stitch_ticket", stitchTicket).onConflict("entity_id").merge(["final_entity", "hash", "last_updated_at"]);
  if (options.strategy.mode === "deferred") {
    await markDeferredStitchCompleted({
      knex,
      entityRef,
      stitchTicket
    });
  }
  if (amountOfRowsChanged === 0) {
    logger.debug(`Entity ${entityRef} is already stitched, skipping write.`);
    return "abandoned";
  }
  await knex("search").where({ entity_id: entityId }).delete();
  await knex.batchInsert("search", searchEntries, BATCH_SIZE$1);
  return "changed";
}

function progressTracker(knex, logger) {
  const promStitchedEntities = createCounterMetric({
    name: "catalog_stitched_entities_count",
    help: "Amount of entities stitched. DEPRECATED, use OpenTelemetry metrics instead"
  });
  const meter = api.metrics.getMeter("default");
  const stitchedEntities = meter.createCounter(
    "catalog.stitched.entities.count",
    {
      description: "Amount of entities stitched"
    }
  );
  const stitchingDuration = meter.createHistogram(
    "catalog.stitching.duration",
    {
      description: "Time spent executing the full stitching flow",
      unit: "seconds"
    }
  );
  const stitchingQueueCount = meter.createObservableGauge(
    "catalog.stitching.queue.length",
    { description: "Number of entities currently in the stitching queue" }
  );
  stitchingQueueCount.addCallback(async (result) => {
    const total = await knex("refresh_state").count({ count: "*" }).whereNotNull("next_stitch_at");
    result.observe(Number(total[0].count));
  });
  const stitchingQueueDelay = meter.createHistogram(
    "catalog.stitching.queue.delay",
    {
      description: "The amount of delay between being scheduled for stitching, and the start of actually being stitched",
      unit: "seconds"
    }
  );
  function stitchStart(item) {
    logger.debug(`Stitching ${item.entityRef}`);
    const startTime = process.hrtime();
    if (item.stitchRequestedAt) {
      stitchingQueueDelay.record(
        -item.stitchRequestedAt.diffNow().as("seconds")
      );
    }
    function endTime() {
      const delta = process.hrtime(startTime);
      return delta[0] + delta[1] / 1e9;
    }
    function markComplete(result) {
      promStitchedEntities.inc(1);
      stitchedEntities.add(1, { result });
      stitchingDuration.record(endTime(), { result });
    }
    function markFailed(error) {
      promStitchedEntities.inc(1);
      stitchedEntities.add(1, { result: "error" });
      stitchingDuration.record(endTime(), { result: "error" });
      logger.error(
        `Failed to stitch ${item.entityRef}, ${errors.stringifyError(error)}`
      );
    }
    return {
      markComplete,
      markFailed
    };
  }
  return { stitchStart };
}

var __defProp$4 = Object.defineProperty;
var __defNormalProp$4 = (obj, key, value) => key in obj ? __defProp$4(obj, key, { enumerable: true, configurable: true, writable: true, value }) : obj[key] = value;
var __publicField$4 = (obj, key, value) => {
  __defNormalProp$4(obj, typeof key !== "symbol" ? key + "" : key, value);
  return value;
};
var __accessCheck = (obj, member, msg) => {
  if (!member.has(obj))
    throw TypeError("Cannot " + msg);
};
var __privateAdd = (obj, member, value) => {
  if (member.has(obj))
    throw TypeError("Cannot add the same private member more than once");
  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
};
var __privateMethod = (obj, member, method) => {
  __accessCheck(obj, member, "access private method");
  return method;
};
var _getStitchableEntities, getStitchableEntities_fn, _stitchOne, stitchOne_fn;
const _DefaultStitcher = class _DefaultStitcher {
  constructor(options) {
    __privateAdd(this, _getStitchableEntities);
    __privateAdd(this, _stitchOne);
    __publicField$4(this, "knex");
    __publicField$4(this, "logger");
    __publicField$4(this, "strategy");
    __publicField$4(this, "tracker");
    __publicField$4(this, "stopFunc");
    this.knex = options.knex;
    this.logger = options.logger;
    this.strategy = options.strategy;
    this.tracker = progressTracker(options.knex, options.logger);
  }
  static fromConfig(config, options) {
    return new _DefaultStitcher({
      knex: options.knex,
      logger: options.logger,
      strategy: stitchingStrategyFromConfig(config)
    });
  }
  async stitch(options) {
    const { entityRefs, entityIds } = options;
    if (this.strategy.mode === "deferred") {
      await markForStitching({
        knex: this.knex,
        strategy: this.strategy,
        entityRefs,
        entityIds
      });
      return;
    }
    if (entityRefs) {
      for (const entityRef of entityRefs) {
        await __privateMethod(this, _stitchOne, stitchOne_fn).call(this, { entityRef });
      }
    }
    if (entityIds) {
      const chunks = splitToChunks__default["default"](
        Array.isArray(entityIds) ? entityIds : [...entityIds],
        100
      );
      for (const chunk of chunks) {
        const rows = await this.knex("refresh_state").select("entity_ref").whereIn("entity_id", chunk);
        for (const row of rows) {
          await __privateMethod(this, _stitchOne, stitchOne_fn).call(this, { entityRef: row.entity_ref });
        }
      }
    }
  }
  async start() {
    if (this.strategy.mode === "deferred") {
      if (this.stopFunc) {
        throw new Error("Processing engine is already started");
      }
      const { pollingInterval, stitchTimeout } = this.strategy;
      const stopPipeline = startTaskPipeline({
        lowWatermark: 2,
        highWatermark: 5,
        pollingIntervalMs: types.durationToMilliseconds(pollingInterval),
        loadTasks: async (count) => {
          return await __privateMethod(this, _getStitchableEntities, getStitchableEntities_fn).call(this, count, stitchTimeout);
        },
        processTask: async (item) => {
          return await __privateMethod(this, _stitchOne, stitchOne_fn).call(this, {
            entityRef: item.entityRef,
            stitchTicket: item.stitchTicket,
            stitchRequestedAt: item.stitchRequestedAt
          });
        }
      });
      this.stopFunc = () => {
        stopPipeline();
      };
    }
  }
  async stop() {
    if (this.strategy.mode === "deferred") {
      if (this.stopFunc) {
        this.stopFunc();
        this.stopFunc = void 0;
      }
    }
  }
};
_getStitchableEntities = new WeakSet();
getStitchableEntities_fn = async function(count, stitchTimeout) {
  try {
    return await getDeferredStitchableEntities({
      knex: this.knex,
      batchSize: count,
      stitchTimeout
    });
  } catch (error) {
    this.logger.warn("Failed to load stitchable entities", error);
    return [];
  }
};
_stitchOne = new WeakSet();
stitchOne_fn = async function(options) {
  const track = this.tracker.stitchStart({
    entityRef: options.entityRef,
    stitchRequestedAt: options.stitchRequestedAt
  });
  try {
    const result = await performStitching({
      knex: this.knex,
      logger: this.logger,
      strategy: this.strategy,
      entityRef: options.entityRef,
      stitchTicket: options.stitchTicket
    });
    track.markComplete(result);
  } catch (error) {
    track.markFailed(error);
  }
};
let DefaultStitcher = _DefaultStitcher;

const schema = zod.z.object({
  entityRefs: zod.z.array(zod.z.string()),
  fields: zod.z.array(zod.z.string()).optional()
});
function entitiesBatchRequest(req) {
  try {
    return schema.parse(req.body);
  } catch (error) {
    throw new errors.InputError(
      `Malformed request body (did you remember to specify an application/json content type?), ${error.message}`
    );
  }
}

function basicEntityFilter(items) {
  const filtersByKey = {};
  for (const [key, value] of Object.entries(items)) {
    const values = [value].flat();
    const f = key in filtersByKey ? filtersByKey[key] : filtersByKey[key] = { key, values: [] };
    f.values.push(...values);
  }
  return { anyOf: [{ allOf: Object.values(filtersByKey) }] };
}

function parseStringsParam(param, ctx) {
  if (param === void 0) {
    return void 0;
  }
  const array = [param].flat();
  if (array.some((p) => typeof p !== "string")) {
    throw new errors.InputError(`Invalid ${ctx}, not a string`);
  }
  return array;
}

function parseEntityFilterParams(params) {
  const filterStrings = parseStringsParam(params.filter, "filter");
  if (!filterStrings) {
    return void 0;
  }
  const filters = filterStrings.map(parseEntityFilterString).filter(Boolean);
  if (!filters.length) {
    return void 0;
  }
  return { anyOf: filters.map((f) => ({ allOf: f })) };
}
function parseEntityFilterString(filterString) {
  const statements = filterString.split(",").map((s) => s.trim()).filter(Boolean);
  if (!statements.length) {
    return void 0;
  }
  const filtersByKey = {};
  for (const statement of statements) {
    const equalsIndex = statement.indexOf("=");
    const key = equalsIndex === -1 ? statement : statement.substring(0, equalsIndex).trim();
    const value = equalsIndex === -1 ? void 0 : statement.substring(equalsIndex + 1).trim();
    if (!key) {
      throw new errors.InputError(
        `Invalid filter, '${statement}' is not a valid statement (expected a string on the form a=b or a= or a)`
      );
    }
    const f = key in filtersByKey ? filtersByKey[key] : filtersByKey[key] = { key };
    if (value !== void 0) {
      f.values = f.values || [];
      f.values.push(value);
    }
  }
  return Object.values(filtersByKey);
}

function getPathArrayAndValue(input, field) {
  return field.split(".").reduce(
    ([pathArray, inputSubset], pathPart, index, fieldParts) => {
      if (lodash__default["default"].hasIn(inputSubset, pathPart)) {
        return [pathArray.concat(pathPart), inputSubset[pathPart]];
      } else if (fieldParts[index + 1] !== void 0) {
        fieldParts[index + 1] = `${pathPart}.${fieldParts[index + 1]}`;
        return [pathArray, inputSubset];
      }
      return [pathArray, void 0];
    },
    [[], input]
  );
}
function parseEntityTransformParams(params, extra) {
  var _a;
  const queryFields = parseStringsParam(params.fields, "fields");
  const fields = Array.from(
    new Set(
      [...extra != null ? extra : [], ...(_a = queryFields == null ? void 0 : queryFields.map((s) => s.split(","))) != null ? _a : []].flat().map((s) => s.trim()).filter(Boolean)
    )
  );
  if (!fields.length) {
    return void 0;
  }
  const arrayTypeField = fields.find((f) => f.includes("["));
  if (arrayTypeField) {
    throw new errors.InputError(
      `Invalid field "${arrayTypeField}", array type fields are not supported`
    );
  }
  return (input) => {
    const output = {};
    for (const field of fields) {
      const [pathArray, value] = getPathArrayAndValue(input, field);
      if (value !== void 0) {
        lodash__default["default"].set(output, pathArray, value);
      }
    }
    return output;
  };
}

function parseEntityOrderFieldParams(params) {
  const orderFieldStrings = parseStringsParam(params.orderField, "orderField");
  if (!orderFieldStrings) {
    return void 0;
  }
  return orderFieldStrings.map((orderFieldString) => {
    const [field, order] = orderFieldString.split(",");
    if (order !== void 0 && !isOrder(order)) {
      throw new errors.InputError("Invalid order field order, must be asc or desc");
    }
    return { field, order };
  });
}
function isOrder(order) {
  return ["asc", "desc"].includes(order);
}

function parseQueryEntitiesParams(params) {
  const fields = parseEntityTransformParams(params);
  if (params.cursor) {
    const decodedCursor = decodeCursor(params.cursor);
    const response2 = {
      cursor: decodedCursor,
      fields
    };
    return response2;
  }
  const filter = parseEntityFilterParams(params);
  const orderFields = parseEntityOrderFieldParams(params);
  const response = {
    fields,
    filter,
    orderFields,
    fullTextFilter: {
      term: params.fullTextFilterTerm || "",
      fields: params.fullTextFilterFields
    }
  };
  return response;
}

function parseEntityFacetParams(params) {
  const facetStrings = parseStringsParam(params.facet, "facet");
  if (facetStrings) {
    const filtered = facetStrings.filter(Boolean);
    if (filtered.length) {
      return filtered;
    }
  }
  throw new errors.InputError("Missing facet parameter");
}

function parseEntityOrderParams(params) {
  var _a;
  return (_a = parseStringsParam(params.order, "order")) == null ? void 0 : _a.map((item) => {
    const match = item.match(/^(asc|desc):(.+)$/);
    if (!match) {
      throw new errors.InputError(
        `Invalid order parameter "${item}", expected "<asc or desc>:<field name>"`
      );
    }
    return {
      order: match[1],
      field: match[2]
    };
  });
}

const spec = {
  openapi: "3.0.3",
  info: {
    title: "catalog",
    version: "1",
    description: "The Backstage backend plugin that provides the Backstage catalog",
    license: {
      name: "Apache-2.0",
      url: "http://www.apache.org/licenses/LICENSE-2.0.html"
    },
    contact: {}
  },
  servers: [
    {
      url: "/"
    }
  ],
  components: {
    examples: {},
    headers: {},
    parameters: {
      kind: {
        name: "kind",
        in: "path",
        required: true,
        allowReserved: true,
        schema: {
          type: "string"
        }
      },
      namespace: {
        name: "namespace",
        in: "path",
        required: true,
        allowReserved: true,
        schema: {
          type: "string"
        }
      },
      name: {
        name: "name",
        in: "path",
        required: true,
        allowReserved: true,
        schema: {
          type: "string"
        }
      },
      uid: {
        name: "uid",
        in: "path",
        required: true,
        allowReserved: true,
        schema: {
          type: "string"
        }
      },
      cursor: {
        name: "cursor",
        in: "query",
        description: "Cursor to a set page of results.",
        required: false,
        allowReserved: true,
        schema: {
          type: "string",
          minLength: 1
        }
      },
      after: {
        name: "after",
        in: "query",
        description: "Pointer to the previous page of results.",
        required: false,
        allowReserved: true,
        schema: {
          type: "string",
          minLength: 1
        }
      },
      fields: {
        name: "fields",
        in: "query",
        description: "Restrict to just these fields in the response.",
        required: false,
        allowReserved: true,
        explode: false,
        schema: {
          type: "array",
          items: {
            type: "string"
          }
        },
        examples: {
          "Get name and the entire relations collection": {
            value: ["metadata.name", "relations"]
          },
          "Get kind, name and namespace": {
            value: ["kind", "metadata.name", "metadata.namespace"]
          }
        }
      },
      filter: {
        name: "filter",
        in: "query",
        description: "Filter for just the entities defined by this filter.",
        required: false,
        allowReserved: true,
        schema: {
          type: "array",
          items: {
            type: "string"
          }
        },
        examples: {
          "Get groups": {
            value: ["kind=group"]
          },
          "Get orphaned components": {
            value: [
              "kind=component,metadata.annotations.backstage.io/orphan=true"
            ]
          }
        }
      },
      offset: {
        name: "offset",
        in: "query",
        description: "Number of records to skip in the query page.",
        required: false,
        allowReserved: true,
        schema: {
          type: "integer",
          minimum: 0
        }
      },
      limit: {
        name: "limit",
        in: "query",
        description: "Number of records to return in the response.",
        required: false,
        allowReserved: true,
        schema: {
          type: "integer",
          minimum: 0
        }
      },
      orderField: {
        name: "orderField",
        in: "query",
        description: "The fields to sort returned results by.",
        required: false,
        allowReserved: true,
        schema: {
          type: "array",
          items: {
            type: "string",
            description: "A two-item tuple of [field, order]."
          }
        },
        explode: true,
        style: "form",
        examples: {
          "Order ascending by name": {
            value: ["metadata.name,asc"]
          },
          "Order descending by owner": {
            value: ["spec.owner,desc"]
          }
        }
      }
    },
    requestBodies: {},
    responses: {
      ErrorResponse: {
        description: "An error response from the backend.",
        content: {
          "application/json": {
            schema: {
              $ref: "#/components/schemas/Error"
            }
          }
        }
      }
    },
    schemas: {
      Error: {
        type: "object",
        properties: {
          error: {
            type: "object",
            properties: {
              name: {
                type: "string"
              },
              message: {
                type: "string"
              },
              stack: {
                type: "string"
              },
              code: {
                type: "string"
              }
            },
            required: ["name", "message"]
          },
          request: {
            type: "object",
            properties: {
              method: {
                type: "string"
              },
              url: {
                type: "string"
              }
            },
            required: ["method", "url"]
          },
          response: {
            type: "object",
            properties: {
              statusCode: {
                type: "number"
              }
            },
            required: ["statusCode"]
          }
        },
        required: ["error", "response"],
        additionalProperties: {}
      },
      JsonObject: {
        type: "object",
        properties: {},
        description: "A type representing all allowed JSON object values.",
        additionalProperties: {}
      },
      MapStringString: {
        type: "object",
        properties: {},
        additionalProperties: {
          type: "string"
        },
        description: "Construct a type with a set of properties K of type T"
      },
      EntityLink: {
        type: "object",
        properties: {
          type: {
            type: "string",
            description: "An optional value to categorize links into specific groups"
          },
          icon: {
            type: "string",
            description: "An optional semantic key that represents a visual icon."
          },
          title: {
            type: "string",
            description: "An optional descriptive title for the link."
          },
          url: {
            type: "string",
            description: "The url to the external site, document, etc."
          }
        },
        required: ["url"],
        description: "A link to external information that is related to the entity.",
        additionalProperties: false
      },
      EntityMeta: {
        type: "object",
        properties: {
          links: {
            type: "array",
            items: {
              $ref: "#/components/schemas/EntityLink"
            },
            description: "A list of external hyperlinks related to the entity."
          },
          tags: {
            type: "array",
            items: {
              type: "string"
            },
            description: "A list of single-valued strings, to for example classify catalog entities in\nvarious ways."
          },
          annotations: {
            $ref: "#/components/schemas/MapStringString"
          },
          labels: {
            $ref: "#/components/schemas/MapStringString"
          },
          description: {
            type: "string",
            description: "A short (typically relatively few words, on one line) description of the\nentity."
          },
          title: {
            type: "string",
            description: "A display name of the entity, to be presented in user interfaces instead\nof the `name` property above, when available.\nThis field is sometimes useful when the `name` is cumbersome or ends up\nbeing perceived as overly technical. The title generally does not have\nas stringent format requirements on it, so it may contain special\ncharacters and be more explanatory. Do keep it very short though, and\navoid situations where a title can be confused with the name of another\nentity, or where two entities share a title.\nNote that this is only for display purposes, and may be ignored by some\nparts of the code. Entity references still always make use of the `name`\nproperty, not the title."
          },
          namespace: {
            type: "string",
            description: "The namespace that the entity belongs to."
          },
          name: {
            type: "string",
            description: "The name of the entity.\nMust be unique within the catalog at any given point in time, for any\ngiven namespace + kind pair. This value is part of the technical\nidentifier of the entity, and as such it will appear in URLs, database\ntables, entity references, and similar. It is subject to restrictions\nregarding what characters are allowed.\nIf you want to use a different, more human readable string with fewer\nrestrictions on it in user interfaces, see the `title` field below."
          },
          etag: {
            type: "string",
            description: "An opaque string that changes for each update operation to any part of\nthe entity, including metadata.\nThis field can not be set by the user at creation time, and the server\nwill reject an attempt to do so. The field will be populated in read\noperations. The field can (optionally) be specified when performing\nupdate or delete operations, and the server will then reject the\noperation if it does not match the current stored value."
          },
          uid: {
            type: "string",
            description: "A globally unique ID for the entity.\nThis field can not be set by the user at creation time, and the server\nwill reject an attempt to do so. The field will be populated in read\noperations. The field can (optionally) be specified when performing\nupdate or delete operations, but the server is free to reject requests\nthat do so in such a way that it breaks semantics."
          }
        },
        required: ["name"],
        description: "Metadata fields common to all versions/kinds of entity.",
        additionalProperties: {}
      },
      EntityRelation: {
        type: "object",
        properties: {
          targetRef: {
            type: "string",
            description: "The entity ref of the target of this relation."
          },
          type: {
            type: "string",
            description: "The type of the relation."
          }
        },
        required: ["targetRef", "type"],
        description: "A relation of a specific type to another entity in the catalog.",
        additionalProperties: false
      },
      Entity: {
        type: "object",
        properties: {
          relations: {
            type: "array",
            items: {
              $ref: "#/components/schemas/EntityRelation"
            },
            description: "The relations that this entity has with other entities."
          },
          spec: {
            $ref: "#/components/schemas/JsonObject"
          },
          metadata: {
            $ref: "#/components/schemas/EntityMeta"
          },
          kind: {
            type: "string",
            description: "The high level entity type being described."
          },
          apiVersion: {
            type: "string",
            description: "The version of specification format for this particular entity that\nthis is written against."
          }
        },
        required: ["metadata", "kind", "apiVersion"],
        description: "The parts of the format that's common to all versions/kinds of entity."
      },
      NullableEntity: {
        type: "object",
        properties: {
          relations: {
            type: "array",
            items: {
              $ref: "#/components/schemas/EntityRelation"
            },
            description: "The relations that this entity has with other entities."
          },
          spec: {
            $ref: "#/components/schemas/JsonObject"
          },
          metadata: {
            $ref: "#/components/schemas/EntityMeta"
          },
          kind: {
            type: "string",
            description: "The high level entity type being described."
          },
          apiVersion: {
            type: "string",
            description: "The version of specification format for this particular entity that\nthis is written against."
          }
        },
        required: ["metadata", "kind", "apiVersion"],
        description: "The parts of the format that's common to all versions/kinds of entity.",
        nullable: true
      },
      EntityAncestryResponse: {
        type: "object",
        properties: {
          items: {
            type: "array",
            items: {
              type: "object",
              properties: {
                parentEntityRefs: {
                  items: {
                    type: "string"
                  },
                  type: "array"
                },
                entity: {
                  $ref: "#/components/schemas/Entity"
                }
              },
              required: ["parentEntityRefs", "entity"]
            }
          },
          rootEntityRef: {
            type: "string"
          }
        },
        required: ["items", "rootEntityRef"],
        additionalProperties: false
      },
      EntitiesBatchResponse: {
        type: "object",
        properties: {
          items: {
            type: "array",
            items: {
              $ref: "#/components/schemas/NullableEntity"
            },
            description: "The list of entities, in the same order as the refs in the request. Entries\nthat are null signify that no entity existed with that ref."
          }
        },
        required: ["items"],
        additionalProperties: false
      },
      EntityFacet: {
        type: "object",
        properties: {
          value: {
            type: "string"
          },
          count: {
            type: "number"
          }
        },
        required: ["value", "count"],
        additionalProperties: false
      },
      EntityFacetsResponse: {
        type: "object",
        properties: {
          facets: {
            type: "object",
            additionalProperties: {
              type: "array",
              items: {
                $ref: "#/components/schemas/EntityFacet"
              }
            }
          }
        },
        required: ["facets"],
        additionalProperties: false
      },
      Location: {
        type: "object",
        properties: {
          target: {
            type: "string"
          },
          type: {
            type: "string"
          },
          id: {
            type: "string"
          }
        },
        required: ["target", "type", "id"],
        description: "Entity location for a specific entity.",
        additionalProperties: false
      },
      LocationSpec: {
        type: "object",
        properties: {
          target: {
            type: "string"
          },
          type: {
            type: "string"
          }
        },
        required: ["target", "type"],
        description: "Holds the entity location information.",
        additionalProperties: false
      },
      AnalyzeLocationExistingEntity: {
        type: "object",
        properties: {
          entity: {
            $ref: "#/components/schemas/Entity"
          },
          isRegistered: {
            type: "boolean"
          },
          location: {
            $ref: "#/components/schemas/LocationSpec"
          }
        },
        required: ["entity", "isRegistered", "location"],
        description: "If the folder pointed to already contained catalog info yaml files, they are\nread and emitted like this so that the frontend can inform the user that it\nlocated them and can make sure to register them as well if they weren't\nalready",
        additionalProperties: false
      },
      RecursivePartialEntityRelation: {
        type: "object",
        properties: {
          targetRef: {
            type: "string",
            description: "The entity ref of the target of this relation."
          },
          type: {
            type: "string",
            description: "The type of the relation."
          }
        },
        description: "A relation of a specific type to another entity in the catalog.",
        additionalProperties: false
      },
      RecursivePartialEntityMeta: {
        allOf: [
          {
            $ref: "#/components/schemas/JsonObject"
          },
          {
            type: "object",
            properties: {
              links: {
                type: "array",
                items: {
                  $ref: "#/components/schemas/EntityLink"
                },
                description: "A list of external hyperlinks related to the entity."
              },
              tags: {
                type: "array",
                items: {
                  type: "string"
                },
                description: "A list of single-valued strings, to for example classify catalog entities in\nvarious ways."
              },
              annotations: {
                $ref: "#/components/schemas/MapStringString"
              },
              labels: {
                $ref: "#/components/schemas/MapStringString"
              },
              description: {
                type: "string",
                description: "A short (typically relatively few words, on one line) description of the\nentity."
              },
              title: {
                type: "string",
                description: "A display name of the entity, to be presented in user interfaces instead\nof the `name` property above, when available.\nThis field is sometimes useful when the `name` is cumbersome or ends up\nbeing perceived as overly technical. The title generally does not have\nas stringent format requirements on it, so it may contain special\ncharacters and be more explanatory. Do keep it very short though, and\navoid situations where a title can be confused with the name of another\nentity, or where two entities share a title.\nNote that this is only for display purposes, and may be ignored by some\nparts of the code. Entity references still always make use of the `name`\nproperty, not the title."
              },
              namespace: {
                type: "string",
                description: "The namespace that the entity belongs to."
              },
              name: {
                type: "string",
                description: "The name of the entity.\nMust be unique within the catalog at any given point in time, for any\ngiven namespace + kind pair. This value is part of the technical\nidentifier of the entity, and as such it will appear in URLs, database\ntables, entity references, and similar. It is subject to restrictions\nregarding what characters are allowed.\nIf you want to use a different, more human readable string with fewer\nrestrictions on it in user interfaces, see the `title` field below."
              },
              etag: {
                type: "string",
                description: "An opaque string that changes for each update operation to any part of\nthe entity, including metadata.\nThis field can not be set by the user at creation time, and the server\nwill reject an attempt to do so. The field will be populated in read\noperations. The field can (optionally) be specified when performing\nupdate or delete operations, and the server will then reject the\noperation if it does not match the current stored value."
              },
              uid: {
                type: "string",
                description: "A globally unique ID for the entity.\nThis field can not be set by the user at creation time, and the server\nwill reject an attempt to do so. The field will be populated in read\noperations. The field can (optionally) be specified when performing\nupdate or delete operations, but the server is free to reject requests\nthat do so in such a way that it breaks semantics."
              }
            },
            description: "Metadata fields common to all versions/kinds of entity."
          }
        ],
        additionalProperties: false
      },
      RecursivePartialEntity: {
        type: "object",
        properties: {
          apiVersion: {
            type: "string",
            description: "The version of specification format for this particular entity that\nthis is written against."
          },
          kind: {
            type: "string",
            description: "The high level entity type being described."
          },
          metadata: {
            $ref: "#/components/schemas/RecursivePartialEntityMeta"
          },
          spec: {
            $ref: "#/components/schemas/JsonObject"
          },
          relations: {
            type: "array",
            items: {
              $ref: "#/components/schemas/RecursivePartialEntityRelation"
            },
            description: "The relations that this entity has with other entities."
          }
        },
        description: "Makes all keys of an entire hierarchy optional.",
        additionalProperties: false
      },
      AnalyzeLocationEntityField: {
        type: "object",
        properties: {
          description: {
            type: "string",
            description: 'A text to show to the user to inform about the choices made. Like, it could say\n"Found a CODEOWNERS file that covers this target, so we suggest leaving this\nfield empty; which would currently make it owned by X" where X is taken from the\ncodeowners file.'
          },
          value: {
            type: "string",
            nullable: true
          },
          state: {
            type: "string",
            enum: [
              "analysisSuggestedValue",
              "analysisSuggestedNoValue",
              "needsUserInput"
            ],
            description: "The outcome of the analysis for this particular field"
          },
          field: {
            type: "string",
            description: 'e.g. "spec.owner"? The frontend needs to know how to "inject" the field into the\nentity again if the user wants to change it'
          }
        },
        required: ["description", "value", "state", "field"],
        additionalProperties: false
      },
      AnalyzeLocationGenerateEntity: {
        type: "object",
        properties: {
          fields: {
            type: "array",
            items: {
              $ref: "#/components/schemas/AnalyzeLocationEntityField"
            }
          },
          entity: {
            $ref: "#/components/schemas/RecursivePartialEntity"
          }
        },
        required: ["fields", "entity"],
        description: "This is some form of representation of what the analyzer could deduce.\nWe should probably have a chat about how this can best be conveyed to\nthe frontend. It'll probably contain a (possibly incomplete) entity, plus\nenough info for the frontend to know what form data to show to the user\nfor overriding/completing the info.",
        additionalProperties: false
      },
      AnalyzeLocationResponse: {
        type: "object",
        properties: {
          generateEntities: {
            items: {
              $ref: "#/components/schemas/AnalyzeLocationGenerateEntity"
            },
            type: "array"
          },
          existingEntityFiles: {
            items: {
              $ref: "#/components/schemas/AnalyzeLocationExistingEntity"
            },
            type: "array"
          }
        },
        required: ["generateEntities", "existingEntityFiles"],
        additionalProperties: false
      },
      LocationInput: {
        type: "object",
        properties: {
          type: {
            type: "string"
          },
          target: {
            type: "string"
          }
        },
        required: ["type", "target"],
        additionalProperties: false
      },
      EntitiesQueryResponse: {
        type: "object",
        properties: {
          items: {
            type: "array",
            items: {
              $ref: "#/components/schemas/Entity"
            },
            description: "The list of entities paginated by a specific filter."
          },
          totalItems: {
            type: "number"
          },
          pageInfo: {
            type: "object",
            properties: {
              nextCursor: {
                type: "string",
                description: "The cursor for the next batch of entities."
              },
              prevCursor: {
                type: "string",
                description: "The cursor for the previous batch of entities."
              }
            }
          }
        },
        required: ["items", "totalItems", "pageInfo"],
        additionalProperties: false
      }
    },
    securitySchemes: {
      JWT: {
        type: "http",
        scheme: "bearer",
        bearerFormat: "JWT"
      }
    }
  },
  paths: {
    "/refresh": {
      post: {
        operationId: "RefreshEntity",
        description: "Refresh the entity related to entityRef.",
        responses: {
          "200": {
            description: "Refreshed"
          },
          "400": {
            $ref: "#/components/responses/ErrorResponse"
          },
          default: {
            $ref: "#/components/responses/ErrorResponse"
          }
        },
        security: [
          {},
          {
            JWT: []
          }
        ],
        parameters: [],
        requestBody: {
          required: true,
          content: {
            "application/json": {
              schema: {
                type: "object",
                properties: {
                  authorizationToken: {
                    type: "string"
                  },
                  entityRef: {
                    type: "string",
                    description: "The reference to a single entity that should be refreshed"
                  }
                },
                required: ["entityRef"],
                description: "Options for requesting a refresh of entities in the catalog.",
                additionalProperties: false
              }
            }
          }
        }
      }
    },
    "/entities": {
      get: {
        operationId: "GetEntities",
        description: "Get all entities matching a given filter.",
        responses: {
          "200": {
            description: "",
            content: {
              "application/json": {
                schema: {
                  type: "array",
                  items: {
                    $ref: "#/components/schemas/Entity"
                  }
                }
              }
            }
          },
          "400": {
            $ref: "#/components/responses/ErrorResponse"
          },
          default: {
            $ref: "#/components/responses/ErrorResponse"
          }
        },
        security: [
          {},
          {
            JWT: []
          }
        ],
        parameters: [
          {
            $ref: "#/components/parameters/fields"
          },
          {
            $ref: "#/components/parameters/limit"
          },
          {
            $ref: "#/components/parameters/filter"
          },
          {
            $ref: "#/components/parameters/offset"
          },
          {
            $ref: "#/components/parameters/after"
          },
          {
            name: "order",
            in: "query",
            allowReserved: true,
            required: false,
            schema: {
              type: "array",
              items: {
                type: "string"
              }
            }
          }
        ]
      }
    },
    "/entities/by-uid/{uid}": {
      get: {
        operationId: "GetEntityByUid",
        description: "Get a single entity by the UID.",
        responses: {
          "200": {
            description: "Ok",
            content: {
              "application/json": {
                schema: {
                  $ref: "#/components/schemas/Entity"
                }
              }
            }
          },
          "400": {
            $ref: "#/components/responses/ErrorResponse"
          },
          default: {
            $ref: "#/components/responses/ErrorResponse"
          }
        },
        security: [
          {},
          {
            JWT: []
          }
        ],
        parameters: [
          {
            $ref: "#/components/parameters/uid"
          }
        ]
      },
      delete: {
        operationId: "DeleteEntityByUid",
        description: "Delete a single entity by UID.",
        responses: {
          "204": {
            description: "Deleted successfully."
          },
          "400": {
            $ref: "#/components/responses/ErrorResponse"
          },
          default: {
            $ref: "#/components/responses/ErrorResponse"
          }
        },
        security: [
          {},
          {
            JWT: []
          }
        ],
        parameters: [
          {
            $ref: "#/components/parameters/uid"
          }
        ]
      }
    },
    "/entities/by-name/{kind}/{namespace}/{name}": {
      get: {
        operationId: "GetEntityByName",
        description: "Get an entity by an entity ref.",
        responses: {
          "200": {
            description: "Ok",
            content: {
              "application/json": {
                schema: {
                  $ref: "#/components/schemas/Entity"
                }
              }
            }
          },
          "400": {
            $ref: "#/components/responses/ErrorResponse"
          },
          default: {
            $ref: "#/components/responses/ErrorResponse"
          }
        },
        security: [
          {},
          {
            JWT: []
          }
        ],
        parameters: [
          {
            $ref: "#/components/parameters/kind"
          },
          {
            $ref: "#/components/parameters/namespace"
          },
          {
            $ref: "#/components/parameters/name"
          }
        ]
      }
    },
    "/entities/by-name/{kind}/{namespace}/{name}/ancestry": {
      get: {
        operationId: "GetEntityAncestryByName",
        description: "Get an entity's ancestry by entity ref.",
        responses: {
          "200": {
            description: "Ok",
            content: {
              "application/json": {
                schema: {
                  $ref: "#/components/schemas/EntityAncestryResponse"
                }
              }
            }
          },
          "400": {
            $ref: "#/components/responses/ErrorResponse"
          },
          default: {
            $ref: "#/components/responses/ErrorResponse"
          }
        },
        security: [
          {},
          {
            JWT: []
          }
        ],
        parameters: [
          {
            $ref: "#/components/parameters/kind"
          },
          {
            $ref: "#/components/parameters/namespace"
          },
          {
            $ref: "#/components/parameters/name"
          }
        ]
      }
    },
    "/entities/by-refs": {
      post: {
        operationId: "GetEntitiesByRefs",
        description: "Get a batch set of entities given an array of entityRefs.",
        responses: {
          "200": {
            description: "Ok",
            content: {
              "application/json": {
                schema: {
                  $ref: "#/components/schemas/EntitiesBatchResponse"
                }
              }
            }
          },
          "400": {
            $ref: "#/components/responses/ErrorResponse"
          },
          default: {
            $ref: "#/components/responses/ErrorResponse"
          }
        },
        security: [
          {},
          {
            JWT: []
          }
        ],
        requestBody: {
          required: false,
          content: {
            "application/json": {
              schema: {
                type: "object",
                required: ["entityRefs"],
                properties: {
                  entityRefs: {
                    type: "array",
                    items: {
                      type: "string"
                    }
                  },
                  fields: {
                    type: "array",
                    items: {
                      type: "string"
                    }
                  }
                }
              },
              examples: {
                "Fetch Backstage entities": {
                  value: {
                    entityRefs: [
                      "component:default/backstage",
                      "api:default/backstage"
                    ]
                  }
                },
                "Fetch annotations for backstage entity": {
                  value: {
                    entityRefs: ["component:default/backstage"],
                    fields: ["metadata.annotations"]
                  }
                }
              }
            }
          }
        }
      }
    },
    "/entities/by-query": {
      get: {
        operationId: "GetEntitiesByQuery",
        description: "Search for entities by a given query.",
        responses: {
          "200": {
            description: "Ok",
            content: {
              "application/json": {
                schema: {
                  $ref: "#/components/schemas/EntitiesQueryResponse"
                }
              }
            }
          },
          "400": {
            $ref: "#/components/responses/ErrorResponse"
          },
          default: {
            $ref: "#/components/responses/ErrorResponse"
          }
        },
        security: [
          {},
          {
            JWT: []
          }
        ],
        parameters: [
          {
            $ref: "#/components/parameters/fields"
          },
          {
            $ref: "#/components/parameters/limit"
          },
          {
            $ref: "#/components/parameters/orderField"
          },
          {
            $ref: "#/components/parameters/cursor"
          },
          {
            $ref: "#/components/parameters/filter"
          },
          {
            name: "fullTextFilterTerm",
            in: "query",
            description: "Text search term.",
            required: false,
            allowReserved: true,
            schema: {
              type: "string"
            }
          },
          {
            name: "fullTextFilterFields",
            in: "query",
            description: "A comma separated list of fields to sort returned results by.",
            required: false,
            allowReserved: true,
            schema: {
              type: "array",
              items: {
                type: "string"
              }
            },
            explode: false,
            style: "form"
          }
        ]
      }
    },
    "/entity-facets": {
      get: {
        operationId: "GetEntityFacets",
        description: "Get all entity facets that match the given filters.",
        responses: {
          "200": {
            description: "Ok",
            content: {
              "application/json": {
                schema: {
                  $ref: "#/components/schemas/EntityFacetsResponse"
                }
              }
            }
          },
          "400": {
            $ref: "#/components/responses/ErrorResponse"
          },
          default: {
            $ref: "#/components/responses/ErrorResponse"
          }
        },
        security: [
          {},
          {
            JWT: []
          }
        ],
        parameters: [
          {
            in: "query",
            name: "facet",
            required: true,
            allowReserved: true,
            schema: {
              type: "array",
              items: {
                type: "string"
              }
            },
            examples: {
              "Entities by kind": {
                value: ["kind"]
              },
              "Entities by spec type": {
                value: ["spec.type"]
              }
            }
          },
          {
            $ref: "#/components/parameters/filter"
          }
        ]
      }
    },
    "/locations": {
      post: {
        operationId: "CreateLocation",
        description: "Create a location for a given target.",
        responses: {
          "201": {
            description: "Created",
            content: {
              "application/json": {
                schema: {
                  type: "object",
                  properties: {
                    exists: {
                      type: "boolean"
                    },
                    entities: {
                      items: {
                        $ref: "#/components/schemas/Entity"
                      },
                      type: "array"
                    },
                    location: {
                      $ref: "#/components/schemas/Location"
                    }
                  },
                  required: ["entities", "location"]
                }
              }
            }
          },
          "400": {
            $ref: "#/components/responses/ErrorResponse"
          },
          default: {
            $ref: "#/components/responses/ErrorResponse"
          }
        },
        security: [
          {},
          {
            JWT: []
          }
        ],
        parameters: [
          {
            in: "query",
            name: "dryRun",
            required: false,
            allowReserved: true,
            schema: {
              type: "string"
            }
          }
        ],
        requestBody: {
          required: true,
          content: {
            "application/json": {
              schema: {
                type: "object",
                properties: {
                  target: {
                    type: "string"
                  },
                  type: {
                    type: "string"
                  }
                },
                required: ["target", "type"]
              }
            }
          }
        }
      },
      get: {
        operationId: "GetLocations",
        description: "Get all locations",
        responses: {
          "200": {
            description: "Ok",
            content: {
              "application/json": {
                schema: {
                  type: "array",
                  items: {
                    type: "object",
                    properties: {
                      data: {
                        $ref: "#/components/schemas/Location"
                      }
                    },
                    required: ["data"]
                  }
                }
              }
            }
          },
          default: {
            $ref: "#/components/responses/ErrorResponse"
          }
        },
        security: [
          {},
          {
            JWT: []
          }
        ],
        parameters: []
      }
    },
    "/locations/{id}": {
      get: {
        operationId: "GetLocation",
        description: "Get a location by id.",
        responses: {
          "200": {
            description: "Ok",
            content: {
              "application/json": {
                schema: {
                  $ref: "#/components/schemas/Location"
                }
              }
            }
          },
          default: {
            $ref: "#/components/responses/ErrorResponse"
          }
        },
        security: [
          {},
          {
            JWT: []
          }
        ],
        parameters: [
          {
            in: "path",
            name: "id",
            required: true,
            allowReserved: true,
            schema: {
              type: "string"
            }
          }
        ]
      },
      delete: {
        operationId: "DeleteLocation",
        description: "Delete a location by id.",
        responses: {
          "204": {
            description: "No content"
          },
          "400": {
            $ref: "#/components/responses/ErrorResponse"
          },
          default: {
            $ref: "#/components/responses/ErrorResponse"
          }
        },
        security: [
          {},
          {
            JWT: []
          }
        ],
        parameters: [
          {
            in: "path",
            name: "id",
            required: true,
            allowReserved: true,
            schema: {
              type: "string"
            }
          }
        ]
      }
    },
    "/locations/by-entity/{kind}/{namespace}/{name}": {
      get: {
        operationId: "getLocationByEntity",
        description: "Get a location for entity.",
        responses: {
          "200": {
            description: "Ok",
            content: {
              "application/json": {
                schema: {
                  $ref: "#/components/schemas/Location"
                }
              }
            }
          },
          default: {
            $ref: "#/components/responses/ErrorResponse"
          }
        },
        security: [
          {},
          {
            JWT: []
          }
        ],
        parameters: [
          {
            in: "path",
            name: "kind",
            required: true,
            allowReserved: true,
            schema: {
              type: "string"
            }
          },
          {
            in: "path",
            name: "namespace",
            required: true,
            allowReserved: true,
            schema: {
              type: "string"
            }
          },
          {
            in: "path",
            name: "name",
            required: true,
            allowReserved: true,
            schema: {
              type: "string"
            }
          }
        ]
      }
    },
    "/analyze-location": {
      post: {
        operationId: "AnalyzeLocation",
        description: "Validate a given location.",
        responses: {
          "200": {
            description: "Ok",
            content: {
              "application/json": {
                schema: {
                  $ref: "#/components/schemas/AnalyzeLocationResponse"
                }
              }
            }
          },
          "400": {
            $ref: "#/components/responses/ErrorResponse"
          },
          default: {
            $ref: "#/components/responses/ErrorResponse"
          }
        },
        security: [
          {},
          {
            JWT: []
          }
        ],
        parameters: [],
        requestBody: {
          required: true,
          content: {
            "application/json": {
              schema: {
                type: "object",
                properties: {
                  catalogFileName: {
                    type: "string"
                  },
                  location: {
                    $ref: "#/components/schemas/LocationInput"
                  }
                },
                required: ["location"]
              }
            }
          }
        }
      }
    },
    "/validate-entity": {
      post: {
        operationId: "ValidateEntity",
        description: "Validate that a passed in entity has no errors in schema.",
        responses: {
          "200": {
            description: "Ok"
          },
          "400": {
            description: "Validation errors.",
            content: {
              "application/json; charset=utf-8": {
                schema: {
                  type: "object",
                  properties: {
                    errors: {
                      type: "array",
                      items: {
                        type: "object",
                        properties: {
                          name: {
                            type: "string"
                          },
                          message: {
                            type: "string"
                          }
                        },
                        required: ["name", "message"],
                        additionalProperties: {}
                      }
                    }
                  },
                  required: ["errors"]
                }
              }
            }
          }
        },
        security: [
          {},
          {
            JWT: []
          }
        ],
        parameters: [],
        requestBody: {
          required: true,
          content: {
            "application/json": {
              schema: {
                type: "object",
                properties: {
                  location: {
                    type: "string"
                  },
                  entity: {
                    type: "object",
                    additionalProperties: {}
                  }
                },
                required: ["location", "entity"]
              }
            }
          }
        }
      }
    }
  }
};
const createOpenApiRouter = async (options) => backendOpenapiUtils.createValidatedOpenApiRouter(spec, options);

function parseEntityPaginationParams({
  limit,
  offset,
  after
}) {
  if (offset === void 0 && limit === void 0 && after === void 0) {
    return void 0;
  }
  if (offset !== void 0 && offset < 0) {
    throw new errors.InputError(`Invalid offset, must be zero or greater`);
  }
  if (limit !== void 0 && limit <= 0) {
    throw new errors.InputError(`Invalid limit, must be greater than zero`);
  }
  if (after !== void 0 && !after) {
    throw new errors.InputError(`Invalid after, must not be empty`);
  }
  return {
    ...offset !== void 0 ? { offset } : {},
    ...limit !== void 0 ? { limit } : {},
    ...after !== void 0 ? { after } : {}
  };
}

async function createRouter(options) {
  const router = await createOpenApiRouter({
    validatorOptions: {
      // We want the spec to be up to date with the expected value, but the return type needs
      //  to be controlled by the router implementation not the request validator.
      ignorePaths: /^\/validate-entity\/?$/
    }
  });
  const {
    entitiesCatalog,
    locationAnalyzer,
    locationService,
    orchestrator,
    refreshService,
    config,
    logger,
    permissionIntegrationRouter
  } = options;
  const readonlyEnabled = config.getOptionalBoolean("catalog.readonly") || false;
  if (readonlyEnabled) {
    logger.info("Catalog is running in readonly mode");
  }
  if (refreshService) {
    router.post("/refresh", async (req, res) => {
      const refreshOptions = req.body;
      refreshOptions.authorizationToken = pluginAuthNode.getBearerTokenFromAuthorizationHeader(
        req.header("authorization")
      );
      await refreshService.refresh(refreshOptions);
      res.status(200).end();
    });
  }
  if (permissionIntegrationRouter) {
    router.use(permissionIntegrationRouter);
  }
  if (entitiesCatalog) {
    router.get("/entities", async (req, res) => {
      const { entities, pageInfo } = await entitiesCatalog.entities({
        filter: parseEntityFilterParams(req.query),
        fields: parseEntityTransformParams(req.query),
        order: parseEntityOrderParams(req.query),
        pagination: parseEntityPaginationParams(req.query),
        authorizationToken: pluginAuthNode.getBearerTokenFromAuthorizationHeader(
          req.header("authorization")
        )
      });
      if (pageInfo.hasNextPage) {
        const url = new URL(`http://ignored${req.url}`);
        url.searchParams.delete("offset");
        url.searchParams.set("after", pageInfo.endCursor);
        res.setHeader("link", `<${url.pathname}${url.search}>; rel="next"`);
      }
      res.json(entities);
    }).get("/entities/by-query", async (req, res) => {
      const { items, pageInfo, totalItems } = await entitiesCatalog.queryEntities({
        limit: req.query.limit,
        ...parseQueryEntitiesParams(req.query),
        authorizationToken: pluginAuthNode.getBearerTokenFromAuthorizationHeader(
          req.header("authorization")
        )
      });
      res.json({
        items,
        totalItems,
        pageInfo: {
          ...pageInfo.nextCursor && {
            nextCursor: encodeCursor(pageInfo.nextCursor)
          },
          ...pageInfo.prevCursor && {
            prevCursor: encodeCursor(pageInfo.prevCursor)
          }
        }
      });
    }).get("/entities/by-uid/:uid", async (req, res) => {
      const { uid } = req.params;
      const { entities } = await entitiesCatalog.entities({
        filter: basicEntityFilter({ "metadata.uid": uid }),
        authorizationToken: pluginAuthNode.getBearerTokenFromAuthorizationHeader(
          req.header("authorization")
        )
      });
      if (!entities.length) {
        throw new errors.NotFoundError(`No entity with uid ${uid}`);
      }
      res.status(200).json(entities[0]);
    }).delete("/entities/by-uid/:uid", async (req, res) => {
      const { uid } = req.params;
      await entitiesCatalog.removeEntityByUid(uid, {
        authorizationToken: pluginAuthNode.getBearerTokenFromAuthorizationHeader(
          req.header("authorization")
        )
      });
      res.status(204).end();
    }).get("/entities/by-name/:kind/:namespace/:name", async (req, res) => {
      const { kind, namespace, name } = req.params;
      const { entities } = await entitiesCatalog.entities({
        filter: basicEntityFilter({
          kind,
          "metadata.namespace": namespace,
          "metadata.name": name
        }),
        authorizationToken: pluginAuthNode.getBearerTokenFromAuthorizationHeader(
          req.header("authorization")
        )
      });
      if (!entities.length) {
        throw new errors.NotFoundError(
          `No entity named '${name}' found, with kind '${kind}' in namespace '${namespace}'`
        );
      }
      res.status(200).json(entities[0]);
    }).get(
      "/entities/by-name/:kind/:namespace/:name/ancestry",
      async (req, res) => {
        const { kind, namespace, name } = req.params;
        const entityRef = catalogModel.stringifyEntityRef({ kind, namespace, name });
        const response = await entitiesCatalog.entityAncestry(entityRef, {
          authorizationToken: pluginAuthNode.getBearerTokenFromAuthorizationHeader(
            req.header("authorization")
          )
        });
        res.status(200).json(response);
      }
    ).post("/entities/by-refs", async (req, res) => {
      const request = entitiesBatchRequest(req);
      const token = pluginAuthNode.getBearerTokenFromAuthorizationHeader(
        req.header("authorization")
      );
      const response = await entitiesCatalog.entitiesBatch({
        entityRefs: request.entityRefs,
        fields: parseEntityTransformParams(req.query, request.fields),
        authorizationToken: token
      });
      res.status(200).json(response);
    }).get("/entity-facets", async (req, res) => {
      const response = await entitiesCatalog.facets({
        filter: parseEntityFilterParams(req.query),
        facets: parseEntityFacetParams(req.query),
        authorizationToken: pluginAuthNode.getBearerTokenFromAuthorizationHeader(
          req.header("authorization")
        )
      });
      res.status(200).json(response);
    });
  }
  if (locationService) {
    router.post("/locations", async (req, res) => {
      const location = await validateRequestBody(req, locationInput);
      const dryRun = yn__default["default"](req.query.dryRun, { default: false });
      if (!dryRun) {
        disallowReadonlyMode(readonlyEnabled);
      }
      const output = await locationService.createLocation(location, dryRun, {
        authorizationToken: pluginAuthNode.getBearerTokenFromAuthorizationHeader(
          req.header("authorization")
        )
      });
      res.status(201).json(output);
    }).get("/locations", async (req, res) => {
      const locations = await locationService.listLocations({
        authorizationToken: pluginAuthNode.getBearerTokenFromAuthorizationHeader(
          req.header("authorization")
        )
      });
      res.status(200).json(locations.map((l) => ({ data: l })));
    }).get("/locations/:id", async (req, res) => {
      const { id } = req.params;
      const output = await locationService.getLocation(id, {
        authorizationToken: pluginAuthNode.getBearerTokenFromAuthorizationHeader(
          req.header("authorization")
        )
      });
      res.status(200).json(output);
    }).delete("/locations/:id", async (req, res) => {
      disallowReadonlyMode(readonlyEnabled);
      const { id } = req.params;
      await locationService.deleteLocation(id, {
        authorizationToken: pluginAuthNode.getBearerTokenFromAuthorizationHeader(
          req.header("authorization")
        )
      });
      res.status(204).end();
    }).get("/locations/by-entity/:kind/:namespace/:name", async (req, res) => {
      const { kind, namespace, name } = req.params;
      const output = await locationService.getLocationByEntity(
        { kind, namespace, name },
        {
          authorizationToken: pluginAuthNode.getBearerTokenFromAuthorizationHeader(
            req.header("authorization")
          )
        }
      );
      res.status(200).json(output);
    });
  }
  if (locationAnalyzer) {
    router.post("/analyze-location", async (req, res) => {
      const body = await validateRequestBody(
        req,
        zod.z.object({
          location: locationInput,
          catalogFilename: zod.z.string().optional()
        })
      );
      const schema = zod.z.object({
        location: locationInput,
        catalogFilename: zod.z.string().optional()
      });
      const output = await locationAnalyzer.analyzeLocation(schema.parse(body));
      res.status(200).json(output);
    });
  }
  if (orchestrator) {
    router.post("/validate-entity", async (req, res) => {
      const bodySchema = zod.z.object({
        entity: zod.z.unknown(),
        location: zod.z.string()
      });
      let body;
      let entity;
      let location;
      try {
        body = await validateRequestBody(req, bodySchema);
        entity = validateEntityEnvelope(body.entity);
        location = catalogModel.parseLocationRef(body.location);
        if (location.type !== "url")
          throw new TypeError(
            `Invalid location ref ${body.location}, only 'url:<target>' is supported, e.g. url:https://host/path`
          );
      } catch (err) {
        return res.status(400).json({
          errors: [errors.serializeError(err)]
        });
      }
      const processingResult = await orchestrator.process({
        entity: {
          ...entity,
          metadata: {
            ...entity.metadata,
            annotations: {
              [catalogModel.ANNOTATION_LOCATION]: body.location,
              [catalogModel.ANNOTATION_ORIGIN_LOCATION]: body.location,
              ...entity.metadata.annotations
            }
          }
        }
      });
      if (!processingResult.ok)
        res.status(400).json({
          errors: processingResult.errors.map((e) => errors.serializeError(e))
        });
      return res.status(200).end();
    });
  }
  router.use(backendCommon.errorHandler());
  return router;
}

var __defProp$3 = Object.defineProperty;
var __defNormalProp$3 = (obj, key, value) => key in obj ? __defProp$3(obj, key, { enumerable: true, configurable: true, writable: true, value }) : obj[key] = value;
var __publicField$3 = (obj, key, value) => {
  __defNormalProp$3(obj, typeof key !== "symbol" ? key + "" : key, value);
  return value;
};
class DefaultRefreshService {
  constructor(options) {
    __publicField$3(this, "database");
    this.database = options.database;
  }
  async refresh(options) {
    await this.database.transaction(async (tx) => {
      const { entityRefs } = await this.database.listAncestors(tx, {
        entityRef: options.entityRef
      });
      const locationAncestor = entityRefs.find(
        (ref) => ref.startsWith("location:")
      );
      if (locationAncestor) {
        await this.database.refresh(tx, {
          entityRef: locationAncestor
        });
      }
      await this.database.refresh(tx, {
        entityRef: options.entityRef
      });
    });
  }
}

class AuthorizedRefreshService {
  constructor(service, permissionApi) {
    this.service = service;
    this.permissionApi = permissionApi;
  }
  async refresh(options) {
    const authorizeDecision = (await this.permissionApi.authorize(
      [
        {
          permission: alpha.catalogEntityRefreshPermission,
          resourceRef: options.entityRef
        }
      ],
      { token: options.authorizationToken }
    ))[0];
    if (authorizeDecision.result !== pluginPermissionCommon.AuthorizeResult.ALLOW) {
      throw new errors.NotAllowedError();
    }
    await this.service.refresh(options);
  }
}

var __defProp$2 = Object.defineProperty;
var __defNormalProp$2 = (obj, key, value) => key in obj ? __defProp$2(obj, key, { enumerable: true, configurable: true, writable: true, value }) : obj[key] = value;
var __publicField$2 = (obj, key, value) => {
  __defNormalProp$2(obj, typeof key !== "symbol" ? key + "" : key, value);
  return value;
};
const _DefaultCatalogRulesEnforcer = class _DefaultCatalogRulesEnforcer {
  constructor(rules) {
    this.rules = rules;
  }
  /**
   * Loads catalog rules from config.
   *
   * This reads `catalog.rules` and defaults to the default rules if no value is present.
   * The value of the config should be a list of config objects, each with a single `allow`
   * field which in turn is a list of entity kinds to allow.
   *
   * If there is no matching rule to allow an ingested entity, it will be rejected by the catalog.
   *
   * It also reads in rules from `catalog.locations`, where each location can have a list
   * of rules for that specific location, specified in a `rules` field.
   *
   * For example:
   *
   * ```yaml
   * catalog:
   *   rules:
   *   - allow: [Component, API]
   *   - allow: [Template]
   *     locations:
   *       - type: url
   *         pattern: https://github.com/org/*\/blob/master/template.yaml
   *   - allow: [Location]
   *     locations:
   *       - type: url
   *         pattern: https://github.com/org/repo/blob/master/location.yaml
   *
   *   locations:
   *   - type: url
   *     target: https://github.com/org/repo/blob/master/users.yaml
   *     rules:
   *       - allow: [User, Group]
   *   - type: url
   *     target: https://github.com/org/repo/blob/master/systems.yaml
   *     rules:
   *       - allow: [System]
   * ```
   */
  static fromConfig(config) {
    const rules = new Array();
    if (config.has("catalog.rules")) {
      const globalRules = config.getConfigArray("catalog.rules").map((ruleConf) => {
        var _a;
        return {
          allow: ruleConf.getStringArray("allow").map((kind) => ({ kind })),
          locations: (_a = ruleConf.getOptionalConfigArray("locations")) == null ? void 0 : _a.map((locationConfig) => {
            const location = {
              pattern: locationConfig.getOptionalString("pattern"),
              type: locationConfig.getString("type"),
              exact: locationConfig.getOptionalString("exact")
            };
            if (location.pattern && location.exact) {
              throw new Error(
                "A catalog rule location cannot have both exact and pattern values"
              );
            }
            return location;
          })
        };
      });
      rules.push(...globalRules);
    } else {
      rules.push(..._DefaultCatalogRulesEnforcer.defaultRules);
    }
    if (config.has("catalog.locations")) {
      const locationRules = config.getConfigArray("catalog.locations").flatMap((locConf) => {
        if (!locConf.has("rules")) {
          return [];
        }
        const type = locConf.getString("type");
        const exact = resolveTarget(type, locConf.getString("target"));
        return locConf.getConfigArray("rules").map((ruleConf) => ({
          allow: ruleConf.getStringArray("allow").map((kind) => ({ kind })),
          locations: [{ type, exact }]
        }));
      });
      rules.push(...locationRules);
    }
    return new _DefaultCatalogRulesEnforcer(rules);
  }
  /**
   * Checks whether a specific entity/location combination is allowed
   * according to the configured rules.
   */
  isAllowed(entity, location) {
    for (const rule of this.rules) {
      if (!this.matchLocation(location, rule.locations)) {
        continue;
      }
      if (this.matchEntity(entity, rule.allow)) {
        return true;
      }
    }
    return false;
  }
  matchLocation(location, matchers) {
    if (!matchers) {
      return true;
    }
    for (const matcher of matchers) {
      if (matcher.type !== (location == null ? void 0 : location.type)) {
        continue;
      }
      if (matcher.exact && matcher.exact !== (location == null ? void 0 : location.target)) {
        continue;
      }
      if (matcher.pattern && !minimatch__default["default"](location == null ? void 0 : location.target, matcher.pattern, {
        nocase: true,
        dot: true
      })) {
        continue;
      }
      return true;
    }
    return false;
  }
  matchEntity(entity, matchers) {
    var _a;
    if (!matchers) {
      return true;
    }
    for (const matcher of matchers) {
      if (((_a = entity == null ? void 0 : entity.kind) == null ? void 0 : _a.toLowerCase()) !== matcher.kind.toLowerCase()) {
        continue;
      }
      return true;
    }
    return false;
  }
};
/**
 * Default rules used by the catalog.
 *
 * Denies any location from specifying user or group entities.
 */
__publicField$2(_DefaultCatalogRulesEnforcer, "defaultRules", [
  {
    allow: ["Component", "API", "Location"].map((kind) => ({ kind }))
  }
]);
let DefaultCatalogRulesEnforcer = _DefaultCatalogRulesEnforcer;
function resolveTarget(type, target) {
  if (type !== "file") {
    return target;
  }
  return path__default["default"].resolve(target);
}

var __defProp$1 = Object.defineProperty;
var __defNormalProp$1 = (obj, key, value) => key in obj ? __defProp$1(obj, key, { enumerable: true, configurable: true, writable: true, value }) : obj[key] = value;
var __publicField$1 = (obj, key, value) => {
  __defNormalProp$1(obj, typeof key !== "symbol" ? key + "" : key, value);
  return value;
};
class Connection {
  constructor(config) {
    this.config = config;
    __publicField$1(this, "validateEntityEnvelope", catalogModel.entityEnvelopeSchemaValidator());
  }
  async applyMutation(mutation) {
    const db = this.config.providerDatabase;
    if (mutation.type === "full") {
      this.check(mutation.entities.map((e) => e.entity));
      await db.transaction(async (tx) => {
        await db.replaceUnprocessedEntities(tx, {
          sourceKey: this.config.id,
          type: "full",
          items: mutation.entities
        });
      });
    } else if (mutation.type === "delta") {
      this.check(mutation.added.map((e) => e.entity));
      this.check(
        mutation.removed.map((e) => "entity" in e ? e.entity : void 0).filter((e) => Boolean(e))
      );
      await db.transaction(async (tx) => {
        await db.replaceUnprocessedEntities(tx, {
          sourceKey: this.config.id,
          type: "delta",
          added: mutation.added,
          removed: mutation.removed.map(
            (r) => "entityRef" in r ? r : {
              entityRef: catalogModel.stringifyEntityRef(r.entity),
              locationKey: r.locationKey
            }
          )
        });
      });
    }
  }
  async refresh(options) {
    const db = this.config.providerDatabase;
    await db.transaction(async (tx) => {
      return db.refreshByRefreshKeys(tx, {
        keys: options.keys
      });
    });
  }
  check(entities) {
    for (const entity of entities) {
      try {
        this.validateEntityEnvelope(entity);
      } catch (e) {
        throw new TypeError(`Malformed entity envelope, ${e}`);
      }
    }
  }
}
async function connectEntityProviders(db, providers) {
  await Promise.all(
    providers.map(async (provider) => {
      const connection = new Connection({
        id: provider.getProviderName(),
        providerDatabase: db
      });
      return provider.connect(connection);
    })
  );
}

const createCatalogPermissionRule = pluginPermissionNode.makeCreatePermissionRule();

const hasAnnotation = createCatalogPermissionRule({
  name: "HAS_ANNOTATION",
  description: "Allow entities with the specified annotation",
  resourceType: alpha.RESOURCE_TYPE_CATALOG_ENTITY,
  paramsSchema: zod.z.object({
    annotation: zod.z.string().describe("Name of the annotation to match on"),
    value: zod.z.string().optional().describe("Value of the annotation to match on")
  }),
  apply: (resource, { annotation, value }) => {
    var _a, _b;
    return !!((_a = resource.metadata.annotations) == null ? void 0 : _a.hasOwnProperty(annotation)) && (value === void 0 ? true : ((_b = resource.metadata.annotations) == null ? void 0 : _b[annotation]) === value);
  },
  toQuery: ({ annotation, value }) => value === void 0 ? {
    key: `metadata.annotations.${annotation}`
  } : {
    key: `metadata.annotations.${annotation}`,
    values: [value]
  }
});

const isEntityKind = createCatalogPermissionRule({
  name: "IS_ENTITY_KIND",
  description: "Allow entities matching a specified kind",
  resourceType: alpha.RESOURCE_TYPE_CATALOG_ENTITY,
  paramsSchema: zod.z.object({
    kinds: zod.z.array(zod.z.string()).describe("List of kinds to match at least one of")
  }),
  apply(resource, { kinds }) {
    const resourceKind = resource.kind.toLocaleLowerCase("en-US");
    return kinds.some((kind) => kind.toLocaleLowerCase("en-US") === resourceKind);
  },
  toQuery({ kinds }) {
    return {
      key: "kind",
      values: kinds.map((kind) => kind.toLocaleLowerCase("en-US"))
    };
  }
});

const isEntityOwner = createCatalogPermissionRule({
  name: "IS_ENTITY_OWNER",
  description: "Allow entities owned by a specified claim",
  resourceType: alpha.RESOURCE_TYPE_CATALOG_ENTITY,
  paramsSchema: zod.z.object({
    claims: zod.z.array(zod.z.string()).describe(
      `List of claims to match at least one on within ${catalogModel.RELATION_OWNED_BY}`
    )
  }),
  apply: (resource, { claims }) => {
    if (!resource.relations) {
      return false;
    }
    return resource.relations.filter((relation) => relation.type === catalogModel.RELATION_OWNED_BY).some((relation) => claims.includes(relation.targetRef));
  },
  toQuery: ({ claims }) => ({
    key: "relations.ownedBy",
    values: claims
  })
});

const hasLabel = createCatalogPermissionRule({
  name: "HAS_LABEL",
  description: "Allow entities with the specified label",
  resourceType: alpha.RESOURCE_TYPE_CATALOG_ENTITY,
  paramsSchema: zod.z.object({
    label: zod.z.string().describe("Name of the label to match on")
  }),
  apply: (resource, { label }) => {
    var _a;
    return !!((_a = resource.metadata.labels) == null ? void 0 : _a.hasOwnProperty(label));
  },
  toQuery: ({ label }) => ({
    key: `metadata.labels.${label}`
  })
});

const createPropertyRule = (propertyType) => createCatalogPermissionRule({
  name: `HAS_${propertyType.toUpperCase()}`,
  description: `Allow entities with the specified ${propertyType} subfield`,
  resourceType: alpha.RESOURCE_TYPE_CATALOG_ENTITY,
  paramsSchema: zod.z.object({
    key: zod.z.string().describe(`Property within the entities ${propertyType} to match on`),
    value: zod.z.string().optional().describe(`Value of the given property to match on`)
  }),
  apply: (resource, { key, value }) => {
    const foundValue = lodash.get(resource[propertyType], key);
    if (Array.isArray(foundValue)) {
      if (value !== void 0) {
        return foundValue.includes(value);
      }
      return foundValue.length > 0;
    }
    if (value !== void 0) {
      return value === foundValue;
    }
    return !!foundValue;
  },
  toQuery: ({ key, value }) => ({
    key: `${propertyType}.${key}`,
    ...value !== void 0 && { values: [value] }
  })
});

const hasMetadata = createPropertyRule("metadata");

const hasSpec = createPropertyRule("spec");

const permissionRules = {
  hasAnnotation,
  hasLabel,
  hasMetadata,
  hasSpec,
  isEntityKind,
  isEntityOwner
};

class AuthorizedEntitiesCatalog {
  constructor(entitiesCatalog, permissionApi, transformConditions) {
    this.entitiesCatalog = entitiesCatalog;
    this.permissionApi = permissionApi;
    this.transformConditions = transformConditions;
  }
  async entities(request) {
    const authorizeDecision = (await this.permissionApi.authorizeConditional(
      [{ permission: alpha.catalogEntityReadPermission }],
      { token: request == null ? void 0 : request.authorizationToken }
    ))[0];
    if (authorizeDecision.result === pluginPermissionCommon.AuthorizeResult.DENY) {
      return {
        entities: [],
        pageInfo: { hasNextPage: false }
      };
    }
    if (authorizeDecision.result === pluginPermissionCommon.AuthorizeResult.CONDITIONAL) {
      const permissionFilter = this.transformConditions(
        authorizeDecision.conditions
      );
      return this.entitiesCatalog.entities({
        ...request,
        filter: (request == null ? void 0 : request.filter) ? { allOf: [permissionFilter, request.filter] } : permissionFilter
      });
    }
    return this.entitiesCatalog.entities(request);
  }
  async entitiesBatch(request) {
    const authorizeDecision = (await this.permissionApi.authorizeConditional(
      [{ permission: alpha.catalogEntityReadPermission }],
      { token: request == null ? void 0 : request.authorizationToken }
    ))[0];
    if (authorizeDecision.result === pluginPermissionCommon.AuthorizeResult.DENY) {
      return {
        items: new Array(request.entityRefs.length).fill(null)
      };
    }
    if (authorizeDecision.result === pluginPermissionCommon.AuthorizeResult.CONDITIONAL) {
      const permissionFilter = this.transformConditions(
        authorizeDecision.conditions
      );
      return this.entitiesCatalog.entitiesBatch({
        ...request,
        filter: (request == null ? void 0 : request.filter) ? { allOf: [permissionFilter, request.filter] } : permissionFilter
      });
    }
    return this.entitiesCatalog.entitiesBatch(request);
  }
  async queryEntities(request) {
    const authorizeDecision = (await this.permissionApi.authorizeConditional(
      [{ permission: alpha.catalogEntityReadPermission }],
      { token: request.authorizationToken }
    ))[0];
    if (authorizeDecision.result === pluginPermissionCommon.AuthorizeResult.DENY) {
      return {
        items: [],
        pageInfo: {},
        totalItems: 0
      };
    }
    if (authorizeDecision.result === pluginPermissionCommon.AuthorizeResult.CONDITIONAL) {
      const permissionFilter = this.transformConditions(
        authorizeDecision.conditions
      );
      let permissionedRequest;
      let requestFilter;
      if (isQueryEntitiesCursorRequest(request)) {
        requestFilter = request.cursor.filter;
        permissionedRequest = {
          ...request,
          cursor: {
            ...request.cursor,
            filter: request.cursor.filter ? { allOf: [permissionFilter, request.cursor.filter] } : permissionFilter
          }
        };
      } else {
        permissionedRequest = {
          ...request,
          filter: request.filter ? { allOf: [permissionFilter, request.filter] } : permissionFilter
        };
        requestFilter = request.filter;
      }
      const response = await this.entitiesCatalog.queryEntities(
        permissionedRequest
      );
      const prevCursor = response.pageInfo.prevCursor && {
        ...response.pageInfo.prevCursor,
        filter: requestFilter
      };
      const nextCursor = response.pageInfo.nextCursor && {
        ...response.pageInfo.nextCursor,
        filter: requestFilter
      };
      return {
        ...response,
        pageInfo: {
          prevCursor,
          nextCursor
        }
      };
    }
    return this.entitiesCatalog.queryEntities(request);
  }
  async removeEntityByUid(uid, options) {
    const authorizeResponse = (await this.permissionApi.authorizeConditional(
      [{ permission: alpha.catalogEntityDeletePermission }],
      { token: options == null ? void 0 : options.authorizationToken }
    ))[0];
    if (authorizeResponse.result === pluginPermissionCommon.AuthorizeResult.DENY) {
      throw new errors.NotAllowedError();
    }
    if (authorizeResponse.result === pluginPermissionCommon.AuthorizeResult.CONDITIONAL) {
      const permissionFilter = this.transformConditions(
        authorizeResponse.conditions
      );
      const { entities } = await this.entitiesCatalog.entities({
        filter: {
          allOf: [permissionFilter, basicEntityFilter({ "metadata.uid": uid })]
        }
      });
      if (entities.length === 0) {
        throw new errors.NotAllowedError();
      }
    }
    return this.entitiesCatalog.removeEntityByUid(uid);
  }
  async entityAncestry(entityRef, options) {
    const rootEntityAuthorizeResponse = (await this.permissionApi.authorize(
      [{ permission: alpha.catalogEntityReadPermission, resourceRef: entityRef }],
      { token: options == null ? void 0 : options.authorizationToken }
    ))[0];
    if (rootEntityAuthorizeResponse.result === pluginPermissionCommon.AuthorizeResult.DENY) {
      throw new errors.NotAllowedError();
    }
    const ancestryResult = await this.entitiesCatalog.entityAncestry(entityRef);
    const authorizeResponse = await this.permissionApi.authorize(
      ancestryResult.items.map((item) => ({
        permission: alpha.catalogEntityReadPermission,
        resourceRef: catalogModel.stringifyEntityRef(item.entity)
      })),
      { token: options == null ? void 0 : options.authorizationToken }
    );
    const unauthorizedAncestryItems = ancestryResult.items.filter(
      (_, index) => authorizeResponse[index].result === pluginPermissionCommon.AuthorizeResult.DENY
    );
    if (unauthorizedAncestryItems.length === 0) {
      return ancestryResult;
    }
    const rootUnauthorizedEntityRefs = unauthorizedAncestryItems.map(
      (ancestryItem) => catalogModel.stringifyEntityRef(ancestryItem.entity)
    );
    const allUnauthorizedEntityRefs = new Set(
      rootUnauthorizedEntityRefs.flatMap(
        (rootEntityRef) => this.findParents(
          rootEntityRef,
          ancestryResult.items,
          new Set(rootUnauthorizedEntityRefs)
        )
      )
    );
    return {
      rootEntityRef: ancestryResult.rootEntityRef,
      items: ancestryResult.items.filter(
        (ancestryItem) => !allUnauthorizedEntityRefs.has(
          catalogModel.stringifyEntityRef(ancestryItem.entity)
        )
      )
    };
  }
  async facets(request) {
    const authorizeDecision = (await this.permissionApi.authorizeConditional(
      [{ permission: alpha.catalogEntityReadPermission }],
      { token: request == null ? void 0 : request.authorizationToken }
    ))[0];
    if (authorizeDecision.result === pluginPermissionCommon.AuthorizeResult.DENY) {
      return {
        facets: Object.fromEntries(request.facets.map((f) => [f, []]))
      };
    }
    if (authorizeDecision.result === pluginPermissionCommon.AuthorizeResult.CONDITIONAL) {
      const permissionFilter = this.transformConditions(
        authorizeDecision.conditions
      );
      return this.entitiesCatalog.facets({
        ...request,
        filter: (request == null ? void 0 : request.filter) ? { allOf: [permissionFilter, request.filter] } : permissionFilter
      });
    }
    return this.entitiesCatalog.facets(request);
  }
  findParents(entityRef, allAncestryItems, seenEntityRefs) {
    const entity = allAncestryItems.find(
      (ancestryItem) => catalogModel.stringifyEntityRef(ancestryItem.entity) === entityRef
    );
    if (!entity)
      return [];
    const newSeenEntityRefs = new Set(seenEntityRefs);
    entity.parentEntityRefs.forEach(
      (parentRef) => newSeenEntityRefs.add(parentRef)
    );
    return [
      entityRef,
      ...entity.parentEntityRefs.flatMap(
        (parentRef) => seenEntityRefs.has(parentRef) ? [] : this.findParents(parentRef, allAncestryItems, newSeenEntityRefs)
      )
    ];
  }
}

class AuthorizedLocationService {
  constructor(locationService, permissionApi) {
    this.locationService = locationService;
    this.permissionApi = permissionApi;
  }
  async createLocation(spec, dryRun, options) {
    const authorizationResponse = (await this.permissionApi.authorize(
      [{ permission: alpha.catalogLocationCreatePermission }],
      { token: options == null ? void 0 : options.authorizationToken }
    ))[0];
    if (authorizationResponse.result === pluginPermissionCommon.AuthorizeResult.DENY) {
      throw new errors.NotAllowedError();
    }
    return this.locationService.createLocation(spec, dryRun);
  }
  async listLocations(options) {
    const authorizationResponse = (await this.permissionApi.authorize(
      [{ permission: alpha.catalogLocationReadPermission }],
      { token: options == null ? void 0 : options.authorizationToken }
    ))[0];
    if (authorizationResponse.result === pluginPermissionCommon.AuthorizeResult.DENY) {
      return [];
    }
    return this.locationService.listLocations();
  }
  async getLocation(id, options) {
    const authorizationResponse = (await this.permissionApi.authorize(
      [{ permission: alpha.catalogLocationReadPermission }],
      { token: options == null ? void 0 : options.authorizationToken }
    ))[0];
    if (authorizationResponse.result === pluginPermissionCommon.AuthorizeResult.DENY) {
      throw new errors.NotFoundError(`Found no location with ID ${id}`);
    }
    return this.locationService.getLocation(id);
  }
  async deleteLocation(id, options) {
    const authorizationResponse = (await this.permissionApi.authorize(
      [{ permission: alpha.catalogLocationDeletePermission }],
      { token: options == null ? void 0 : options.authorizationToken }
    ))[0];
    if (authorizationResponse.result === pluginPermissionCommon.AuthorizeResult.DENY) {
      throw new errors.NotAllowedError();
    }
    return this.locationService.deleteLocation(id);
  }
  async getLocationByEntity(entityRef, options) {
    const authorizationResponse = (await this.permissionApi.authorize(
      [{ permission: alpha.catalogLocationReadPermission }],
      { token: options == null ? void 0 : options.authorizationToken }
    ))[0];
    if (authorizationResponse.result === pluginPermissionCommon.AuthorizeResult.DENY) {
      throw new errors.NotFoundError();
    }
    return this.locationService.getLocationByEntity(entityRef);
  }
}

async function deleteWithEagerPruningOfChildren(options) {
  const { knex, entityRefs, sourceKey } = options;
  let removedCount = 0;
  for (const refs of lodash__default["default"].chunk(entityRefs, 1e3)) {
    const { orphanEntityRefs } = await findDescendantsThatWouldHaveBeenOrphanedByDeletion({
      knex: options.knex,
      refs,
      sourceKey
    });
    for (const refsToDelete of lodash__default["default"].chunk(orphanEntityRefs, 1e3)) {
      await markEntitiesAffectedByDeletionForStitching({
        knex: options.knex,
        entityRefs: refsToDelete
      });
      await knex.delete().from("refresh_state").whereIn("entity_ref", refsToDelete);
    }
    await knex("refresh_state_references").where("source_key", "=", sourceKey).whereIn("target_entity_ref", refs).delete();
    removedCount += orphanEntityRefs.length;
  }
  return removedCount;
}
async function findDescendantsThatWouldHaveBeenOrphanedByDeletion(options) {
  const { knex, refs, sourceKey } = options;
  const orphans = (
    // First find all nodes that can be reached downwards from the roots
    // (deletion targets), including the roots themselves, by traversing
    // down the refresh_state_references table. Note that this query
    // starts with a condition that source_key = our source key, and
    // target_entity_ref is one of the deletion targets. This has two
    // effects: it won't match attempts at deleting something that didn't
    // originate from us in the first place, and also won't match non-root
    // entities (source_key would be null for those).
    //
    //   KeyA - R1 - R2        Legend:
    //                 \       -----------------------------------------
    //                  R3     Key*    Source key
    //                 /       R*      Entity ref
    //   KeyA - R4 - R5        lines   Individual references; sources to
    //              /                  the left and targets to the right
    //   KeyB --- R6
    //
    // The scenario is that KeyA wants to delete R1.
    //
    // The query starts with the KeyA-R1 reference, and then traverses
    // down to also find R2 and R3. It uses union instead of union all,
    // because it wants to find the set of unique descendants even if
    // the tree has unexpected loops etc.
    await knex.withRecursive(
      "descendants",
      ["entity_ref"],
      (initial) => initial.select("target_entity_ref").from("refresh_state_references").where("source_key", "=", sourceKey).whereIn("target_entity_ref", refs).union(
        (recursive) => recursive.select("refresh_state_references.target_entity_ref").from("descendants").join(
          "refresh_state_references",
          "descendants.entity_ref",
          "refresh_state_references.source_entity_ref"
        )
      )
    ).withRecursive(
      "ancestors",
      ["source_key", "source_entity_ref", "target_entity_ref", "subject"],
      (initial) => initial.select(
        "refresh_state_references.source_key",
        "refresh_state_references.source_entity_ref",
        "refresh_state_references.target_entity_ref",
        "descendants.entity_ref"
      ).from("descendants").join(
        "refresh_state_references",
        "refresh_state_references.target_entity_ref",
        "descendants.entity_ref"
      ).union(
        (recursive) => recursive.select(
          "refresh_state_references.source_key",
          "refresh_state_references.source_entity_ref",
          "refresh_state_references.target_entity_ref",
          "ancestors.subject"
        ).from("ancestors").join(
          "refresh_state_references",
          "refresh_state_references.target_entity_ref",
          "ancestors.source_entity_ref"
        )
      )
    ).with(
      "retained",
      ["entity_ref"],
      (notPartOfDeletion) => notPartOfDeletion.select("subject").from("ancestors").whereNotNull("ancestors.source_key").where(
        (foreignKeyOrRef) => foreignKeyOrRef.where("ancestors.source_key", "!=", sourceKey).orWhereNotIn("ancestors.target_entity_ref", refs)
      )
    ).select("descendants.entity_ref AS entity_ref").from("descendants").leftOuterJoin(
      "retained",
      "retained.entity_ref",
      "descendants.entity_ref"
    ).whereNull("retained.entity_ref").then((rows) => rows.map((row) => row.entity_ref))
  );
  return { orphanEntityRefs: orphans };
}
async function markEntitiesAffectedByDeletionForStitching(options) {
  const { knex, entityRefs } = options;
  const affectedIds = await knex.select("refresh_state.entity_id AS entity_id").from("relations").join(
    "refresh_state",
    "relations.source_entity_ref",
    "refresh_state.entity_ref"
  ).whereIn("relations.target_entity_ref", entityRefs).then((rows) => rows.map((row) => row.entity_id));
  for (const ids of lodash__default["default"].chunk(affectedIds, 1e3)) {
    await knex.table("final_entities").update({
      hash: "force-stitching"
    }).whereIn("entity_id", ids);
    await knex.table("refresh_state").update({
      result_hash: "force-stitching",
      next_update_at: knex.fn.now()
    }).whereIn("entity_id", ids);
  }
}

async function refreshByRefreshKeys(options) {
  const { tx, keys } = options;
  await tx("refresh_state").whereIn("entity_id", function selectEntityRefs(inner) {
    inner.whereIn("key", keys).select({
      entity_id: "refresh_keys.entity_id"
    }).from("refresh_keys");
  }).update({ next_update_at: tx.fn.now() });
}

const BATCH_SIZE = 50;
class DefaultProviderDatabase {
  constructor(options) {
    this.options = options;
  }
  async transaction(fn) {
    try {
      let result = void 0;
      await this.options.database.transaction(
        async (tx) => {
          result = await fn(tx);
        },
        {
          // If we explicitly trigger a rollback, don't fail.
          doNotRejectOnRollback: true
        }
      );
      return result;
    } catch (e) {
      this.options.logger.debug(`Error during transaction, ${e}`);
      throw rethrowError(e);
    }
  }
  async replaceUnprocessedEntities(txOpaque, options) {
    const tx = txOpaque;
    const { toAdd, toUpsert, toRemove } = await this.createDelta(tx, options);
    if (toRemove.length) {
      const removedCount = await deleteWithEagerPruningOfChildren({
        knex: tx,
        entityRefs: toRemove,
        sourceKey: options.sourceKey
      });
      this.options.logger.debug(
        `removed, ${removedCount} entities: ${JSON.stringify(toRemove)}`
      );
    }
    if (toAdd.length) {
      for (const chunk of lodash__default["default"].chunk(toAdd, 50)) {
        try {
          await tx.batchInsert(
            "refresh_state",
            chunk.map((item) => ({
              entity_id: uuid.v4(),
              entity_ref: catalogModel.stringifyEntityRef(item.deferred.entity),
              unprocessed_entity: JSON.stringify(item.deferred.entity),
              unprocessed_hash: item.hash,
              errors: "",
              location_key: item.deferred.locationKey,
              next_update_at: tx.fn.now(),
              last_discovery_at: tx.fn.now()
            })),
            BATCH_SIZE
          );
          await tx.batchInsert(
            "refresh_state_references",
            chunk.map((item) => ({
              source_key: options.sourceKey,
              target_entity_ref: catalogModel.stringifyEntityRef(item.deferred.entity)
            })),
            BATCH_SIZE
          );
        } catch (error) {
          if (!backendCommon.isDatabaseConflictError(error)) {
            throw error;
          } else {
            this.options.logger.debug(
              `Fast insert path failed, falling back to slow path, ${error}`
            );
            toUpsert.push(...chunk);
          }
        }
      }
    }
    if (toUpsert.length) {
      for (const {
        deferred: { entity, locationKey },
        hash
      } of toUpsert) {
        const entityRef = catalogModel.stringifyEntityRef(entity);
        try {
          let ok = await updateUnprocessedEntity({
            tx,
            entity,
            hash,
            locationKey
          });
          if (!ok) {
            ok = await insertUnprocessedEntity({
              tx,
              entity,
              hash,
              locationKey,
              logger: this.options.logger
            });
          }
          await tx("refresh_state_references").where("target_entity_ref", entityRef).andWhere({ source_key: options.sourceKey }).delete();
          if (ok) {
            await tx(
              "refresh_state_references"
            ).insert({
              source_key: options.sourceKey,
              target_entity_ref: entityRef
            });
          } else {
            const conflictingKey = await checkLocationKeyConflict({
              tx,
              entityRef,
              locationKey
            });
            if (conflictingKey) {
              this.options.logger.warn(
                `Source ${options.sourceKey} detected conflicting entityRef ${entityRef} already referenced by ${conflictingKey} and now also ${locationKey}`
              );
            }
          }
        } catch (error) {
          this.options.logger.error(
            `Failed to add '${entityRef}' from source '${options.sourceKey}', ${error}`
          );
        }
      }
    }
  }
  async refreshByRefreshKeys(txOpaque, options) {
    const tx = txOpaque;
    await refreshByRefreshKeys({ tx, keys: options.keys });
  }
  async createDelta(tx, options) {
    var _a, _b;
    if (options.type === "delta") {
      return {
        toAdd: [],
        toUpsert: options.added.map((e) => ({
          deferred: e,
          hash: generateStableHash$1(e.entity)
        })),
        toRemove: options.removed.map((e) => e.entityRef)
      };
    }
    const oldRefs = await tx(
      "refresh_state_references"
    ).leftJoin("refresh_state", {
      target_entity_ref: "entity_ref"
    }).where({ source_key: options.sourceKey }).select({
      target_entity_ref: "refresh_state_references.target_entity_ref",
      location_key: "refresh_state.location_key",
      unprocessed_hash: "refresh_state.unprocessed_hash"
    });
    const items = options.items.map((deferred) => ({
      deferred,
      ref: catalogModel.stringifyEntityRef(deferred.entity),
      hash: generateStableHash$1(deferred.entity)
    }));
    const oldRefsSet = new Map(
      oldRefs.map((r) => [
        r.target_entity_ref,
        {
          locationKey: r.location_key,
          oldEntityHash: r.unprocessed_hash
        }
      ])
    );
    const newRefsSet = new Set(items.map((item) => item.ref));
    const toAdd = new Array();
    const toUpsert = new Array();
    const toRemove = oldRefs.map((row) => row.target_entity_ref).filter((ref) => !newRefsSet.has(ref));
    for (const item of items) {
      const oldRef = oldRefsSet.get(item.ref);
      const upsertItem = { deferred: item.deferred, hash: item.hash };
      if (!oldRef) {
        toAdd.push(upsertItem);
      } else if (((_a = oldRef == null ? void 0 : oldRef.locationKey) != null ? _a : void 0) !== ((_b = item.deferred.locationKey) != null ? _b : void 0)) {
        toRemove.push(item.ref);
        toAdd.push(upsertItem);
      } else if (oldRef.oldEntityHash !== item.hash) {
        toUpsert.push(upsertItem);
      }
    }
    return { toAdd, toUpsert, toRemove };
  }
}

const MAX_ANCESTOR_DEPTH = 32;
class DefaultCatalogDatabase {
  constructor(options) {
    this.options = options;
  }
  async transaction(fn) {
    try {
      let result = void 0;
      await this.options.database.transaction(
        async (tx) => {
          result = await fn(tx);
        },
        {
          // If we explicitly trigger a rollback, don't fail.
          doNotRejectOnRollback: true
        }
      );
      return result;
    } catch (e) {
      this.options.logger.debug(`Error during transaction, ${e}`);
      throw rethrowError(e);
    }
  }
  async listAncestors(txOpaque, options) {
    var _a;
    const tx = txOpaque;
    const { entityRef } = options;
    const entityRefs = new Array();
    let currentRef = entityRef.toLocaleLowerCase("en-US");
    for (let depth = 1; depth <= MAX_ANCESTOR_DEPTH; depth += 1) {
      const rows = await tx(
        "refresh_state_references"
      ).where({ target_entity_ref: currentRef }).select();
      if (rows.length === 0) {
        if (depth === 1) {
          throw new errors.NotFoundError(`Entity ${currentRef} not found`);
        }
        throw new errors.NotFoundError(
          `Entity ${entityRef} has a broken parent reference chain at ${currentRef}`
        );
      }
      const parentRef = (_a = rows.find((r) => r.source_entity_ref)) == null ? void 0 : _a.source_entity_ref;
      if (!parentRef) {
        return { entityRefs };
      }
      entityRefs.push(parentRef);
      currentRef = parentRef;
    }
    throw new Error(
      `Unable receive ancestors for ${entityRef}, reached maximum depth of ${MAX_ANCESTOR_DEPTH}`
    );
  }
  async refresh(txOpaque, options) {
    const tx = txOpaque;
    const { entityRef } = options;
    const updateResult = await tx("refresh_state").where({ entity_ref: entityRef.toLocaleLowerCase("en-US") }).update({ next_update_at: tx.fn.now() });
    if (updateResult === 0) {
      throw new errors.NotFoundError(`Failed to schedule ${entityRef} for refresh`);
    }
  }
}

var __defProp = Object.defineProperty;
var __defNormalProp = (obj, key, value) => key in obj ? __defProp(obj, key, { enumerable: true, configurable: true, writable: true, value }) : obj[key] = value;
var __publicField = (obj, key, value) => {
  __defNormalProp(obj, typeof key !== "symbol" ? key + "" : key, value);
  return value;
};
class CatalogBuilder {
  constructor(env) {
    __publicField(this, "env");
    __publicField(this, "entityPolicies");
    __publicField(this, "entityPoliciesReplace");
    __publicField(this, "placeholderResolvers");
    __publicField(this, "fieldFormatValidators");
    __publicField(this, "entityProviders");
    __publicField(this, "processors");
    __publicField(this, "locationAnalyzers");
    __publicField(this, "processorsReplace");
    __publicField(this, "parser");
    __publicField(this, "onProcessingError");
    __publicField(this, "processingInterval");
    __publicField(this, "locationAnalyzer");
    __publicField(this, "permissionRules");
    __publicField(this, "allowedLocationType");
    __publicField(this, "legacySingleProcessorValidation", false);
    __publicField(this, "eventBroker");
    this.env = env;
    this.entityPolicies = [];
    this.entityPoliciesReplace = false;
    this.placeholderResolvers = {};
    this.fieldFormatValidators = {};
    this.entityProviders = [];
    this.processors = [];
    this.locationAnalyzers = [];
    this.processorsReplace = false;
    this.parser = void 0;
    this.permissionRules = Object.values(permissionRules);
    this.allowedLocationType = ["url"];
    this.processingInterval = CatalogBuilder.getDefaultProcessingInterval(
      env.config
    );
  }
  /**
   * Creates a catalog builder.
   */
  static create(env) {
    return new CatalogBuilder(env);
  }
  /**
   * Adds policies that are used to validate entities between the pre-
   * processing and post-processing stages. All such policies must pass for the
   * entity to be considered valid.
   *
   * If what you want to do is to replace the rules for what format is allowed
   * in various core entity fields (such as metadata.name), you may want to use
   * {@link CatalogBuilder#setFieldFormatValidators} instead.
   *
   * @param policies - One or more policies
   */
  addEntityPolicy(...policies) {
    this.entityPolicies.push(...policies.flat());
    return this;
  }
  /**
   * Processing interval determines how often entities should be processed.
   * Seconds provided will be multiplied by 1.5
   * The default processing interval is 100-150 seconds.
   * setting this too low will potentially deplete request quotas to upstream services.
   */
  setProcessingIntervalSeconds(seconds) {
    this.processingInterval = createRandomProcessingInterval({
      minSeconds: seconds,
      maxSeconds: seconds * 1.5
    });
    return this;
  }
  /**
   * Overwrites the default processing interval function used to spread
   * entity updates in the catalog.
   */
  setProcessingInterval(processingInterval) {
    this.processingInterval = processingInterval;
    return this;
  }
  /**
   * Overwrites the default location analyzer.
   */
  setLocationAnalyzer(locationAnalyzer) {
    this.locationAnalyzer = locationAnalyzer;
    return this;
  }
  /**
   * Sets what policies to use for validation of entities between the pre-
   * processing and post-processing stages. All such policies must pass for the
   * entity to be considered valid.
   *
   * If what you want to do is to replace the rules for what format is allowed
   * in various core entity fields (such as metadata.name), you may want to use
   * {@link CatalogBuilder#setFieldFormatValidators} instead.
   *
   * This function replaces the default set of policies; use with care.
   *
   * @param policies - One or more policies
   */
  replaceEntityPolicies(policies) {
    this.entityPolicies = [...policies];
    this.entityPoliciesReplace = true;
    return this;
  }
  /**
   * Adds, or overwrites, a handler for placeholders (e.g. $file) in entity
   * definition files.
   *
   * @param key - The key that identifies the placeholder, e.g. "file"
   * @param resolver - The resolver that gets values for this placeholder
   */
  setPlaceholderResolver(key, resolver) {
    this.placeholderResolvers[key] = resolver;
    return this;
  }
  /**
   * Sets the validator function to use for one or more special fields of an
   * entity. This is useful if the default rules for formatting of fields are
   * not sufficient.
   *
   * This function has no effect if used together with
   * {@link CatalogBuilder#replaceEntityPolicies}.
   *
   * @param validators - The (subset of) validators to set
   */
  setFieldFormatValidators(validators) {
    lodash__default["default"].merge(this.fieldFormatValidators, validators);
    return this;
  }
  /**
   * Adds or replaces entity providers. These are responsible for bootstrapping
   * the list of entities out of original data sources. For example, there is
   * one entity source for the config locations, and one for the database
   * stored locations. If you ingest entities out of a third party system, you
   * may want to implement that in terms of an entity provider as well.
   *
   * @param providers - One or more entity providers
   */
  addEntityProvider(...providers) {
    this.entityProviders.push(...providers.flat());
    return this;
  }
  /**
   * Adds entity processors. These are responsible for reading, parsing, and
   * processing entities before they are persisted in the catalog.
   *
   * @param processors - One or more processors
   */
  addProcessor(...processors) {
    this.processors.push(...processors.flat());
    return this;
  }
  /**
   * Sets what entity processors to use. These are responsible for reading,
   * parsing, and processing entities before they are persisted in the catalog.
   *
   * This function replaces the default set of processors, consider using with
   * {@link CatalogBuilder#getDefaultProcessors}; use with care.
   *
   * @param processors - One or more processors
   */
  replaceProcessors(processors) {
    this.processors = [...processors];
    this.processorsReplace = true;
    return this;
  }
  /**
   * Returns the default list of entity processors. These are responsible for reading,
   * parsing, and processing entities before they are persisted in the catalog. Changing
   * the order of processing can give more control to custom processors.
   *
   * Consider using with {@link CatalogBuilder#replaceProcessors}
   *
   */
  getDefaultProcessors() {
    const { config, logger, reader } = this.env;
    const integrations = integration.ScmIntegrations.fromConfig(config);
    return [
      new FileReaderProcessor(),
      new UrlReaderProcessor({ reader, logger }),
      CodeOwnersProcessor.fromConfig(config, { logger, reader }),
      new AnnotateLocationEntityProcessor({ integrations })
    ];
  }
  /**
   * Adds Location Analyzers. These are responsible for analyzing
   * repositories when onboarding them into the catalog, by finding
   * catalog-info.yaml files and other artifacts that can help automatically
   * register or create catalog data on the user's behalf.
   *
   * @param locationAnalyzers - One or more location analyzers
   */
  addLocationAnalyzers(...analyzers) {
    this.locationAnalyzers.push(...analyzers.flat());
    return this;
  }
  /**
   * Sets up the catalog to use a custom parser for entity data.
   *
   * This is the function that gets called immediately after some raw entity
   * specification data has been read from a remote source, and needs to be
   * parsed and emitted as structured data.
   *
   * @param parser - The custom parser
   */
  setEntityDataParser(parser) {
    this.parser = parser;
    return this;
  }
  /**
   * Adds additional permission rules. Permission rules are used to evaluate
   * catalog resources against queries. See
   * {@link @backstage/plugin-permission-node#PermissionRule}.
   *
   * @param permissionRules - Additional permission rules
   */
  addPermissionRules(...permissionRules) {
    this.permissionRules.push(...permissionRules.flat());
    return this;
  }
  /**
   * Sets up the allowed location types from being registered via the location service.
   *
   * @param allowedLocationTypes - the allowed location types
   */
  setAllowedLocationTypes(allowedLocationTypes) {
    this.allowedLocationType = allowedLocationTypes;
    return this;
  }
  /**
   * Enables the legacy behaviour of canceling validation early whenever only a
   * single processor declares an entity kind to be valid.
   */
  useLegacySingleProcessorValidation() {
    this.legacySingleProcessorValidation = true;
    return this;
  }
  /**
   * Enables the publishing of events for conflicts in the DefaultProcessingDatabase
   */
  setEventBroker(broker) {
    this.eventBroker = broker;
    return this;
  }
  /**
   * Wires up and returns all of the component parts of the catalog
   */
  async build() {
    var _a, _b;
    const { config, database, logger, permissions, scheduler } = this.env;
    const policy = this.buildEntityPolicy();
    const processors = this.buildProcessors();
    const parser = this.parser || defaultEntityDataParser;
    const dbClient = await database.getClient();
    if (!((_a = database.migrations) == null ? void 0 : _a.skip)) {
      logger.info("Performing database migration");
      await applyDatabaseMigrations(dbClient);
    }
    const stitcher = DefaultStitcher.fromConfig(config, {
      knex: dbClient,
      logger
    });
    const processingDatabase = new DefaultProcessingDatabase({
      database: dbClient,
      logger,
      refreshInterval: this.processingInterval,
      eventBroker: this.eventBroker
    });
    const providerDatabase = new DefaultProviderDatabase({
      database: dbClient,
      logger
    });
    const catalogDatabase = new DefaultCatalogDatabase({
      database: dbClient,
      logger
    });
    const integrations = integration.ScmIntegrations.fromConfig(config);
    const rulesEnforcer = DefaultCatalogRulesEnforcer.fromConfig(config);
    const orchestrator = new DefaultCatalogProcessingOrchestrator({
      processors,
      integrations,
      rulesEnforcer,
      logger,
      parser,
      policy,
      legacySingleProcessorValidation: this.legacySingleProcessorValidation
    });
    const unauthorizedEntitiesCatalog = new DefaultEntitiesCatalog({
      database: dbClient,
      logger,
      stitcher
    });
    let permissionEvaluator;
    if ("authorizeConditional" in permissions) {
      permissionEvaluator = permissions;
    } else {
      logger.warn(
        "PermissionAuthorizer is deprecated. Please use an instance of PermissionEvaluator instead of PermissionAuthorizer in PluginEnvironment#permissions"
      );
      permissionEvaluator = pluginPermissionCommon.toPermissionEvaluator(permissions);
    }
    const entitiesCatalog = new AuthorizedEntitiesCatalog(
      unauthorizedEntitiesCatalog,
      permissionEvaluator,
      pluginPermissionNode.createConditionTransformer(this.permissionRules)
    );
    const permissionIntegrationRouter = pluginPermissionNode.createPermissionIntegrationRouter({
      resourceType: alpha.RESOURCE_TYPE_CATALOG_ENTITY,
      getResources: async (resourceRefs) => {
        const { entities } = await unauthorizedEntitiesCatalog.entities({
          filter: {
            anyOf: resourceRefs.map((resourceRef) => {
              const { kind, namespace, name } = catalogModel.parseEntityRef(resourceRef);
              return basicEntityFilter({
                kind,
                "metadata.namespace": namespace,
                "metadata.name": name
              });
            })
          }
        });
        const entitiesByRef = lodash.keyBy(entities, catalogModel.stringifyEntityRef);
        return resourceRefs.map(
          (resourceRef) => entitiesByRef[catalogModel.stringifyEntityRef(catalogModel.parseEntityRef(resourceRef))]
        );
      },
      permissions: alpha.catalogPermissions,
      rules: this.permissionRules
    });
    const locationStore = new DefaultLocationStore(dbClient);
    const configLocationProvider = new ConfigLocationEntityProvider(config);
    const entityProviders = lodash__default["default"].uniqBy(
      [...this.entityProviders, locationStore, configLocationProvider],
      (provider) => provider.getProviderName()
    );
    const processingEngine = new DefaultCatalogProcessingEngine({
      config,
      scheduler,
      logger,
      knex: dbClient,
      processingDatabase,
      orchestrator,
      stitcher,
      createHash: () => crypto.createHash("sha1"),
      pollingIntervalMs: 1e3,
      onProcessingError: (event) => {
        var _a2;
        (_a2 = this.onProcessingError) == null ? void 0 : _a2.call(this, event);
      }
    });
    const locationAnalyzer = (_b = this.locationAnalyzer) != null ? _b : new RepoLocationAnalyzer(logger, integrations, this.locationAnalyzers);
    const locationService = new AuthorizedLocationService(
      new DefaultLocationService(locationStore, orchestrator, {
        allowedLocationTypes: this.allowedLocationType
      }),
      permissionEvaluator
    );
    const refreshService = new AuthorizedRefreshService(
      new DefaultRefreshService({ database: catalogDatabase }),
      permissionEvaluator
    );
    const router = await createRouter({
      entitiesCatalog,
      locationAnalyzer,
      locationService,
      orchestrator,
      refreshService,
      logger,
      config,
      permissionIntegrationRouter
    });
    await connectEntityProviders(providerDatabase, entityProviders);
    return {
      processingEngine: {
        async start() {
          await processingEngine.start();
          await stitcher.start();
        },
        async stop() {
          await processingEngine.stop();
          await stitcher.stop();
        }
      },
      router
    };
  }
  subscribe(options) {
    this.onProcessingError = options.onProcessingError;
  }
  buildEntityPolicy() {
    const entityPolicies = this.entityPoliciesReplace ? [new catalogModel.SchemaValidEntityPolicy(), ...this.entityPolicies] : [
      new catalogModel.SchemaValidEntityPolicy(),
      new catalogModel.DefaultNamespaceEntityPolicy(),
      new catalogModel.NoForeignRootFieldsEntityPolicy(),
      new catalogModel.FieldFormatEntityPolicy(
        catalogModel.makeValidator(this.fieldFormatValidators)
      ),
      ...this.entityPolicies
    ];
    return catalogModel.EntityPolicies.allOf(entityPolicies);
  }
  buildProcessors() {
    const { config, reader } = this.env;
    const integrations = integration.ScmIntegrations.fromConfig(config);
    this.checkDeprecatedReaderProcessors();
    const placeholderResolvers = {
      json: jsonPlaceholderResolver,
      yaml: yamlPlaceholderResolver,
      text: textPlaceholderResolver,
      ...this.placeholderResolvers
    };
    const processors = [
      new PlaceholderProcessor({
        resolvers: placeholderResolvers,
        reader,
        integrations
      })
    ];
    const builtinKindsEntityProcessor = new BuiltinKindsEntityProcessor();
    if (!this.processors.some(
      (processor) => processor.getProcessorName() === builtinKindsEntityProcessor.getProcessorName()
    )) {
      processors.push(builtinKindsEntityProcessor);
    }
    if (!this.processorsReplace) {
      processors.push(...this.getDefaultProcessors());
    }
    processors.push(...this.processors);
    this.checkMissingExternalProcessors(processors);
    return processors;
  }
  // TODO(Rugvip): These old processors are removed, for a while we'll be throwing
  //               errors here to make sure people know where to move the config
  checkDeprecatedReaderProcessors() {
    const pc = this.env.config.getOptionalConfig("catalog.processors");
    if (pc == null ? void 0 : pc.has("github")) {
      throw new Error(
        `Using deprecated configuration for catalog.processors.github, move to using integrations.github instead`
      );
    }
    if (pc == null ? void 0 : pc.has("gitlabApi")) {
      throw new Error(
        `Using deprecated configuration for catalog.processors.gitlabApi, move to using integrations.gitlab instead`
      );
    }
    if (pc == null ? void 0 : pc.has("bitbucketApi")) {
      throw new Error(
        `Using deprecated configuration for catalog.processors.bitbucketApi, move to using integrations.bitbucket instead`
      );
    }
    if (pc == null ? void 0 : pc.has("azureApi")) {
      throw new Error(
        `Using deprecated configuration for catalog.processors.azureApi, move to using integrations.azure instead`
      );
    }
  }
  // TODO(freben): This can be removed no sooner than June 2022, after adopters have had some time to adapt to the new package structure
  checkMissingExternalProcessors(processors) {
    var _a, _b;
    const skipCheckVarName = "BACKSTAGE_CATALOG_SKIP_MISSING_PROCESSORS_CHECK";
    if (process.env[skipCheckVarName]) {
      return;
    }
    const locationTypes = new Set(
      (_b = (_a = this.env.config.getOptionalConfigArray("catalog.locations")) == null ? void 0 : _a.map((l) => l.getString("type"))) != null ? _b : []
    );
    const processorNames = new Set(processors.map((p) => p.getProcessorName()));
    function check(locationType, processorName, installationUrl) {
      if (locationTypes.has(locationType) && !processorNames.has(processorName)) {
        throw new Error(
          [
            `Your config contains a "catalog.locations" entry of type ${locationType},`,
            `but does not have the corresponding catalog processor ${processorName} installed.`,
            `This processor used to be built into the catalog itself, but is now moved to an`,
            `external module that has to be installed manually. Please follow the installation`,
            `instructions at ${installationUrl} if you are using this ability, or remove the`,
            `location from your app config if you do not. You can also silence this check entirely`,
            `by setting the environment variable ${skipCheckVarName} to 'true'.`
          ].join(" ")
        );
      }
    }
    check(
      "aws-cloud-accounts",
      "AwsOrganizationCloudAccountProcessor",
      "https://backstage.io/docs/integrations"
    );
    check(
      "s3-discovery",
      "AwsS3DiscoveryProcessor",
      "https://backstage.io/docs/integrations/aws-s3/discovery"
    );
    check(
      "azure-discovery",
      "AzureDevOpsDiscoveryProcessor",
      "https://backstage.io/docs/integrations/azure/discovery"
    );
    check(
      "bitbucket-discovery",
      "BitbucketDiscoveryProcessor",
      "https://backstage.io/docs/integrations/bitbucket/discovery"
    );
    check(
      "github-discovery",
      "GithubDiscoveryProcessor",
      "https://backstage.io/docs/integrations/github/discovery"
    );
    check(
      "github-org",
      "GithubOrgReaderProcessor",
      "https://backstage.io/docs/integrations/github/org"
    );
    check(
      "gitlab-discovery",
      "GitLabDiscoveryProcessor",
      "https://backstage.io/docs/integrations/gitlab/discovery"
    );
    check(
      "ldap-org",
      "LdapOrgReaderProcessor",
      "https://backstage.io/docs/integrations/ldap/org"
    );
    check(
      "microsoft-graph-org",
      "MicrosoftGraphOrgReaderProcessor",
      "https://backstage.io/docs/integrations/azure/org"
    );
  }
  static getDefaultProcessingInterval(config$1) {
    const processingIntervalKey = "catalog.processingInterval";
    if (!config$1.has(processingIntervalKey)) {
      return createRandomProcessingInterval({
        minSeconds: 100,
        maxSeconds: 150
      });
    }
    const duration = config.readDurationFromConfig(config$1, {
      key: processingIntervalKey
    });
    const seconds = Math.max(
      1,
      Math.round(types.durationToMilliseconds(duration) / 1e3)
    );
    return createRandomProcessingInterval({
      minSeconds: seconds,
      maxSeconds: seconds * 1.5
    });
  }
}

exports.AnnotateLocationEntityProcessor = AnnotateLocationEntityProcessor;
exports.BuiltinKindsEntityProcessor = BuiltinKindsEntityProcessor;
exports.CATALOG_CONFLICTS_TOPIC = CATALOG_CONFLICTS_TOPIC;
exports.CatalogBuilder = CatalogBuilder;
exports.CodeOwnersProcessor = CodeOwnersProcessor;
exports.FileReaderProcessor = FileReaderProcessor;
exports.PlaceholderProcessor = PlaceholderProcessor;
exports.UrlReaderProcessor = UrlReaderProcessor;
exports.createCatalogPermissionRule = createCatalogPermissionRule;
exports.createRandomProcessingInterval = createRandomProcessingInterval;
exports.parseEntityYaml = parseEntityYaml;
exports.permissionRules = permissionRules;
//# sourceMappingURL=CatalogBuilder-12834e8e.cjs.js.map
