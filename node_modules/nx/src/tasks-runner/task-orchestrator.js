"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.TaskOrchestrator = void 0;
const events_1 = require("events");
const perf_hooks_1 = require("perf_hooks");
const forked_process_task_runner_1 = require("./forked-process-task-runner");
const cache_1 = require("./cache");
const utils_1 = require("./utils");
const tasks_schedule_1 = require("./tasks-schedule");
class TaskOrchestrator {
    // endregion internal state
    constructor(hasher, initiatingProject, projectGraph, taskGraph, options, bail, daemon) {
        this.hasher = hasher;
        this.initiatingProject = initiatingProject;
        this.projectGraph = projectGraph;
        this.taskGraph = taskGraph;
        this.options = options;
        this.bail = bail;
        this.daemon = daemon;
        this.cache = new cache_1.Cache(this.options);
        this.forkedProcessTaskRunner = new forked_process_task_runner_1.ForkedProcessTaskRunner(this.options);
        this.tasksSchedule = new tasks_schedule_1.TasksSchedule(this.hasher, this.projectGraph, this.taskGraph, this.options);
        // region internal state
        this.reverseTaskDeps = (0, utils_1.calculateReverseDeps)(this.taskGraph);
        this.completedTasks = {};
        this.waitingForTasks = [];
        this.groups = [];
        this.bailed = false;
    }
    async run() {
        // initial scheduling
        await this.tasksSchedule.scheduleNextTasks();
        perf_hooks_1.performance.mark('task-execution:start');
        const threads = [];
        process.stdout.setMaxListeners(this.options.parallel + events_1.defaultMaxListeners);
        process.stderr.setMaxListeners(this.options.parallel + events_1.defaultMaxListeners);
        // initial seeding of the queue
        for (let i = 0; i < this.options.parallel; ++i) {
            threads.push(this.executeNextBatchOfTasksUsingTaskSchedule());
        }
        await Promise.all(threads);
        perf_hooks_1.performance.mark('task-execution:end');
        perf_hooks_1.performance.measure('task-execution', 'task-execution:start', 'task-execution:end');
        this.cache.removeOldCacheRecords();
        return this.completedTasks;
    }
    async executeNextBatchOfTasksUsingTaskSchedule() {
        // completed all the tasks
        if (!this.tasksSchedule.hasTasks() || this.bailed) {
            return null;
        }
        const doNotSkipCache = this.options.skipNxCache === false ||
            this.options.skipNxCache === undefined;
        const batch = this.tasksSchedule.nextBatch();
        if (batch) {
            const groupId = this.closeGroup();
            await this.applyFromCacheOrRunBatch(doNotSkipCache, batch, groupId);
            this.openGroup(groupId);
            return this.executeNextBatchOfTasksUsingTaskSchedule();
        }
        const task = this.tasksSchedule.nextTask();
        if (task) {
            const groupId = this.closeGroup();
            await this.applyFromCacheOrRunTask(doNotSkipCache, task, groupId);
            this.openGroup(groupId);
            return this.executeNextBatchOfTasksUsingTaskSchedule();
        }
        // block until some other task completes, then try again
        return new Promise((res) => this.waitingForTasks.push(res)).then(() => this.executeNextBatchOfTasksUsingTaskSchedule());
    }
    // region Applying Cache
    async applyCachedResults(tasks) {
        const cacheableTasks = tasks.filter((t) => (0, utils_1.isCacheableTask)(t, this.options));
        const res = await Promise.all(cacheableTasks.map((t) => this.applyCachedResult(t)));
        return res.filter((r) => r !== null);
    }
    async applyCachedResult(task) {
        task.startTime = Date.now();
        const cachedResult = await this.cache.get(task);
        if (!cachedResult || cachedResult.code !== 0)
            return null;
        const outputs = (0, utils_1.getOutputs)(this.projectGraph.nodes, task);
        const shouldCopyOutputsFromCache = !!outputs.length &&
            (await this.shouldCopyOutputsFromCache(outputs, task.hash));
        if (shouldCopyOutputsFromCache) {
            await this.cache.copyFilesFromCache(task.hash, cachedResult, outputs);
        }
        task.endTime = Date.now();
        const status = cachedResult.remote
            ? 'remote-cache'
            : shouldCopyOutputsFromCache
                ? 'local-cache'
                : 'local-cache-kept-existing';
        this.options.lifeCycle.printTaskTerminalOutput(task, status, cachedResult.terminalOutput);
        return {
            task,
            status,
        };
    }
    // endregion Applying Cache
    // region Batch
    async applyFromCacheOrRunBatch(doNotSkipCache, batch, groupId) {
        const taskEntries = Object.entries(batch.taskGraph.tasks);
        const tasks = taskEntries.map(([, task]) => task);
        await this.preRunSteps(tasks, { groupId });
        let results = doNotSkipCache ? await this.applyCachedResults(tasks) : [];
        // Run tasks that were not cached
        if (results.length !== taskEntries.length) {
            const unrunTaskGraph = (0, utils_1.removeTasksFromTaskGraph)(batch.taskGraph, results.map(({ task }) => task.id));
            const batchResults = await this.runBatch({
                executorName: batch.executorName,
                taskGraph: unrunTaskGraph,
            });
            results.push(...batchResults);
        }
        await this.postRunSteps(tasks, results, doNotSkipCache, { groupId });
        const tasksCompleted = taskEntries.filter(([taskId]) => this.completedTasks[taskId]);
        // Batch is still not done, run it again
        if (tasksCompleted.length !== taskEntries.length) {
            await this.applyFromCacheOrRunBatch(doNotSkipCache, {
                executorName: batch.executorName,
                taskGraph: (0, utils_1.removeTasksFromTaskGraph)(batch.taskGraph, tasksCompleted.map(([taskId]) => taskId)),
            }, groupId);
        }
    }
    async runBatch(batch) {
        try {
            const results = await this.forkedProcessTaskRunner.forkProcessForBatch(batch, this.taskGraph);
            const batchResultEntries = Object.entries(results);
            return batchResultEntries.map(([taskId, result]) => ({
                ...result,
                task: {
                    ...this.taskGraph.tasks[taskId],
                    startTime: result.startTime,
                    endTime: result.endTime,
                },
                status: (result.success ? 'success' : 'failure'),
                terminalOutput: result.terminalOutput,
            }));
        }
        catch (e) {
            return batch.taskGraph.roots.map((rootTaskId) => ({
                task: this.taskGraph.tasks[rootTaskId],
                status: 'failure',
            }));
        }
    }
    // endregion Batch
    // region Single Task
    async applyFromCacheOrRunTask(doNotSkipCache, task, groupId) {
        await this.preRunSteps([task], { groupId });
        // hash the task here
        let results = doNotSkipCache ? await this.applyCachedResults([task]) : [];
        // the task wasn't cached
        if (results.length === 0) {
            // cache prep
            const { code, terminalOutput } = await this.runTaskInForkedProcess(task);
            results.push({
                task,
                status: code === 0 ? 'success' : 'failure',
                terminalOutput,
            });
        }
        await this.postRunSteps([task], results, doNotSkipCache, { groupId });
    }
    async runTaskInForkedProcess(task) {
        try {
            // obtain metadata
            const temporaryOutputPath = this.cache.temporaryOutputPath(task);
            const streamOutput = (0, utils_1.shouldStreamOutput)(task, this.initiatingProject, this.options);
            const pipeOutput = await this.pipeOutputCapture(task);
            // execution
            const { code, terminalOutput } = pipeOutput
                ? await this.forkedProcessTaskRunner.forkProcessPipeOutputCapture(task, {
                    temporaryOutputPath,
                    streamOutput,
                    taskGraph: this.taskGraph,
                })
                : await this.forkedProcessTaskRunner.forkProcessDirectOutputCapture(task, {
                    temporaryOutputPath,
                    streamOutput,
                    taskGraph: this.taskGraph,
                });
            return {
                code,
                terminalOutput,
            };
        }
        catch (e) {
            return {
                code: 1,
            };
        }
    }
    // endregion Single Task
    // region Lifecycle
    async preRunSteps(tasks, metadata) {
        this.options.lifeCycle.startTasks(tasks, metadata);
    }
    async postRunSteps(tasks, results, doNotSkipCache, { groupId }) {
        for (const task of tasks) {
            await this.recordOutputsHash(task);
        }
        if (doNotSkipCache) {
            // cache the results
            perf_hooks_1.performance.mark('cache-results-start');
            await Promise.all(results
                .filter(({ status }) => status !== 'local-cache' &&
                status !== 'local-cache-kept-existing' &&
                status !== 'remote-cache' &&
                status !== 'skipped')
                .map((result) => ({
                ...result,
                code: result.status === 'local-cache' ||
                    result.status === 'local-cache-kept-existing' ||
                    result.status === 'remote-cache' ||
                    result.status === 'success'
                    ? 0
                    : 1,
                outputs: (0, utils_1.getOutputs)(this.projectGraph.nodes, result.task),
            }))
                .filter(({ task, code }) => this.shouldCacheTaskResult(task, code))
                .filter(({ terminalOutput, outputs }) => terminalOutput || outputs)
                .map(async ({ task, code, terminalOutput, outputs }) => this.cache.put(task, terminalOutput, outputs, code)));
            perf_hooks_1.performance.mark('cache-results-end');
            perf_hooks_1.performance.measure('cache-results', 'cache-results-start', 'cache-results-end');
        }
        this.options.lifeCycle.endTasks(results.map((result) => {
            const code = result.status === 'success' ||
                result.status === 'local-cache' ||
                result.status === 'local-cache-kept-existing' ||
                result.status === 'remote-cache'
                ? 0
                : 1;
            return {
                ...result,
                task: result.task,
                status: result.status,
                code,
            };
        }), { groupId });
        this.complete(results.map(({ task, status }) => {
            return {
                taskId: task.id,
                status,
            };
        }));
        await this.tasksSchedule.scheduleNextTasks();
        // release blocked threads
        this.waitingForTasks.forEach((f) => f(null));
        this.waitingForTasks.length = 0;
    }
    complete(taskResults) {
        this.tasksSchedule.complete(taskResults.map(({ taskId }) => taskId));
        for (const { taskId, status } of taskResults) {
            if (this.completedTasks[taskId] === undefined) {
                this.completedTasks[taskId] = status;
                if (status === 'failure' || status === 'skipped') {
                    if (this.bail) {
                        // mark the execution as bailed which will stop all further execution
                        // only the tasks that are currently running will finish
                        this.bailed = true;
                    }
                    else {
                        // only mark the packages that depend on the current task as skipped
                        // other tasks will continue to execute
                        this.complete(this.reverseTaskDeps[taskId].map((depTaskId) => ({
                            taskId: depTaskId,
                            status: 'skipped',
                        })));
                    }
                }
            }
        }
    }
    //endregion Lifecycle
    // region utils
    async pipeOutputCapture(task) {
        try {
            const { schema } = await (0, utils_1.getExecutorForTask)(task, this.projectGraph);
            return (schema.outputCapture === 'pipe' ||
                process.env.NX_STREAM_OUTPUT === 'true');
        }
        catch (e) {
            return false;
        }
    }
    shouldCacheTaskResult(task, code) {
        return ((0, utils_1.isCacheableTask)(task, this.options) &&
            (process.env.NX_CACHE_FAILURES == 'true' ? true : code === 0));
    }
    closeGroup() {
        for (let i = 0; i < this.options.parallel; i++) {
            if (!this.groups[i]) {
                this.groups[i] = true;
                return i;
            }
        }
    }
    openGroup(id) {
        this.groups[id] = false;
    }
    async shouldCopyOutputsFromCache(outputs, hash) {
        if (this.daemon?.enabled()) {
            return !(await this.daemon.outputsHashesMatch(outputs, hash));
        }
        else {
            return true;
        }
    }
    async recordOutputsHash(task) {
        if (this.daemon?.enabled()) {
            return this.daemon.recordOutputsHash((0, utils_1.getOutputs)(this.projectGraph.nodes, task), task.hash);
        }
    }
}
exports.TaskOrchestrator = TaskOrchestrator;
